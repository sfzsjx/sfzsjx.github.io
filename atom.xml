<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>上善若水博客</title>
  
  <subtitle>大数据</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-03-16T08:26:16.279Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>上善若水</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Mysql 优化原理 笔记</title>
    <link href="http://yoursite.com/2019/03/16/Mysql-%E4%BC%98%E5%8C%96%E5%8E%9F%E7%90%86-%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2019/03/16/Mysql-优化原理-笔记/</id>
    <published>2019-03-16T08:07:15.000Z</published>
    <updated>2019-03-16T08:26:16.279Z</updated>
    
    <content type="html"><![CDATA[<p>Mysql 逻辑框架<br><img src="/images/2019/03/16/7156c0e0-47be-11e9-898c-d1fd811fe7b6.png" alt="image.png"></p><p>MYSQL 逻辑框架整体分为三层，最上层为客户端层，并非Mysql独有，诸如：连接处理，授权认证，安全等。</p><p>MYSQL 大多数核心服务均在这中间这一层，包括查询解析、分析、优化、缓存、内置函数。所有的跨存储引擎也在这层实现，如：存储过程，触发器和视图等</p><p>最下层为存储引擎。负责Mysql中数据存储和提取。</p><h2 id="Mysql查询过程"><a href="#Mysql查询过程" class="headerlink" title="Mysql查询过程"></a>Mysql查询过程</h2><p>  Mysql查询优化，首先得了解Mysql是如何优化和执行查询的，然后在实际的工作中就是遵循一些原则让Mysql的优化器能够按照预想的合理的方式运行而已。</p><p><img src="/images/2019/03/16/bce25300-47c1-11e9-898c-d1fd811fe7b6.png" alt="image.png"></p><p><img src="/images/2019/03/16/cfcff250-47c2-11e9-898c-d1fd811fe7b6.png" alt="image.png"></p><p>参考：<a href="https://mp.weixin.qq.com/s/OeKXHpnk72kp37E6z97xMA" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/OeKXHpnk72kp37E6z97xMA</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Mysql 逻辑框架&lt;br&gt;&lt;img src=&quot;/images/2019/03/16/7156c0e0-47be-11e9-898c-d1fd811fe7b6.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;MYSQL 逻辑框架整体分为三层，最上层为客户端层，并非
      
    
    </summary>
    
      <category term="mysql，数据库" scheme="http://yoursite.com/categories/mysql%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>数据挖掘实战（2）： 信用卡诈骗分析</title>
    <link href="http://yoursite.com/2019/03/15/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%98%EF%BC%882%EF%BC%89%EF%BC%9A-%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%AF%88%E9%AA%97%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2019/03/15/数据挖掘实战（2）：-信用卡诈骗分析/</id>
    <published>2019-03-15T06:13:29.000Z</published>
    <updated>2019-03-15T07:31:41.410Z</updated>
    
    <content type="html"><![CDATA[<p>信用卡诈骗分析目标：通过以往的交易数据分析出每笔交易是否正常，是否存在盗刷的风险。<br>学习目标：</p><ol><li>学习逻辑回归</li><li>信用卡欺诈属于二分类问题，欺诈交易在所有交易中比例很小，对于这种数据不平衡情况，到底采用什么样的模型评估标准更准确；</li><li>完成信用卡欺诈分析实战项目，并通过数据可视化对数据探索和模型评估进一步加强了解。</li></ol><p>构建逻辑回归分类器<br>  逻辑回归（logistic回归），主要解决二分类问题。在逻辑回归中使用Logistic函数<br>也称Sigmoid函数。</p><p><img src="/images/2019/03/15/c13beb30-46e7-11e9-a19b-17ea8a04d566.png" alt="image.png"></p><p>函数形如S状：<br><img src="/images/2019/03/15/d9159210-46e7-11e9-a19b-17ea8a04d566.png" alt="image.png"></p><p>算法实现理解：我们要实现一个二分类任务，0为不发生，1为发生。而通过对历史样本学习得到一个新的模型<br>，当新的样本给出时，预测出结果。这里得到是y的一个预测概率。通常我们认为概率大于50%<br>则发生，反之，则不发生。</p><p>在sklearn中，使用LogisticRegression()函数构建逻辑回归分类器，函数常用的构造参数：</p><ol><li>penalty ：惩罚项，取值为l1或l2，默认为l2。当模型参数满足高斯分布时用l2，当模型参数满足拉普拉斯分布时用l1;</li><li>solver: 代表的是逻辑回归损失函数的优化方法。有5个参数可选，分别为liblinear、lbfgs、newton-cg、sag或saga.默认为liblinear,s适用于数据量较小的数据集，当数据量较大的时候可以选用sag或saga方法。</li><li>max_iter:算法收敛最大迭代次数，默认为10.</li><li>n_jobs:拟合和预测的时候CPU的核数，默认为1.</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;信用卡诈骗分析目标：通过以往的交易数据分析出每笔交易是否正常，是否存在盗刷的风险。&lt;br&gt;学习目标：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;学习逻辑回归&lt;/li&gt;
&lt;li&gt;信用卡欺诈属于二分类问题，欺诈交易在所有交易中比例很小，对于这种数据不平衡情况，到底采用什么样的模型评估标准更准确
      
    
    </summary>
    
      <category term="数据分析" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="数据分析" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>shell 编写 脚本常用命令</title>
    <link href="http://yoursite.com/2019/03/15/shell-%E7%BC%96%E5%86%99-%E8%84%9A%E6%9C%AC%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2019/03/15/shell-编写-脚本常用命令/</id>
    <published>2019-03-15T01:22:52.000Z</published>
    <updated>2019-03-15T01:34:25.111Z</updated>
    
    <content type="html"><![CDATA[<p>统计test.sh 文件命令的行数<br>sed -n ‘$=’ /home/hadoop/test/test.sh</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;统计test.sh 文件命令的行数&lt;br&gt;sed -n ‘$=’ /home/hadoop/test/test.sh&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>数据挖掘实战（1） ： 信用卡违约率分析</title>
    <link href="http://yoursite.com/2019/03/14/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%98%EF%BC%881%EF%BC%89-%EF%BC%9A-%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%BF%9D%E7%BA%A6%E7%8E%87%E5%88%86%E6%9E%90/"/>
    <id>http://yoursite.com/2019/03/14/数据挖掘实战（1）-：-信用卡违约率分析/</id>
    <published>2019-03-14T02:23:18.000Z</published>
    <updated>2019-03-15T05:46:46.512Z</updated>
    
    <content type="html"><![CDATA[<p>数据挖掘常遇见的问题，也是<strong>核心问题</strong>：</p><ol><li>如何选择各种分类器，到底选择哪个分类算法？</li><li>如何优化分类器参数，以便得到更好的分类器？</li></ol><p><strong>三个目标</strong>：</p><ol><li>创建各种分类器，包括已经掌握的SVM、决策树、KNN分类器，以及随机森林分类器；</li><li>掌握GridSearchCV工具，优化算法模型的参数；</li><li>使用Pipeline 管道机制进行流水线作业。（数据规范或者数据降维）</li></ol><p>构建<strong>随机森林</strong>分类器<br>  随机森林（Random Forest,简称 RF），他实际是一个包含多个决策树分类器，<br>每个子分类器都是一颗CART分类回归树。所以随机森林既可以做分类也可以做回归任务。做分类时，输出的结果是每个子分类器<br>中分类结果最多的那个；做回归时，输出的结果是每个子分类的任务输出结果的平均值。<br>在sklearn中，使用RandomForestClassifier()构造随机森林模型，常用的参数有：<br><img src="/images/2019/03/14/79bd1cb0-45fd-11e9-9d60-a566f1b35488.png" alt="image.png"></p><p>使用 <strong>GridSearchCV</strong> 工具对模型参数进行调优<br>  GridSearchCV 是Python 的参数自动搜索模块，只要告诉它想要的调优的参数有哪些以及参数的取值范围，<br>它就会把所以的情况都跑一遍，然后告诉我们哪个参数最优，结果如何。<br>GridSearchCV(estimator,param_grid,cv = None,scoring=None)构造参数的自动搜索模块，主要参数说明；</p><p><img src="/images/2019/03/14/fecb8ac0-45ff-11e9-9d60-a566f1b35488.png" alt="image.png"></p><p>简单例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">rf = RandomForestClassifier()</span><br><span class="line">parameters = &#123;&quot;n_estimators&quot;:range(1,11)&#125;</span><br><span class="line">iris = load_iris()</span><br><span class="line">clf = GridSearchCV(estimator=rf,param_grid=parameters,cv =5)</span><br><span class="line">clf.fit(iris.data,iris.target)</span><br><span class="line">print(&quot;最优分数：%.4lf&quot;  %clf.best_score_)</span><br><span class="line">print(&quot;最优参数：&quot;,clf.best_params_)</span><br></pre></td></tr></table></figure></p><p>使用 <strong>Pipeline </strong>管道机制进行流水作业<br>Python 有一种 Pipeline 管道机制。管道机制就是让我们把每一步都按照顺序下来，从而创建Pipeline流水作业。<br>每一步都采用（’名称’，步骤）的方式来表示。</p><p>下面使用Pipeline管道机制，用随机森林对iris数据集做分类任务。先用StandardScaler方法对数据规范化，然后使用随机森林分类：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.model_selection import GridSearchCV</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rf = RandomForestClassifier()</span><br><span class="line">parameters = &#123;&quot;randomforestclassifier__n_estimators&quot;: range(1,11)&#125;</span><br><span class="line">iris = load_iris()</span><br><span class="line">pipeline = Pipeline([</span><br><span class="line">    (&apos;scaler&apos;,StandardScaler()),</span><br><span class="line">    (&apos;randomforestclassifier&apos;,rf)</span><br><span class="line"> ]) </span><br><span class="line"></span><br><span class="line">clf = GridSearchCV(estimator=pipeline,param_grid=parameters)</span><br><span class="line"></span><br><span class="line">clf.fit(iris.data,iris.target)</span><br><span class="line"></span><br><span class="line">print(&quot;最优分数：%.4lf&quot; %clf.best_score_)</span><br><span class="line">print(&quot;最优参数：&quot;,clf.best_params_)</span><br></pre></td></tr></table></figure><p>对信用卡违约率进行分析</p><p>数据来源github上下载即可 ：<a href="https://github.com/cystanford/credit_default" target="_blank" rel="noopener">信用卡违约数据</a><br>这个数据集是台湾某银行05年4月到9月的信用卡数据，数据集一共25个字段，具体含义如下：<br><img src="/images/2019/03/14/d48a1df0-4620-11e9-9d60-a566f1b35488.png" alt="image.png"></p><p>现在针对这个数据集构建一个信用卡违约率分类器。<br>项目的流程如下：<br><img src="/images/2019/03/14/667a0a90-4621-11e9-9d60-a566f1b35488.png" alt="image.png"></p><ol><li>加载数据</li><li>准备阶段：探索数据，采用数据可视化方式可以让我们对数据有更加直观的了解</li><li>分类阶段：之所以把数据规范化放到这个阶段，是因为我们采用了Pipeline 管道机制。而为了找到合适的分类算法以及<br>相适应的分类器参数，需要多试几个分类器以及采用GridSearchCV工具找到最优参数<br>具体代码：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"># 信用卡违约率分析</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.model_selection import learning_curve, train_test_split,GridSearchCV</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">from sklearn.svm import SVC</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">from sklearn.ensemble import RandomForestClassifier</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">import seaborn as sns</span><br><span class="line"># 数据加载</span><br><span class="line">data = data = pd.read_csv(&apos;./UCI_Credit_Card.csv&apos;)</span><br><span class="line"># 数据探索</span><br><span class="line">print(data.shape) # 查看数据集大小</span><br><span class="line">print(data.describe()) # 数据集概览</span><br><span class="line"># 查看下一个月违约率的情况</span><br><span class="line">next_month = data[&apos;default.payment.next.month&apos;].value_counts()</span><br><span class="line">print(next_month)</span><br><span class="line">df = pd.DataFrame(&#123;&apos;default.payment.next.month&apos;: next_month.index,&apos;values&apos;: next_month.values&#125;)</span><br><span class="line">plt.rcParams[&apos;font.sans-serif&apos;]=[&apos;SimHei&apos;] # 用来正常显示中文标签</span><br><span class="line">plt.figure(figsize = (6,6))</span><br><span class="line">plt.title(&apos;信用卡违约率客户\n (违约：1，守约：0)&apos;)</span><br><span class="line">sns.set_color_codes(&quot;pastel&quot;)</span><br><span class="line">sns.barplot(x = &apos;default.payment.next.month&apos;, y=&quot;values&quot;, data=df)</span><br><span class="line">locs, labels = plt.xticks()</span><br><span class="line">plt.show()</span><br><span class="line"># 特征选择，去掉 ID 字段、最后一个结果字段即可</span><br><span class="line">data.drop([&apos;ID&apos;], inplace=True, axis =1) #ID 这个字段没有用</span><br><span class="line">target = data[&apos;default.payment.next.month&apos;].values</span><br><span class="line">columns = data.columns.tolist()</span><br><span class="line">columns.remove(&apos;default.payment.next.month&apos;)</span><br><span class="line">features = data[columns].values</span><br><span class="line"># 30% 作为测试集，其余作为训练集</span><br><span class="line">train_x, test_x, train_y, test_y = train_test_split(features, target, test_size=0.30, stratify = target, random_state = 1)</span><br><span class="line">    </span><br><span class="line"># 构造各种分类器</span><br><span class="line">classifiers = [</span><br><span class="line">    SVC(random_state = 1, kernel = &apos;rbf&apos;),    </span><br><span class="line">    DecisionTreeClassifier(random_state = 1, criterion = &apos;gini&apos;),</span><br><span class="line">    RandomForestClassifier(random_state = 1, criterion = &apos;gini&apos;),</span><br><span class="line">    KNeighborsClassifier(metric = &apos;minkowski&apos;),</span><br><span class="line">]</span><br><span class="line"># 分类器名称</span><br><span class="line">classifier_names = [</span><br><span class="line">            &apos;svc&apos;, </span><br><span class="line">            &apos;decisiontreeclassifier&apos;,</span><br><span class="line">            &apos;randomforestclassifier&apos;,</span><br><span class="line">            &apos;kneighborsclassifier&apos;,</span><br><span class="line">]</span><br><span class="line"># 分类器参数</span><br><span class="line">classifier_param_grid = [</span><br><span class="line">            &#123;&apos;svc__C&apos;:[1], &apos;svc__gamma&apos;:[0.01]&#125;,</span><br><span class="line">            &#123;&apos;decisiontreeclassifier__max_depth&apos;:[6,9,11]&#125;,</span><br><span class="line">            &#123;&apos;randomforestclassifier__n_estimators&apos;:[3,5,6]&#125; ,</span><br><span class="line">            &#123;&apos;kneighborsclassifier__n_neighbors&apos;:[4,6,8]&#125;,</span><br><span class="line">]</span><br><span class="line"> </span><br><span class="line"># 对具体的分类器进行 GridSearchCV 参数调优</span><br><span class="line">def GridSearchCV_work(pipeline, train_x, train_y, test_x, test_y, param_grid, score = &apos;accuracy&apos;):</span><br><span class="line">    response = &#123;&#125;</span><br><span class="line">    gridsearch = GridSearchCV(estimator = pipeline, param_grid = param_grid, scoring = score)</span><br><span class="line">    # 寻找最优的参数 和最优的准确率分数</span><br><span class="line">    search = gridsearch.fit(train_x, train_y)</span><br><span class="line">    print(&quot;GridSearch 最优参数：&quot;, search.best_params_)</span><br><span class="line">    print(&quot;GridSearch 最优分数： %0.4lf&quot; %search.best_score_)</span><br><span class="line">predict_y = gridsearch.predict(test_x)</span><br><span class="line">    print(&quot; 准确率 %0.4lf&quot; %accuracy_score(test_y, predict_y))</span><br><span class="line">    response[&apos;predict_y&apos;] = predict_y</span><br><span class="line">    response[&apos;accuracy_score&apos;] = accuracy_score(test_y,predict_y)</span><br><span class="line">    return response</span><br><span class="line"> </span><br><span class="line">for model, model_name, model_param_grid in zip(classifiers, classifier_names, classifier_param_grid):</span><br><span class="line">    pipeline = Pipeline([</span><br><span class="line">            (&apos;scaler&apos;, StandardScaler()),</span><br><span class="line">            (model_name, model)</span><br><span class="line">    ])</span><br><span class="line">    result = GridSearchCV_work(pipeline, train_x, train_y, test_x, test_y, model_param_grid , score = &apos;accuracy&apos;)</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数据挖掘常遇见的问题，也是&lt;strong&gt;核心问题&lt;/strong&gt;：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如何选择各种分类器，到底选择哪个分类算法？&lt;/li&gt;
&lt;li&gt;如何优化分类器参数，以便得到更好的分类器？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;三个目标&lt;/strong&gt;
      
    
    </summary>
    
      <category term="数据分析" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
    
      <category term="数据分析" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>朴素贝叶斯</title>
    <link href="http://yoursite.com/2019/03/13/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"/>
    <id>http://yoursite.com/2019/03/13/朴素贝叶斯/</id>
    <published>2019-03-13T06:45:42.000Z</published>
    <updated>2019-03-14T01:26:40.085Z</updated>
    
    <content type="html"><![CDATA[<ol><li>使用概率分布进行分类</li><li>学习朴素贝叶斯分类器</li><li>解析RSS源数据</li><li>使用朴素贝叶斯来分析不同地区的态度</li></ol><h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><p>优点：在数据较少的情况下仍然有效，可以处理多类别问题。<br>缺点：对于输入数据的准备方式较为敏感<br>适应数据类型：标称型数据<br>贝叶斯决策理论的核心思想：选择高概率所对应的类别<br>条件概率：</p><p><img src="/images/2019/03/13/7b97ece0-455d-11e9-9d60-a566f1b35488.png" alt="image.png"></p><h3 id="朴素贝叶斯文档分类应用"><a href="#朴素贝叶斯文档分类应用" class="headerlink" title="朴素贝叶斯文档分类应用"></a>朴素贝叶斯文档分类应用</h3><p>一般过程</p><ol><li>收集数据</li><li>准备数据：需要数值型或者布尔型数据</li><li>分析数据：在有大量特征时，绘制特征作用不大，此时使用直方图效果更好</li><li>训练算法：计算不同的独立特征的条件概率</li><li>测试算法：计算错误率</li><li>使用算法：一个常见的朴素贝叶斯应用是文档分类。</li></ol><p>程序清单 1 ： 词表到向量的转换函数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def loadDataSet():</span><br><span class="line">postingList = [[&apos;my&apos;,&apos;dog&apos;,&apos;has&apos;,&apos;flea&apos;,\</span><br><span class="line">&apos;problems&apos;,&apos;help&apos;,&apos;please&apos;],</span><br><span class="line">[&apos;maybe&apos;,&apos;not&apos;,&apos;take&apos;,&apos;him&apos;,\</span><br><span class="line">&apos;I&apos;,&apos;love&apos;,&apos;him&apos;]]</span><br><span class="line">classVec = [0,1] # 1代表有侮辱性文字，0代表正常言论</span><br><span class="line">return postingList,classVec</span><br><span class="line"></span><br><span class="line">def createVocabList(dataSet):</span><br><span class="line">vocabSet = set([])</span><br><span class="line">for document in dataSet:</span><br><span class="line">vocabSet = vocabSet | set(document)</span><br><span class="line">return list(vocabSet)</span><br><span class="line"></span><br><span class="line">def setOfWords2Vec(vocabList,inputSet):</span><br><span class="line">returnVec = [0]*len(vocabList)</span><br><span class="line">for word in inputSet:</span><br><span class="line">if word in vocabList:</span><br><span class="line">returnVec[vocabList.index(word)] = 1</span><br><span class="line">else:print &quot;the Word : %s is not in my Vocabulary!&quot; % word</span><br><span class="line">return returnVec</span><br></pre></td></tr></table></figure><h4 id="训练算法"><a href="#训练算法" class="headerlink" title="训练算法"></a>训练算法</h4><p>函数伪代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">计算每个类别中的文档数目</span><br><span class="line">对每篇训练文档：</span><br><span class="line">对每个类别：</span><br><span class="line">如果词条出现文档中 --&gt; 增加该词条的计数值</span><br><span class="line">增加所有词条的计数值</span><br><span class="line">对每个类别：</span><br><span class="line">对每个词条：</span><br><span class="line">将该词条的数目除以总词条数目得到条件概率</span><br><span class="line">返回每个类别的条件概率</span><br></pre></td></tr></table></figure></p><p>程序清单2 朴素贝叶斯分类器训练函数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">def trainNB0(trainMatrix,trainCategory):</span><br><span class="line"># 初始化概率</span><br><span class="line">numTrainDocs = len(trainMatrix)</span><br><span class="line">numWords = len(trainMatrix[0])</span><br><span class="line">pAbusive = sum(trainCategory)/float(numTrainDocs)</span><br><span class="line">p0Num = zeros(numWords);plNum = zeros(numWords)</span><br><span class="line">p0Denom = 0.0;plDenom = 0.0</span><br><span class="line"># 向量相加</span><br><span class="line">for i in range(numTrainDocs):</span><br><span class="line">if trainCategory[i] ==1;</span><br><span class="line">p1Num += trainMatrix[i]</span><br><span class="line">p1Denom += sum(trainMatrix[i])</span><br><span class="line">else:</span><br><span class="line">p0Num += trainMatrix[i]</span><br><span class="line">p0Denom += sum(trainMatrix[i])</span><br><span class="line">p1Vect = p1Num/p1Denom</span><br><span class="line">p0Vect = p0Num/p0Denom</span><br><span class="line">return p0Vect,p1Vect,pAbusive</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;使用概率分布进行分类&lt;/li&gt;
&lt;li&gt;学习朴素贝叶斯分类器&lt;/li&gt;
&lt;li&gt;解析RSS源数据&lt;/li&gt;
&lt;li&gt;使用朴素贝叶斯来分析不同地区的态度&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;朴素贝叶斯&quot;&gt;&lt;a href=&quot;#朴素贝叶斯&quot; class=&quot;heade
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>neo4j 连接 spark</title>
    <link href="http://yoursite.com/2019/03/11/neo4j-%E8%BF%9E%E6%8E%A5-spark/"/>
    <id>http://yoursite.com/2019/03/11/neo4j-连接-spark/</id>
    <published>2019-03-11T01:29:30.000Z</published>
    <updated>2019-03-11T01:32:45.352Z</updated>
    
    <content type="html"><![CDATA[<p>今天使用neo4j连接spark<br>neo4j版本3.4<br>spark版本1.6.0</p><blockquote><p>(1) 首先，需要添加jar包 neo4j-spark-connector_2.10-1.0.0-RC1.jar或者添加maven依赖<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">org.neo4j.spark    </span><br><span class="line">neo4j-spark-connector_2.10  </span><br><span class="line">1.0.0-RC1</span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>(2) 设置spark连接信息<br>val  conf : SparkConf = new SparkConf().setAppName(“InitSpark”).setMaster(“local[*]”)       conf.set(“spark.neo4j.bolt.url”,”bolt://localhost:7687”)<br>conf.set(“spark.neo4j.bolt.user”,”neo4j”)<br>conf.set(“spark.neo4j.bolt.password”,”123456”)</p></blockquote><blockquote></blockquote><p>简单例子</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">object Neo4jDataFrameTest &#123; </span><br><span class="line"> def main(args: Array[String]): Unit = &#123;      </span><br><span class="line">val sQLContext = InitSpark.getSqlContext   </span><br><span class="line">val query =&quot; MATCH p=(m:ITEM)&lt;-[r:rel*]-(n:ITEM) where m.item = &apos;84010420&apos; and  ALL(c in r where c.exdt&gt;&apos;2018-12-15&apos;)&quot; +  &quot; with  m.item as mark,length(r) as len, last(r).number as num,reduce(s=1.0 ,x in rels(p)| s*tofloat(x.number)) as nums, last(r).mitem as mitem , last(r) as bom  &quot; +  &quot; return  mark,bom.erpid as erpid, bom.virtual as virtual,mitem,bom.item as item,bom.pono as pono,&quot; +  &quot; bom.comment as comment, bom.warehouse as warehouse, bom.exdt as exdt, bom.indt as indt,tofloat(num) as num,nums,len &quot;   </span><br><span class="line">val df = Neo4jDataFrame.withDataType(sQLContext,query,Seq.empty,&quot;mark&quot; -&gt;    StringType,&quot;erpid&quot; -&gt;StringType,&quot;virtual&quot;-&gt;LongType,  &quot;mitem&quot;-&gt;StringType,&quot;item&quot;-&gt;StringType,&quot;pono&quot;-&gt;LongType,&quot;comment&quot;-&gt;StringType,&quot;warehouse&quot;-&gt;StringType,&quot;exdt&quot;-&gt;StringType,  &quot;indt&quot; -&gt;StringType,&quot;num&quot;-&gt;DoubleType,&quot;nums&quot;-&gt; DoubleType ,&quot;len&quot;-&gt;LongType)    </span><br><span class="line">df.show(1000)  &#125;&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">object Neo4jConnectSparkGraph &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">     val sc = InitSpark.getSC</span><br><span class="line">     val sQLContext = InitSpark.getSqlContext</span><br><span class="line">     val cypher = &quot;match (n:ITEM) return n.item limit 10&quot;</span><br><span class="line">     val neo = Neo4jRowRDD(sc,cypher)</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;今天使用neo4j连接spark&lt;br&gt;neo4j版本3.4&lt;br&gt;spark版本1.6.0&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;(1) 首先，需要添加jar包 neo4j-spark-connector_2.10-1.0.0-RC1.jar或者添加maven依赖&lt;br
      
    
    </summary>
    
      <category term="图数据库" scheme="http://yoursite.com/categories/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="neo4j" scheme="http://yoursite.com/tags/neo4j/"/>
    
  </entry>
  
  <entry>
    <title>18| 决策树（中） : CART算法笔记</title>
    <link href="http://yoursite.com/2019/03/07/18-%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88%E4%B8%AD%EF%BC%89-CART%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2019/03/07/18-决策树（中）-CART算法笔记/</id>
    <published>2019-03-07T01:16:53.000Z</published>
    <updated>2019-03-07T02:45:30.239Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/2019/03/07/95366780-4076-11e9-8a4c-37398b64114f.png" alt="image.png"></p><h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><blockquote><p>基于信息度量的不同方式，我们把决策树分为ID3算法、C4.5算法和CART算法。CART算法（Classification And Regression Tree）,<br>又称分类回归树。也就是说CART决策树既可以作为分类树，又可以作为回归树。而且CART只支持二叉树。<br>分类树和回归树的区别<br>分类树可以处理离散数据，也就是数据种类有限的数据，它输出的是样本类别，而回归树可以对连续型的数值进行预测<br>也就是数据在某个区间都有取值的可能，它输出的是一个数值。</p></blockquote><h2 id="CART分类树工作流程"><a href="#CART分类树工作流程" class="headerlink" title="CART分类树工作流程"></a>CART分类树工作流程</h2><p>在属性选择上CART算法采用基尼系数作为衡量指标。</p><blockquote><p>假设t为节点，那么该节点是GINI系数为：<br><img src="/images/2019/03/07/4fe1cf50-4079-11e9-8a4c-37398b64114f.png" alt="image.png"><br>其中p(Ck|t)表示节点t属于类别Ck的概率，节点t的基尼系数为1减去个类别Ck概率平方和。<br>在CART算法中，基于基尼系数对特征属性进行二元分裂，假设属性A将节点D划分为D1和D2，如下图所示：<br><img src="/images/2019/03/07/d4b50920-407b-11e9-8a4c-37398b64114f.png" alt="image.png"><br>那么节点D的基尼系数等于子节点D1和D2的归一化基尼系数之和，用公式表示为：<br><img src="/images/2019/03/07/0e9e5290-407c-11e9-8a4c-37398b64114f.png" alt="image.png"><br>归一化基尼系数代表的是每个子节点的基尼系数乘以该节点占整体父节点D中的比例。节点D被属性A划分后基尼系数越大，样本集合的<br>不确定性越大，也就是不纯度越高。</p></blockquote><h2 id="如何使用CART算法来创建分类树"><a href="#如何使用CART算法来创建分类树" class="headerlink" title="如何使用CART算法来创建分类树"></a>如何使用CART算法来创建分类树</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"># encoding=utf-8</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">from sklearn.tree import DecisionTreeClassifier</span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line"># 准备数据集</span><br><span class="line">iris=load_iris()</span><br><span class="line"># 获取特征集和分类标识</span><br><span class="line">features = iris.data</span><br><span class="line">labels = iris.target</span><br><span class="line"># 随机抽取 33% 的数据作为测试集，其余为训练集</span><br><span class="line">train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)</span><br><span class="line"># 创建 CART 分类树</span><br><span class="line">clf = DecisionTreeClassifier(criterion=&apos;gini&apos;)</span><br><span class="line"># 拟合构造 CART 分类树</span><br><span class="line">clf = clf.fit(train_features, train_labels)</span><br><span class="line"># 用 CART 分类树做预测</span><br><span class="line">test_predict = clf.predict(test_features)</span><br><span class="line"># 预测结果与测试集结果作比对</span><br><span class="line">score = accuracy_score(test_labels, test_predict)</span><br><span class="line">print(&quot;CART 分类树准确率 %.4lf&quot; % score)</span><br></pre></td></tr></table></figure><h2 id="CART回归树工作流程"><a href="#CART回归树工作流程" class="headerlink" title="CART回归树工作流程"></a>CART回归树工作流程</h2><blockquote><p>在CART回归树中，通过样本的混乱程度，也就是样本的离散程度来评价“不纯度”。<br>设x为样本的个体，均值为u。可以通过取差值的绝对值或者方差来评价。<br>差值绝对值：<br><img src="/images/2019/03/07/ee8fa8c0-407e-11e9-8a4c-37398b64114f.png" alt="image.png"><br>方差：<br><img src="/images/2019/03/07/096e0420-407f-11e9-8a4c-37398b64114f.png" alt="image.png"><br>以上两种节点划分标准，分别对应着两种目标函数最优化的标准。最小绝对偏差（LAD）和最小二乘偏差（LSD）。</p></blockquote><h2 id="CART回归树预测"><a href="#CART回归树预测" class="headerlink" title="CART回归树预测"></a>CART回归树预测</h2><p>例子：波士顿房价预测<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># encoding=utf-8</span><br><span class="line">from sklearn.metrics import mean_squared_error</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.datasets import load_boston</span><br><span class="line">from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error</span><br><span class="line">from sklearn.tree import DecisionTreeRegressor</span><br><span class="line"># 准备数据集</span><br><span class="line">boston=load_boston()</span><br><span class="line"># 探索数据</span><br><span class="line">print(boston.feature_names)</span><br><span class="line"># 获取特征集和房价</span><br><span class="line">features = boston.data</span><br><span class="line">prices = boston.target</span><br><span class="line"># 随机抽取 33% 的数据作为测试集，其余为训练集</span><br><span class="line">train_features, test_features, train_price, test_price = train_test_split(features, prices, test_size=0.33)</span><br><span class="line"># 创建 CART 回归树</span><br><span class="line">dtr=DecisionTreeRegressor()</span><br><span class="line"># 拟合构造 CART 回归树</span><br><span class="line">dtr.fit(train_features, train_price)</span><br><span class="line"># 预测测试集中的房价</span><br><span class="line">predict_price = dtr.predict(test_features)</span><br><span class="line"># 测试集的结果评价</span><br><span class="line">print(&apos;回归树二乘偏差均值:&apos;, mean_squared_error(test_price, predict_price))</span><br><span class="line">print(&apos;回归树绝对值偏差均值:&apos;, mean_absolute_error(test_price, predict_price))</span><br></pre></td></tr></table></figure></p><h2 id="CART决策树的剪枝"><a href="#CART决策树的剪枝" class="headerlink" title="CART决策树的剪枝"></a>CART决策树的剪枝</h2><p>CART决策树的剪枝主要采用的是CCP（cost-complexity prune）方法,又称代价复杂度。这种剪枝方式采用了节点的表面误差率增益值作为评估：<br><img src="/images/2019/03/07/7d6460c0-4081-11e9-8a4c-37398b64114f.png" alt="image.png"><br>其中Tt代表以t为根节点的子树，C(Tt)表示节点t的子树没被裁剪时子树Tt的误差，C(t)表示节点t的子树被裁剪时节点t的误差，|Tt|代表子树Tt的叶子树，剪枝后，T的叶子数减少了|Tt|-1。<br>所以节点的表面误差率增益值等于节点t的子树被剪枝后的误差变化除以减掉的叶子数量。</p><p><img src="/images/2019/03/07/ce361dd0-4082-11e9-8a4c-37398b64114f.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/2019/03/07/95366780-4076-11e9-8a4c-37398b64114f.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink
      
    
    </summary>
    
      <category term="决策树" scheme="http://yoursite.com/categories/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/categories/%E5%86%B3%E7%AD%96%E6%A0%91/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
    
      <category term="决策树" scheme="http://yoursite.com/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>03 数据分析实战45 ： Python 基础语法</title>
    <link href="http://yoursite.com/2019/03/01/03-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%9845-%EF%BC%9A-Python-%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95/"/>
    <id>http://yoursite.com/2019/03/01/03-数据分析实战45-：-Python-基础语法/</id>
    <published>2019-03-01T02:37:48.000Z</published>
    <updated>2019-03-01T02:50:10.942Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/2019/03/01/66ec2200-3bc8-11e9-9d0c-09e85593a38e.png" alt="image.png"></p><h1 id="Python-基础语法"><a href="#Python-基础语法" class="headerlink" title="Python 基础语法"></a>Python 基础语法</h1><h2 id="Python-语言特点"><a href="#Python-语言特点" class="headerlink" title="Python 语言特点"></a>Python 语言特点</h2><blockquote><p>Python 语言最大的优点就是简洁，同时有大量的第三方库，功能强大，能够解决数据分析的大部分问题。比如科学计算工具NumPy 和 Pandas库，深度学习工具 Keras 和 TensorFlow,以及机器学习工具 Scikit-learn。</p></blockquote><h2 id="安装及-IDE-环境"><a href="#安装及-IDE-环境" class="headerlink" title="安装及 IDE 环境"></a>安装及 IDE 环境</h2><p>安装Python 3.x 官网下载安装。<br>Python IDE 推荐使用 PythonCharm</p><h2 id="Python-基础语法-1"><a href="#Python-基础语法-1" class="headerlink" title="Python 基础语法"></a>Python 基础语法</h2><h3 id="输入输出"><a href="#输入输出" class="headerlink" title="输入输出"></a>输入输出</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sum = 100+100</span><br><span class="line">print (&apos;hello,%s&apos; %name) # 打印输出</span><br><span class="line">print (&apos;sum = %d&apos; %sum)</span><br></pre></td></tr></table></figure><h3 id="判断语句-if-…-else-…"><a href="#判断语句-if-…-else-…" class="headerlink" title="判断语句 if … else …"></a>判断语句 if … else …</h3><figure class="highlight plain"><figcaption><span>score></span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">       print (&apos;Excellent&apos;)</span><br><span class="line">else:</span><br><span class="line">       if score &lt; 60:</span><br><span class="line">           print( &apos;Fail&apos;)</span><br><span class="line">       else:</span><br><span class="line">           print (&apos;Good Job&apos;)</span><br></pre></td></tr></table></figure><h3 id="循环语句-：-for-…-in"><a href="#循环语句-：-for-…-in" class="headerlink" title="循环语句 ： for … in"></a>循环语句 ： for … in</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for number in range(11):</span><br><span class="line">    sum = sum + number</span><br><span class="line">print (sum)</span><br></pre></td></tr></table></figure><h3 id="循环语句：while"><a href="#循环语句：while" class="headerlink" title="循环语句：while"></a>循环语句：while</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">number = 1</span><br><span class="line">while number &lt; 11:</span><br><span class="line">       sum = sum + number</span><br><span class="line">       number = number + 1</span><br><span class="line">print （sum）</span><br></pre></td></tr></table></figure><h2 id="数据类型：列表、元组、字典、集合"><a href="#数据类型：列表、元组、字典、集合" class="headerlink" title="数据类型：列表、元组、字典、集合"></a>数据类型：列表、元组、字典、集合</h2><h3 id="列表："><a href="#列表：" class="headerlink" title="列表：[]"></a>列表：[]</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lists.append(&apos;d&apos;)</span><br><span class="line">print (lists)</span><br><span class="line">print (len(lists))</span><br><span class="line">lists.insert(0,&apos;mm&apos;)</span><br><span class="line">lists.pop()</span><br><span class="line">print (lists)</span><br></pre></td></tr></table></figure><h3 id="元组（tuple）"><a href="#元组（tuple）" class="headerlink" title="元组（tuple）"></a>元组（tuple）</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print (tuples[0])</span><br></pre></td></tr></table></figure><h3 id="字典（dictionary）"><a href="#字典（dictionary）" class="headerlink" title="字典（dictionary）"></a>字典（dictionary）</h3><figure class="highlight plain"><figcaption><span>-*- coding: utf-8 -*</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 定义一个 dictionary</span><br><span class="line">score = &#123;&apos;guanyu&apos;:95,&apos;zhangfei&apos;:96&#125;</span><br><span class="line"># 添加一个元素</span><br><span class="line">score[&apos;zhaoyun&apos;] = 98</span><br><span class="line">print (score)</span><br><span class="line"># 删除一个元素</span><br><span class="line">score.pop(&apos;zhangfei&apos;)</span><br><span class="line"># 查看 key 是否存在</span><br><span class="line">print (&apos;guanyu&apos; in score)</span><br><span class="line"># 查看一个 key 对应的值</span><br><span class="line">print (score.get(&apos;guanyu&apos;))</span><br><span class="line">print (score.get(&apos;yase&apos;,99))</span><br></pre></td></tr></table></figure><h3 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">s.add(&apos;d&apos;)</span><br><span class="line">s.remove(&apos;b&apos;)</span><br><span class="line">print （s）</span><br><span class="line">print （&apos;c&apos; in s）</span><br></pre></td></tr></table></figure><p><img src="/images/2019/03/01/9d1f4470-3bcc-11e9-9d0c-09e85593a38e.png" alt="image.png"></p><p><img src="/images/2019/03/01/a812ead0-3bcc-11e9-9d0c-09e85593a38e.jpg" alt="1550939818393.jpg"><br>极客时间版权所有: <a href="https://time.geekbang.org/column/article/73574" target="_blank" rel="noopener">https://time.geekbang.org/column/article/73574</a></p><p>极客时间版权所有: <a href="https://time.geekbang.org/column/article/73574" target="_blank" rel="noopener">https://time.geekbang.org/column/article/73574</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/2019/03/01/66ec2200-3bc8-11e9-9d0c-09e85593a38e.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;h1 id=&quot;Python-基础语法&quot;&gt;&lt;a href=&quot;#Python-基础语法&quot; c
      
    
    </summary>
    
      <category term="数据分析" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="python" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/python/"/>
    
    
      <category term="数据分析" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>17-数据分析实战笔记： 决策树</title>
    <link href="http://yoursite.com/2019/02/23/17-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0%EF%BC%9A-%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    <id>http://yoursite.com/2019/02/23/17-数据分析实战笔记：-决策树/</id>
    <published>2019-02-23T06:16:23.000Z</published>
    <updated>2019-03-13T06:40:25.978Z</updated>
    
    <content type="html"><![CDATA[<h1 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h1><h2 id="决策树的工作原理"><a href="#决策树的工作原理" class="headerlink" title="决策树的工作原理"></a>决策树的工作<strong>原理</strong></h2><blockquote><p>  在现实生活，我们做的各种决策，都是基于以往的经验来判断的。如果将背后的逻辑整理成一个结构图，这实际上就是决策树。<br><img src="/images/2019/02/23/4dbc8110-3733-11e9-928d-e15e87e90364.png" alt="image.png"><br>上图就是一个典型的决策树。而在实现决策树时会经历两个阶段：<strong>构造和剪枝。</strong></p></blockquote><h2 id="决策树的构造"><a href="#决策树的构造" class="headerlink" title="决策树的构造"></a>决策树的构造</h2><p>优点：计算复杂度不高，输出结果易于理解，对中间值的确失不敏感，可以处理不相干特征数据<br>缺点：易发生过拟合<br>适用数据类型：数值型和标称型<br>创建分支的伪代码函数createBranch()如下所示：<br>检测数据集中的每个子项是否属于同一类：</p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">If so return 类标签：</span><br><span class="line">Else</span><br><span class="line">寻找划分数据集的最好特征</span><br><span class="line">划分数据集</span><br><span class="line">创建分支节点</span><br><span class="line">for 每个划分的子集</span><br><span class="line">    调用函数createBranch并增加返回结果到分支节点中</span><br><span class="line">        return 分支节点</span><br></pre></td></tr></table></figure><h3 id="构造"><a href="#构造" class="headerlink" title="构造"></a>构造</h3><blockquote><p>构造的过程就是选择什么样的属性作为节点的过程，一般在构造中存在三种类型的节点：<br>1.根节点：树的顶端，最开始的那个节点<br>2.内部节点：树的中间节点<br>3.叶节点：树最底部的节点，也是决策树结果</p></blockquote><p>构造过程中，需要解决的三个重要问题：<br>1.选择哪个属性作为根节点；<br>2.选择哪些属性作为子节点；<br>3.什么时候停止并得到目标状态，即叶子节点。</p><h2 id="决策树的一般流程"><a href="#决策树的一般流程" class="headerlink" title="决策树的一般流程"></a>决策树的一般流程</h2><blockquote><p>（1）收集数据：可以使用任何方法<br>（2）准备数据：树构造算法只适应于标称型数据，因此数值型数据必须离散化<br>（3）分析数据：可以适应任何方法，构造树完成之后，我们应该检查图形是否符合预期。<br>（4）训练算法：构造树的数据结构<br>（5）测试算法：使用经验树计算错误率。<br>（6）使用算法：此步骤可以适应于任何监督学习算法，而使用决策树可以更好的理解数据的含义</p></blockquote><h2 id="信息增益"><a href="#信息增益" class="headerlink" title="信息增益"></a>信息增益</h2><pre><code>划分数据集的最大原则：将无序的数据变得更加有序。在划分数据集前后的信息变化称之为信息增益，而我们可以计算每个特征值划分收获的信息增益，获得信息增益最高</code></pre><p>的特征就是最好的选择。<br>    熵定义为信息的期望值。如果待分类的事务可能划分在多个分类之中，则xi的信息定义为：<br>            <img src="/images/2019/03/13/ed1fe490-453e-11e9-9d60-a566f1b35488.png" alt="image.png"><br>为了计算熵，需要计算所有类别可能包含的信息期望值：<br><img src="/images/2019/03/13/2fda6990-453f-11e9-9d60-a566f1b35488.png" alt="image.png"></p><p>程序清单1 计算给定数据集的香农熵<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from math import log</span><br><span class="line">def calcShannonEnt(dataSet):</span><br><span class="line">numEntries = len(dataSet)</span><br><span class="line">labelCounts = &#123;&#125;</span><br><span class="line">#为所有可能的分类创建字典</span><br><span class="line">for featVec in dataSet:</span><br><span class="line">currentLabel = featVec[-1]</span><br><span class="line">if currentLabel not in labelCounts.keys():</span><br><span class="line">labelCounts[currentLabel] = 0</span><br><span class="line">labelCounts[currentLabel] += 1</span><br><span class="line">shannonEnt = 0.0</span><br><span class="line"># 计算信息期望</span><br><span class="line">for key in labelCounts:</span><br><span class="line">prob = float(labelCounts[key])/numEntries</span><br><span class="line">shannonEnt -= prob*log(prob,2)</span><br><span class="line">return shannonEnt</span><br></pre></td></tr></table></figure></p><p>程序清单2 按照给定的特征划分数据集<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">def splitDataSet(dataSet,axis,value):</span><br><span class="line">retDataSet = []</span><br><span class="line">for featVec in dataSet:</span><br><span class="line">if featVec[axis] == value：</span><br><span class="line">reduceFeatVec = featVec[:axis]</span><br><span class="line">reduceFeatVec.extend(featVec[axis+1:])</span><br><span class="line">retDataSet.append(reducedFeatVec)</span><br><span class="line">return retDataSet</span><br></pre></td></tr></table></figure></p><h3 id="剪枝"><a href="#剪枝" class="headerlink" title="剪枝"></a>剪枝</h3><blockquote><p>剪枝就是给决策树瘦身。也即不需要过多的判断也能得到不错的结果。主要是为了防止“过拟合（Overfitting）”现象的发生。<br>过拟合现象会导致得到的模型虽然训练结果好，但是泛化能力差。<br>剪枝一般分为两种：“预剪枝”（Pre-Pruning）和“后剪枝”（Post-Pruning）</p></blockquote><p><img src="/images/2019/02/23/98412a80-3736-11e9-928d-e15e87e90364.png" alt="image.png"></p><p><img src="/images/2019/03/01/bc0ba040-3bc7-11e9-9d0c-09e85593a38e.jpg" alt="1550939818393.jpg"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;决策树&quot;&gt;&lt;a href=&quot;#决策树&quot; class=&quot;headerlink&quot; title=&quot;决策树&quot;&gt;&lt;/a&gt;决策树&lt;/h1&gt;&lt;h2 id=&quot;决策树的工作原理&quot;&gt;&lt;a href=&quot;#决策树的工作原理&quot; class=&quot;headerlink&quot; title=&quot;决策树的工
      
    
    </summary>
    
      <category term="决策树" scheme="http://yoursite.com/categories/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
    
      <category term="决策树" scheme="http://yoursite.com/tags/%E5%86%B3%E7%AD%96%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>02 数据分析实战笔记--学习数据挖掘的最佳路径</title>
    <link href="http://yoursite.com/2019/02/18/02-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%AE%9E%E6%88%98%E7%AC%94%E8%AE%B0-%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E6%9C%80%E4%BD%B3%E8%B7%AF%E5%BE%84/"/>
    <id>http://yoursite.com/2019/02/18/02-数据分析实战笔记-学习数据挖掘的最佳路径/</id>
    <published>2019-02-18T14:26:38.000Z</published>
    <updated>2019-02-22T05:59:14.544Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/2019/02/22/dc70e0e0-3666-11e9-8304-57f818b3fae9.png" alt="image.png"><br><strong>数据挖掘的基本流程（六大步骤）</strong>：<br>1、商业理解：先从商业的角度理解项目的需求，然后再对数据挖掘的目标进行定义。<br>2、数据理解：尝试收集部分数据，然后对数据进行探索，包括数据描述、数据质量验证<br>3、数据准备：收集数据，并对数据进行清洗、数据集成等操作<br>4、模型建立：选择和应用各种数据挖掘模型，并进行优化<br>5、模型评估：对模型进行评价，并检查构建模型的每个步骤，确认模型是否实现预定的商业目标<br>6、上线发布：项目只有落地实施才能体现价值。当然后序还需要一定的日常运维。</p><p><strong>数据挖掘的十大算法</strong><br>按照不同的目的，算法主要分为四类：<br>|分类算法：C4.5,朴素贝叶斯（Naive Bayes）,SVM,KNN,Adaboost,CART<br>|聚类算法：K-Means,EM<br>|关联分析：Apriori<br>|连接分析：PageRank</p><p><strong>数据挖掘的数学原理</strong></p><p>1、概率论与数理统计<br>2、线性代数<br>3、图论<br>4、最优化方法</p><p><img src="/images/2019/02/22/ec89f8e0-3666-11e9-8304-57f818b3fae9.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/2019/02/22/dc70e0e0-3666-11e9-8304-57f818b3fae9.png&quot; alt=&quot;image.png&quot;&gt;&lt;br&gt;&lt;strong&gt;数据挖掘的基本流程（六大步骤）&lt;/strong&gt;：&lt;br&gt;1、商业理解：先从
      
    
    </summary>
    
      <category term="数据分析" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
      <category term="数据挖掘" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/"/>
    
    
      <category term="数据分析" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>修炼指南</title>
    <link href="http://yoursite.com/2019/02/18/%E4%BF%AE%E7%82%BC%E6%8C%87%E5%8D%97/"/>
    <id>http://yoursite.com/2019/02/18/修炼指南/</id>
    <published>2019-02-18T14:04:46.000Z</published>
    <updated>2019-02-22T05:57:28.340Z</updated>
    
    <content type="html"><![CDATA[<p><strong>MAS学习法</strong></p><p>认知：我们只有把知识转化为自己的语言，它才真正编程我们自己的东西。这个转换的过程就叫做认知的过程。<br><img src="/images/2019/02/22/ab30d8a0-3666-11e9-8304-57f818b3fae9.png" alt="image.png"><br>如何提高我们的学习吸收能力，就要做到知行合一。如果说认知是大脑，那么工具就是我们的双手。所以我们需要把握两点原则:</p><p>1、不要重复造轮子<br>   也即尽量选择已有的第三方工具来完成我们的项目，因为大部分的业务场景都能找到相关的工具来解决，这样既省时又省力。<br>2、工具决定效率<br>   在工作中选择工具的原则是选择使用者最多的工具。因为：Bug少、文档全、案例多。同时找到适合的工具，这样就能大大提高我们的工作效率。</p><p>选择好工具后就需要大量的积累。一般而言，我们很难记住大段的知识和相关指令。但是我们能够记住自己曾经做过的相关的项目，题目和故事。这就需要多练，练熟练透它。正所谓熟能生巧。量变引起质变。</p><p><strong>总结一下几点</strong></p><p>1、记录下自己每天的认知<br>2、这些认知对应工具的那些操作<br>3、勤加练习，巩固知识。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;MAS学习法&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;认知：我们只有把知识转化为自己的语言，它才真正编程我们自己的东西。这个转换的过程就叫做认知的过程。&lt;br&gt;&lt;img src=&quot;/images/2019/02/22/ab30d8a0-3666-11e9-8304-
      
    
    </summary>
    
      <category term="数据分析" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="数据分析" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>数据分析全景图笔记</title>
    <link href="http://yoursite.com/2019/02/18/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%85%A8%E6%99%AF%E5%9B%BE%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2019/02/18/数据分析全景图笔记/</id>
    <published>2019-02-18T06:29:35.000Z</published>
    <updated>2019-02-19T00:48:28.981Z</updated>
    
    <content type="html"><![CDATA[<p>数据分析的<strong>三个</strong>重要组成部分：</p><pre><code>1、数据采集。（源头）2、数据挖掘。（核心，主要是挖掘数据的商业价值）3、数据可视化。（直观感受数据分析结果）</code></pre><p><img src="/images/2019/02/18/45a3d120-3343-11e9-b0b3-2d63e1557176.png" alt="image.png"></p><p><strong>数据采集</strong></p><pre><code>主要是各种各样的数据源打交道，然后使用不用的工具来进行采集。</code></pre><p><img src="/images/2019/02/18/0f33da80-3344-11e9-b0b3-2d63e1557176.png" alt="image.png"></p><p><strong>数据挖掘</strong></p><pre><code>第二部分主要熟悉数据挖掘的基本流程、十大算法、以及背后的数学基础。</code></pre><p><img src="/images/2019/02/18/d1c7dd80-3344-11e9-b0b3-2d63e1557176.png" alt="image.png"></p><p><strong>数据可视化</strong></p><pre><code>数据可视化可以帮我们很好的理解数据的结构，以及分析结果的呈现。主要有两种方法实现数据的可视化。第一种就是使用Python。在Python对数据进行清洗、挖掘的过程中，可以使用Matplotlib,Seaborn等第三方库进行呈现。第二种就是使用第三方工具。若已经生成了csv文件，想采用所见即所得的方式呈现，可以采用微图、DataV、Data GIF Maker等第三方工具。</code></pre><p><img src="/images/2019/02/18/b23122d0-3347-11e9-b0b3-2d63e1557176.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;数据分析的&lt;strong&gt;三个&lt;/strong&gt;重要组成部分：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;1、数据采集。（源头）
2、数据挖掘。（核心，主要是挖掘数据的商业价值）
3、数据可视化。（直观感受数据分析结果）
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;/image
      
    
    </summary>
    
      <category term="数据分析" scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
    
      <category term="数据分析" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>jupyter 安装</title>
    <link href="http://yoursite.com/2019/01/21/jupyter-%E5%AE%89%E8%A3%85/"/>
    <id>http://yoursite.com/2019/01/21/jupyter-安装/</id>
    <published>2019-01-21T01:11:39.000Z</published>
    <updated>2019-02-22T02:54:25.057Z</updated>
    
    <content type="html"><![CDATA[<p>选择管理员运行cmd,执行以下命令：</p><pre><code>pip install jupyter   </code></pre><p>进入目录 C:\Program Files\Python37\Scripts&gt;，运行命令：</p><pre><code>cd C:\Program Files\Python37\Scripts             jupyter notebook</code></pre><p>注意管理员权限问题。</p><pre><code>http://localhost:8888/tree</code></pre><p>第三方库numpy安装 </p><pre><code>pip install numpypip install -U scikit-learnpip install -U pandasqlpip install graphvizpip install pydotplus</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;选择管理员运行cmd,执行以下命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install jupyter   
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;进入目录 C:\Program Files\Python37\Scripts&amp;gt;，运行命令：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
      
    
    </summary>
    
      <category term="python" scheme="http://yoursite.com/categories/python/"/>
    
    
      <category term="python" scheme="http://yoursite.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>学习笔记</title>
    <link href="http://yoursite.com/2019/01/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2019/01/18/学习笔记/</id>
    <published>2019-01-18T08:56:37.000Z</published>
    <updated>2019-01-18T08:56:37.581Z</updated>
    
    <content type="html"><![CDATA[<p>chcp    查看windows系统编码格式</p><p>chcp 65001   将Windows格式编码设为utf-8模式</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;chcp    查看windows系统编码格式&lt;/p&gt;
&lt;p&gt;chcp 65001   将Windows格式编码设为utf-8模式&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>kylin jdbc 连接</title>
    <link href="http://yoursite.com/2019/01/18/kylin-jdbc-%E8%BF%9E%E6%8E%A5/"/>
    <id>http://yoursite.com/2019/01/18/kylin-jdbc-连接/</id>
    <published>2019-01-18T01:13:24.000Z</published>
    <updated>2019-02-19T02:53:03.689Z</updated>
    
    <content type="html"><![CDATA[<p>kylin jdbc 连接</p><p>一 、kylin 简介</p><pre><code>Kylin是ebay开发的一套OLAP系统，与Mondrian不同的是，它是一个MOLAP系统，主要用于支持大数据生态圈的数据分析业务，它主要是通过预计算的方式将用户设定的多维立方体缓存到HBase中。</code></pre><p>二、引入pom文件</p><pre><code>&lt;dependency&gt;    &lt;groupId&gt;org.apache.kylin&lt;/groupId&gt;    &lt;artifactId&gt;kylin-jdbc&lt;/artifactId&gt;    &lt;version&gt;1.6.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><p>三 、例子</p><pre><code>import org.apache.kylin.jdbc.Driver;import org.datanucleus.state.LifeCycleState;import java.sql.Connection;import java.sql.ResultSet;import java.sql.Statement;import java.util.ArrayList;import java.util.List;import java.util.Properties;public class KylinJdbc {    public static void main(String[] args) throws Exception {        Driver driver = (Driver) Class.forName(&quot;org.apache.kylin.jdbc.Driver&quot;).newInstance();        Properties info = new Properties();info.put(&quot;user&quot;, &quot;BI&quot;);info.put(&quot;password&quot;, &quot;16de#+ui9&quot;);        Connection conn = driver.connect(&quot;jdbc:kylin://10.214.234.111:7070/Test_kylin&quot;, info);        Statement state = conn.createStatement();        String sqlStr = &quot;&quot;;        ResultSet resultSet = state.executeQuery(sqlStr);        List list = new ArrayList();        while (resultSet.next()){            list.add(resultSet.getString(&quot;1&quot;));        }        list.forEach(citg -&gt; System.out.println(citg));    }}</code></pre>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;kylin jdbc 连接&lt;/p&gt;
&lt;p&gt;一 、kylin 简介&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Kylin是ebay开发的一套OLAP系统，与Mondrian不同的是，它是一个MOLAP系统，主要用于支持大数据生态圈的数据分析业务，它主要是通过预计算的方式将用户设定的多维立
      
    
    </summary>
    
      <category term="kylin" scheme="http://yoursite.com/categories/kylin/"/>
    
    
      <category term="kylin" scheme="http://yoursite.com/tags/kylin/"/>
    
  </entry>
  
  <entry>
    <title>CDH 5.15 简易版离线安装完整版</title>
    <link href="http://yoursite.com/2019/01/14/CDH-5-15-%E7%AE%80%E6%98%93%E7%89%88%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E5%AE%8C%E6%95%B4%E7%89%88/"/>
    <id>http://yoursite.com/2019/01/14/CDH-5-15-简易版离线安装完整版/</id>
    <published>2019-01-14T06:34:23.000Z</published>
    <updated>2019-01-14T06:34:23.838Z</updated>
    
    <content type="html"><![CDATA[<pre><code>CDH 简易版离线安装</code></pre><p>一、虚拟机搭建</p><p>准备一台32G内存的电脑，安装虚拟机VMware-workstation。虚拟机下载地址：<a href="http://download3.vmware.com/software/wkst/file/VMware-Workstation-Full-14.1.2-8497320.x86_64.bundle。根据自己的电脑系统下载不同的版本，我下载的是VMware-Workstation-Full-14.1.2-8497320.x86_64.bundle。安装完虚拟机后，下载操作系统镜像CentOS-7-x86_64-DVD-1804.iso（这是我选择的版本，你们可以选择不同的版本），创建一个新的虚拟机，至于虚拟机如何创建请自行解决。" target="_blank" rel="noopener">http://download3.vmware.com/software/wkst/file/VMware-Workstation-Full-14.1.2-8497320.x86_64.bundle。根据自己的电脑系统下载不同的版本，我下载的是VMware-Workstation-Full-14.1.2-8497320.x86_64.bundle。安装完虚拟机后，下载操作系统镜像CentOS-7-x86_64-DVD-1804.iso（这是我选择的版本，你们可以选择不同的版本），创建一个新的虚拟机，至于虚拟机如何创建请自行解决。</a></p><p>经过上面的一系列的操作，目前拥有三台虚拟机</p><p>master  内存 16G 磁盘 150G  </p><p>slave1   内存   6G 磁盘 150G</p><p>slave2   内存    6G 磁盘 150G</p><p>二、虚拟机配置</p><p>1.修改所有的主机名，这样便于管理。</p><p>hostnamectl set-hostname master<br>hostnamectl set-hostname slave1<br>hostnamectl set-hostname slave2<br>2.配置静态IP</p><p>首先，选择NAT网络连接模式</p><p> 然后，点击Edit编辑虚拟机网络设置，进入VMware network edit ,选中vmnet8 ,将Use local DHCP service to distribute IP addresses to VMs 前面的勾去掉。</p><p>接着，进入 /etc/sysconfig/network-scripts中查看现有的配置文件然后修改其中的配置文件，其中有个类似ifcfg-enth0的文件是你的网络名字</p><p>TYPE=Ethernet<br>PROXY_METHOD=none<br>BROWSER_ONLY=no<br>BOOTPROTO=static<br>DEFROUTE=yes<br>IPV4_FAILURE_FATAL=no<br>IPV6INIT=yes<br>IPV6_AUTOCONF=yes<br>IPV6_DEFROUTE=yes<br>IPV6_FAILURE_FATAL=no<br>IPV6_ADDR_GEN_MODE=stable-privacy<br>NAME=$’\751\605\615\747\675\656 1’<br>UUID=2bfdf6df-9fd6-44e3-ade7-5a397cf8d2e4<br>ONBOOT=yes<br>IPADDR=172.16.247.135<br>GATEWAY=172.16.247.2<br>NETMASK=255.255.255.0<br>PREFIX=24</p><p>上面主要修改红色字体部分，其中BOOTPROTO=static 表示静态，IPADDR=172.16.247.135 表示静态IP地址</p><p>最后，保存退出，执行</p><p>重启网络<br>service network restart<br>查看IP<br>ifconfig<br>ping网络<br>ping <a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a><br>3.编辑hosts 文件 添加ip地址</p><p>vi /etc/hosts<br> 添加以下配置，你对应的三台机器的IP地址和对应的主机名</p><p>172.16.247.135 master<br>172.16.247.132 slave1<br>172.16.247.136 slave2</p><p>然后将这个文件分别拷贝到各个节点上</p><p>scp /etc/hosts root@slave1:/etc/hosts<br>scp /etc/hosts root@slave2:/etc/hosts</p><p>4.配置SSH免密登陆</p><p>主要分为两个步骤：首先在所有的节点生成公钥</p><p>ssh-keygen -t rsa<br>然后将所有的节点执行拷贝公钥</p><p>ssh-copy-id root@master<br>ssh-copy-id root@slave1<br>ssh-copy-id root@slave2<br>当然也可以公钥添加到认证文件中，并设置authorized_keys的访问权限：<a href="https://blog.csdn.net/johnzhc/article/details/81119030" target="_blank" rel="noopener">https://blog.csdn.net/johnzhc/article/details/81119030</a></p><p>5.关闭selinux和防火墙</p><p>vi /etc/selinux/config</p><p>SELINUX=disabled</p><p>[hadoop@master network-scripts]$ cat /etc/selinux/config</p><h1 id="This-file-controls-the-state-of-SELinux-on-the-system"><a href="#This-file-controls-the-state-of-SELinux-on-the-system" class="headerlink" title="This file controls the state of SELinux on the system."></a>This file controls the state of SELinux on the system.</h1><h1 id="SELINUX-can-take-one-of-these-three-values"><a href="#SELINUX-can-take-one-of-these-three-values" class="headerlink" title="SELINUX= can take one of these three values:"></a>SELINUX= can take one of these three values:</h1><h1 id="enforcing-SELinux-security-policy-is-enforced"><a href="#enforcing-SELinux-security-policy-is-enforced" class="headerlink" title="enforcing - SELinux security policy is enforced."></a>enforcing - SELinux security policy is enforced.</h1><h1 id="permissive-SELinux-prints-warnings-instead-of-enforcing"><a href="#permissive-SELinux-prints-warnings-instead-of-enforcing" class="headerlink" title="permissive - SELinux prints warnings instead of enforcing."></a>permissive - SELinux prints warnings instead of enforcing.</h1><h1 id="disabled-No-SELinux-policy-is-loaded"><a href="#disabled-No-SELinux-policy-is-loaded" class="headerlink" title="disabled - No SELinux policy is loaded."></a>disabled - No SELinux policy is loaded.</h1><p>SELINUX=disabled</p><h1 id="SELINUXTYPE-can-take-one-of-three-two-values"><a href="#SELINUXTYPE-can-take-one-of-three-two-values" class="headerlink" title="SELINUXTYPE= can take one of three two values:"></a>SELINUXTYPE= can take one of three two values:</h1><h1 id="targeted-Targeted-processes-are-protected"><a href="#targeted-Targeted-processes-are-protected" class="headerlink" title="targeted - Targeted processes are protected,"></a>targeted - Targeted processes are protected,</h1><h1 id="minimum-Modification-of-targeted-policy-Only-selected-processes-are-protected"><a href="#minimum-Modification-of-targeted-policy-Only-selected-processes-are-protected" class="headerlink" title="minimum - Modification of targeted policy. Only selected processes are protected."></a>minimum - Modification of targeted policy. Only selected processes are protected.</h1><h1 id="mls-Multi-Level-Security-protection"><a href="#mls-Multi-Level-Security-protection" class="headerlink" title="mls - Multi Level Security protection."></a>mls - Multi Level Security protection.</h1><p>SELINUXTYPE=targeted</p><p> 关闭防火墙和查看防火墙状态：</p><p>systemctl stop firewalld<br>systemctl disable firewalld<br>systemctl status firewalld<br>6.安装NTP时间同步</p><p>yum install  -y ntp     #安装ntp服务（所有节点）</p><p>vi /etc/ntp.conf          #编辑ntp服务的配置文件（所有节点）</p><p>主节点master的ntp.conf修改红色部分，蓝色要注释掉</p><h1 id="Note-Monitoring-will-not-be-disabled-with-the-limited-restriction-flag"><a href="#Note-Monitoring-will-not-be-disabled-with-the-limited-restriction-flag" class="headerlink" title="Note: Monitoring will not be disabled with the limited restriction flag."></a>Note: Monitoring will not be disabled with the limited restriction flag.</h1><p>#disable monitor<br>restrict default nomodify<br>restrict default nomodify notrap<br>server 127.127.1.0<br>fudge 127.127.1.0 stratum 10<br>includefile /etc/ntp/crypto/pw<br>keys /etc/ntp/keys</p><h1 id="中国这边最活跃的时间服务器-http-www-pool-ntp-org-zone-cn"><a href="#中国这边最活跃的时间服务器-http-www-pool-ntp-org-zone-cn" class="headerlink" title="中国这边最活跃的时间服务器 : http://www.pool.ntp.org/zone/cn"></a>中国这边最活跃的时间服务器 : <a href="http://www.pool.ntp.org/zone/cn" target="_blank" rel="noopener">http://www.pool.ntp.org/zone/cn</a></h1><p>server 0.cn.pool.ntp.org<br>server 0.asia.pool.ntp.org<br>server 3.asia.pool.ntp.org</p><h1 id="allow-update-time-by-the-upper-server"><a href="#allow-update-time-by-the-upper-server" class="headerlink" title="allow update time by the upper server"></a>allow update time by the upper server</h1><h1 id="允许上层时间服务器主动修改本机时间"><a href="#允许上层时间服务器主动修改本机时间" class="headerlink" title="允许上层时间服务器主动修改本机时间"></a>允许上层时间服务器主动修改本机时间</h1><p>restrict 0.cn.pool.ntp.org nomodify notrap noquery<br>restrict 0.asia.pool.ntp.org nomodify notrap noquery<br>restrict 3.asia.pool.ntp.org nomodify notrap noquery</p><h1 id="Undisciplined-Local-Clock-This-is-a-fake-driver-intended-for-backup"><a href="#Undisciplined-Local-Clock-This-is-a-fake-driver-intended-for-backup" class="headerlink" title="Undisciplined Local Clock. This is a fake driver intended for backup"></a>Undisciplined Local Clock. This is a fake driver intended for backup</h1><h1 id="and-when-no-outside-source-of-synchronized-time-is-available"><a href="#and-when-no-outside-source-of-synchronized-time-is-available" class="headerlink" title="and when no outside source of synchronized time is available."></a>and when no outside source of synchronized time is available.</h1><h1 id="外部时间服务器不可用时，以本地时间作为时间服务"><a href="#外部时间服务器不可用时，以本地时间作为时间服务" class="headerlink" title="外部时间服务器不可用时，以本地时间作为时间服务"></a>外部时间服务器不可用时，以本地时间作为时间服务</h1><p> 从节点slave的ntp.conf修改红色部分，紫色要注释掉</p><h1 id="with-symmetric-key-cryptography"><a href="#with-symmetric-key-cryptography" class="headerlink" title="with symmetric key cryptography."></a>with symmetric key cryptography.</h1><p>keys /etc/ntp/keys</p><h1 id="Specify-the-key-identifiers-which-are-trusted"><a href="#Specify-the-key-identifiers-which-are-trusted" class="headerlink" title="Specify the key identifiers which are trusted."></a>Specify the key identifiers which are trusted.</h1><p>#trustedkey 4 8 42</p><h1 id="Specify-the-key-identifier-to-use-with-the-ntpdc-utility"><a href="#Specify-the-key-identifier-to-use-with-the-ntpdc-utility" class="headerlink" title="Specify the key identifier to use with the ntpdc utility."></a>Specify the key identifier to use with the ntpdc utility.</h1><p>#requestkey 8</p><h1 id="Specify-the-key-identifier-to-use-with-the-ntpq-utility"><a href="#Specify-the-key-identifier-to-use-with-the-ntpq-utility" class="headerlink" title="Specify the key identifier to use with the ntpq utility."></a>Specify the key identifier to use with the ntpq utility.</h1><p>#controlkey 8</p><h1 id="Enable-writing-of-statistics-records"><a href="#Enable-writing-of-statistics-records" class="headerlink" title="Enable writing of statistics records."></a>Enable writing of statistics records.</h1><p>#statistics clockstats cryptostats loopstats peerstats</p><h1 id="Disable-the-monitoring-facility-to-prevent-amplification-attacks-using-ntpdc"><a href="#Disable-the-monitoring-facility-to-prevent-amplification-attacks-using-ntpdc" class="headerlink" title="Disable the monitoring facility to prevent amplification attacks using ntpdc"></a>Disable the monitoring facility to prevent amplification attacks using ntpdc</h1><h1 id="monlist-command-when-default-restrict-does-not-include-the-noquery-flag-See"><a href="#monlist-command-when-default-restrict-does-not-include-the-noquery-flag-See" class="headerlink" title="monlist command when default restrict does not include the noquery flag. See"></a>monlist command when default restrict does not include the noquery flag. See</h1><h1 id="CVE-2013-5211-for-more-details"><a href="#CVE-2013-5211-for-more-details" class="headerlink" title="CVE-2013-5211 for more details."></a>CVE-2013-5211 for more details.</h1><h1 id="Note-Monitoring-will-not-be-disabled-with-the-limited-restriction-flag-1"><a href="#Note-Monitoring-will-not-be-disabled-with-the-limited-restriction-flag-1" class="headerlink" title="Note: Monitoring will not be disabled with the limited restriction flag."></a>Note: Monitoring will not be disabled with the limited restriction flag.</h1><p>#disable monitor<br>server master prefer     #master 是指你的主机名<br>restrict default nomodify notrap nopeer noquery<br>restrict -6 default kod nomodify notrap nopeer noquery</p><p>设置开机启动ntp服务</p><p>#关闭chronyd服务<br>systemctl disable chronyd.service</p><p>#开机自启动<br> systemctl enable ntpd.service</p><p>以上都配置完成后，执行</p><p>systemctl start ntpd    #开启ntp服务</p><p>ntpstat                         #查看ntp运行状态</p><p>synchronised to NTP server (172.16.247.135) at stratum 3<br>   time correct to within 350 ms<br>   polling server every 1024 s         #出现这个表示成功同步</p><p>7.卸载Centos 系统自带的JDK</p><p>rpm -qa | grep jdk  #查看系统自带的jdk</p><p>yum -y remove   xxjdk   #删除所有的jdk</p><p>8.CM 和CDH下载以及JDK和java驱动</p><p>Cloudera Manager下载地址：<a href="http://archive.cloudera.com/cm5/cm/5/cloudera-manager-centos7-cm5.15.0_x86_64.tar.gz" target="_blank" rel="noopener">http://archive.cloudera.com/cm5/cm/5/cloudera-manager-centos7-cm5.15.0_x86_64.tar.gz</a></p><p>CDH安装包地址：<a href="http://archive.cloudera.com/cdh5/parcels/latest/，由于我们的操作系统为CentOS7.2，需要下载以下文件：" target="_blank" rel="noopener">http://archive.cloudera.com/cdh5/parcels/latest/，由于我们的操作系统为CentOS7.2，需要下载以下文件：</a></p><p>CDH-5.15.0-1.cdh5.15.0.p0.21-el7.parcel</p><p>CDH-5.15.0-1.cdh5.15.0.p0.21-el7.parcel.sha1</p><p>manifest.json</p><p>JDK 可以去官网下载 下载地址：<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></p><p>  下载版本为： jdk-8u172-linux-x64.rpm</p><p>mysql的java驱动 下载地址：<a href="https://dev.mysql.com/downloads/connector/j/5.1.html" target="_blank" rel="noopener">https://dev.mysql.com/downloads/connector/j/5.1.html</a> </p><pre><code>下载版本为：mysql-connector-java-5.1.46.tar.gz</code></pre><p>9.安装CM和jdk以及mysql驱动</p><p>将下载好的安装包分发到各个节点上，并解压缩。</p><p>1.将和cloudera-manager-daemons-5.15.0-1.cm5150.p0.62.el7.x86_64.rpm以及cloudera-manager-server-5.15.0-1.cm5150.p0.62.el7.x86_64.rpm三个安装包传入管理节点（master节点）/tmp 目录下，当然其他目录也可以。但是tmp目录可以使得解压后的rpm包重启后删除不占内存。</p><p>2.将cloudera-manager-agent-5.15.0-1.cm5150.p0.62.el7.x86_64.rpm和cloudera-manager-daemons-5.15.0-1.cm5150.p0.62.el7.x86_64.rpm两个安装包传入所有从节点上（slave1和slave2节点）的/tmp目录下</p><p>3.将jdk-8u172-linux-x64.rpm安装包传入所有节点上/tmp目录,复制语句类似下面：</p><p>scp cloudera-manager-agent-5.15.0-1.cm5150.p0.62.el7.x86_64.rpm root@master:/tmp<br>4.然后解压所有对应的安装包（所有节点）</p><p>yum localinstall *.rpm<br>5.配置JAVA_HOME变量（所有节点）</p><p>echo “JAVA_HOME=/usr/java/latest/“ &gt;&gt; /etc/environment<br>6.安装mysql驱动程序</p><p>将mysql-connector-java-5.1.46.tar.gz解压mysql-connector-java-5.1.46后将解压后包中的mysql-connector-java-5.1.46-bin.jar重命名为mysql-connector-java.jar传入 /usr/share/java目录里面。</p><p>tar mysql-connector-java-5.1.46.tar.gz<br>sudo mkdir -p /usr/share/java<br>cd mysql-connector-java-5.1.46<br>sudo cp mysql-connector-java-5.1.46-bin.jar /usr/share/java/mysql-connector-java.jar</p><p>10.数据库安装</p><p>1.在master节点安装MariaDB(Mysql)这里安装MariDB,若要安装mysql，可参考<a href="https://blog.csdn.net/johnzhc/article/details/81119030。" target="_blank" rel="noopener">https://blog.csdn.net/johnzhc/article/details/81119030。</a></p><p>sudo yum install mariadb-server  #安装maridb<br>sudo systemctl enable mariadb    #设置开机启动<br>sudo systemctl start mariadb     #启动mariadb<br>sudo /usr/bin/mysql_secure_installation  #配置mariadb<br> 可参考文档<a href="https://www.cloudera.com/documentation/cdh/5-1-x/CDH5-Installation-Guide/CDH5-Installation-Guide.html" target="_blank" rel="noopener">https://www.cloudera.com/documentation/cdh/5-1-x/CDH5-Installation-Guide/CDH5-Installation-Guide.html</a></p><p>2.为CDH创建数据库和用户</p><p>mysql -u root -p<br>输入密码登陆mysql ，然后创建多个数据库，并完成授权。</p><p>CREATE DATABASE scm DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</p><p>GRANT ALL ON scm.* TO ‘scm‘@’%’ IDENTIFIED BY ‘scm’;</p><p>CREATE DATABASE amon DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</p><p>GRANT ALL ON amon.* TO ‘amon‘@’%’ IDENTIFIED BY ‘amon’;</p><p>CREATE DATABASE rman DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</p><p>GRANT ALL ON rman.* TO ‘rman‘@’%’ IDENTIFIED BY ‘rman’;</p><p>CREATE DATABASE hue DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</p><p>GRANT ALL ON hue.* TO ‘hue‘@’%’ IDENTIFIED BY ‘hue’;</p><p>CREATE DATABASE hive DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</p><p>GRANT ALL ON hive.* TO ‘hive‘@’%’ IDENTIFIED BY ‘hive’;</p><p>CREATE DATABASE sentry DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</p><p>GRANT ALL ON sentry.* TO ‘sentry‘@’%’ IDENTIFIED BY ‘sentry’;</p><p>CREATE DATABASE oozie DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</p><p>GRANT ALL ON oozie.* TO ‘oozie‘@’%’ IDENTIFIED BY ‘oozie’;<br>最后，退出数据库进行数据库的初始化，执行语句类似下面。</p><p>exit #退出数据库<br>/user/share/cmf/schema/scm_prepare_database.sh (databaseType) (databaseName) (databaseuser) (databasepassword)<br>例如scm数据库： /usr/share/cmf/schema/scm_prepare_database.sh mysql scm scm scm</p><p>11.安装CDH</p><p>1.在master节点创建parcel-repo仓库</p><p>mkdir -p /opt/cloudera/parcel-repo<br>chown cloudera-scm:cloudera-scm /opt/cloudera/parcel-repo<br>2.将CDH安装包复制到/opt/cloudera/parcel-repo 目录下。</p><p>CDH-5.15.0-1.cdh5.15.0.p0.21-el7.parcel</p><p>CDH-5.15.0-1.cdh5.15.0.p0.21-el7.parcel.sha1</p><p>manifest.json</p><p>然后将CDH-5.15.0-1.cdh5.15.0.p0.21-el7.parcel.sha1 重命名CDH-5.15.0-1.cdh5.15.0.p0.21-el7.parcel.sha</p><p>3.修改slave1和slave2的/etc/cloudera-scm-agent/config.ini</p><p>将server_host改为管理节点的网络名本例为master</p><p>4.分别启动cloudera-scm-server和cloudera-scm-agent</p><p>在主节点启动agent和server执行以下命令</p><p>systemctl start cloudera-scm-agent</p><p>systemctl start cloudera-scm-server<br>在slave1和slave2执行以下代码</p><p>systemctl start cloudera-scm-agent<br>5.进入<a href="http://master:7180,默认的用户名和密码均为admin开始添加集群，下面是一种添加服务的顺序。" target="_blank" rel="noopener">http://master:7180,默认的用户名和密码均为admin开始添加集群，下面是一种添加服务的顺序。</a></p><p>hdfs-&gt; yarn-&gt; hive-&gt; impala-&gt; zookeeper-&gt; hbase-&gt; oozie-&gt; hue-&gt;sqoop-&gt;kafka-&gt;spark</p><p> 12.总结</p><p>安装过程主要遇到的坑：</p><p>1.静态IP的配置</p><p>2.时间同步ntp服务</p><p>3.安装服务的对应文件夹的权限问题。主要就是查看日志更改对应文件的权限：</p><p>chmod 777 xxx<br>chown root XXX<br>4.kafka安装</p><p>在安装界面点击主机</p><p>点击parcel</p><p>点击KAFKA分配，并激活</p><p>然后添加kafka服务，并再配置的设置如下的参数：</p><p> kafak mirrormaker：</p><p>Destination Broker list slave1:9092</p><p>source list slave1:9092</p><p>topical whitelist slave1:9092</p><p>kafak Broker</p><p>Advertiesd Host   slave1</p><p>java heap size of broker 256</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;CDH 简易版离线安装
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;一、虚拟机搭建&lt;/p&gt;
&lt;p&gt;准备一台32G内存的电脑，安装虚拟机VMware-workstation。虚拟机下载地址：&lt;a href=&quot;http://download3.vmware.com/soft
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>NEO4J 图数据库使用APOC数据导入</title>
    <link href="http://yoursite.com/2019/01/14/NEO4J-%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BD%BF%E7%94%A8APOC%E6%95%B0%E6%8D%AE%E5%AF%BC%E5%85%A5/"/>
    <id>http://yoursite.com/2019/01/14/NEO4J-图数据库使用APOC数据导入/</id>
    <published>2019-01-14T06:33:35.000Z</published>
    <updated>2019-01-14T06:33:35.829Z</updated>
    
    <content type="html"><![CDATA[<pre><code>Neo4j 数据导入</code></pre><p>一、安装与部署</p><pre><code>直接在官网下载安装包安装，解压即可。</code></pre><p>二、下载相应的jar包</p><p>1.sqlserver 数据导入neo4j的jar包</p><p>apoc-3.4.0.1-all.jar     mssql-jdbc-6.2.2.jre8.jar     sqljdbc4-4.0.jar</p><p>2.mysql 数据导入neo4j的jar包</p><p>apoc-3.3.0.1-all.jar    mysql-connector-java-8.0.8-dmr.jar</p><p>3.将对应jar包放在安装目录plugins文件目录里，然后conf目录里的neo4j.conf的后面加上</p><p>dbms.security.procedures.unrestricted=apoc.*</p><p>apoc.import.file.enabled=true<br>apoc.export.file.enabled=true</p><p>4.restart neo4j,运行return apoc.version(),若有版本号，则成功。</p><p>三、导数据</p><p>import org.neo4j.driver.v1.<em>;<br>public class Connect{<br>public static void main(String[] args){<br> Driver driver = GraphDatabase.driver(“bolt://localhost:7687”,AuthTokens.basic(“neo4j”,”neo4j”));<br> Session session = driver.session();<br> String cypher=”create constraint on (n:ITEM) ASSERT n.itemid is unique”; //创建唯一索引，这样可以更快的导入数据<br> Session.run(cypher);<br> cypher=”CALL apoc.periodic.iterate(\”CALL apoc.load.jdbc(‘jdbc:sqlserver://localhost;username=name;password=word;database=db;characterEncoding=utf-8’,\\”SELECT </em> FROM TABLE1\\”)\”,\”MERGE(n:ITEM{itemid:row.mitemid}) with <em> MERGE(m:ITEM{itemid:row.itemid}) with </em> create p=(n)-[r:rel{rels:row.rels}]-&gt;(m)\”,{batchSize:10000,iterateList:true})”;  //连接sqlserve数据库和设计创建neo4j图数据库数据模型<br> Session.run(cypher);<br> session.close();<br> driver.close();<br>   }<br>}<br>mysql数据库类似,不再赘述。</p><p>补充：1.使用neo4j-import导入数据的命令</p><p>neo4j-admin import –nodes:item  “nodes.csv”  –relationships:rel “rel_header.csv,rel.csv” –ignore-missing-nodes</p><p>2.apoc 导出命令</p><p>call apoc.export.cypher.query(<br>“MATCH (p1:Person)-[r:KNOWS]-&gt;(p2:Person) RETURN p1,r,p2”,<br>“/tmp/friendships.cypher”,<br>{format:’plain’,cypherFormat:’updateStructure’})`<br>参考： <a href="http://neo4j-contrib.github.io/neo4j-apoc-procedures/#_export_import" target="_blank" rel="noopener">http://neo4j-contrib.github.io/neo4j-apoc-procedures/#_export_import</a></p><p>call apoc.export.cypher.query(“match (n:lable) where not (n)–() and n.properties = ‘400’ return distinct(n)”,”C://User/Desktop/test”,{format:’plain’,cypherFormat:’create’})<br> 3.不用解压也能导数据load csv</p><p>load csv from “file:/twitter-2010.txt.gz” as line fieldterminator ‘ ‘ with toInt(line[0]) as id,toInt(line[1]) as id1 return id,id1 limit 10<br>using periodic commit 1000<br>load csv from “file:/twitter-2010.txt.gz” as line fieldterminator ‘ ‘ create (item:ITEM{id:line[0],item:line[1]})</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;Neo4j 数据导入
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;一、安装与部署&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;直接在官网下载安装包安装，解压即可。
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;二、下载相应的jar包&lt;/p&gt;
&lt;p&gt;1.sqlserver 数据导入neo4j的jar
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>RDD常用算子</title>
    <link href="http://yoursite.com/2018/08/15/RDD%E5%B8%B8%E7%94%A8%E7%AE%97%E5%AD%90/"/>
    <id>http://yoursite.com/2018/08/15/RDD常用算子/</id>
    <published>2018-08-15T06:15:14.000Z</published>
    <updated>2018-08-15T10:52:32.586Z</updated>
    
    <content type="html"><![CDATA[<p><strong>1.mapPartitionsWithIndex:独立运行在每个分片上，并带有分区的编号。</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val rdd1 = sc.parallelize(List(1,2,3,4,5,6,7,8,9),2)</span><br><span class="line"> rdd1.saveAsTextFile(&quot;hdfs://master:8020/sfz&quot;) def func1(index:</span><br><span class="line">Int,iter: Iterator[(Int)]) : Iterator[String] = &#123;iter.toList.map(x =&gt;</span><br><span class="line"> &quot;[partID:&quot; + index + &quot;,val: &quot; + x +&quot;]&quot;).iterator&#125;</span><br><span class="line"> rdd1.mapPartitionsWithIndex(func1).collect</span><br></pre></td></tr></table></figure><p><strong><em>2.aggregate:先局部操作，再整体操作。</em></strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">val rdd2 = sc.parallelize(List(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;,&quot;e&quot;,&quot;f&quot;),2)</span><br><span class="line">def func2(index: Int,iter: Iterator[(String)]) : Iterator[String] = &#123;iter.toList.map(x =&gt; &quot;[partID:&quot; + index + &quot;,val: &quot; + x +&quot;]&quot;).iterator&#125;</span><br><span class="line">rdd2.mapPartitionsWithIndex(func2).collect</span><br><span class="line">rdd2.aggregate(&quot;&quot;)(_+_,_+_)</span><br><span class="line"></span><br><span class="line">val rdd3 = sc.parallelize(List(&quot;12&quot;,&quot;23&quot;,&quot;345&quot;,&quot;4567&quot;),2)</span><br><span class="line">rdd3.aggregate(&quot;&quot;)((x,y) =&gt; math.max(x.length,y.length).toString,(x,y) =&gt; x+y)</span><br><span class="line"></span><br><span class="line">val rdd5 = sc.parallelize(List(&quot;12&quot;,&quot;23&quot;,&quot;&quot;,&quot;345&quot;),2)</span><br><span class="line">rdd5.aggregate(&quot;&quot;)((x,y) =&gt; math.min(x.length,y.length).toString,(x,y) =&gt; x+y)</span><br></pre></td></tr></table></figure><p><strong><em>3.aggregateByKey：将key值相同的，先局部操作，再整体操作。和reduceByKey内部实现差不多</em></strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">val pairRDD = sc.parallelize(List( (&quot;cat&quot;,2), (&quot;cat&quot;, 5), (&quot;mouse&quot;,    4),(&quot;cat&quot;, 12), (&quot;dog&quot;, 12), (&quot;mouse&quot;, 2)), 2)    pairRDD.aggregateByKey(0)(math.max(_, _), _ + _).collect</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;strong&gt;1.mapPartitionsWithIndex:独立运行在每个分片上，并带有分区的编号。&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;sp
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>图数据集群搭建</title>
    <link href="http://yoursite.com/2018/08/14/%E5%9B%BE%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    <id>http://yoursite.com/2018/08/14/图数据集群搭建/</id>
    <published>2018-08-14T02:15:50.000Z</published>
    <updated>2018-08-16T00:46:15.748Z</updated>
    
    <content type="html"><![CDATA[<pre><code>** NEO4J高可用集群搭建 **</code></pre><p>高可用的neo4j集群主要采用了主从的结构，来保证集群的容错能力和应变能力，同时也保证了了集群在读取密集型的数据的场景下可横向的扩展能力。同时，它还支持缓存分区，使得NEO4J高可用性集群比neo4j单实例具有更大的负载能力。但HA集群很快要不支持了。</p><p>好了，话不多说，如果看过前一篇文章<a href="https://blog.csdn.net/fffsssfff6/article/details/81215416" target="_blank" rel="noopener">https://blog.csdn.net/fffsssfff6/article/details/81215416</a>, 完成了前半部分的一些基本准备，那么就可以直接进行HA集群搭建。若没有准备，则需要完成至JDK安装的步骤。下面就开始了：</p><p>一、首先 下载neo4j企业版的安装包。可以参考<a href="https://blog.csdn.net/xubo245/article/details/50033003" target="_blank" rel="noopener">https://blog.csdn.net/xubo245/article/details/50033003</a>.  执行下面命令<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">  http://dist.neo4j.org/neo4j-enterprise-3.4.0-unix.tar.gz</span><br><span class="line">```  </span><br><span class="line"> 或者前往neo4j官网下载 ：https://neo4j.com/download/ .</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">二、然后将安装包解压后分别传入到 /opt/neo4j 目录下。</span><br><span class="line">``` bash</span><br><span class="line"></span><br><span class="line">tar -zxvf neo4j-enterprise-3.4.0-unix.tar.gz</span><br><span class="line">scp -r neo4j-enterprise-3.4.0 root@master: /opt/neo4j</span><br><span class="line">scp -r neo4j-enterprise-3.4.0 root@slave1: /opt/neo4j</span><br><span class="line">scp -r neo4j-enterprise-3.4.0 root@slave2: /opt/neo4j</span><br></pre></td></tr></table></figure></p><p>三 、修改配置文件neo4j.conf(重要)</p><p>master节点：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">dbms.mode=HA</span><br><span class="line">ha.server_id=1</span><br><span class="line">ha.initial_hosts=172.16.247.135:5001,172.16.247.132:5001,172.16.247.136:5001</span><br><span class="line">dbms.connectors.default_listen_address=0.0.0.0</span><br></pre></td></tr></table></figure></p><p>slave1节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">dbms.mode=HA</span><br><span class="line">ha.server_id=2</span><br><span class="line">ha.initial_hosts=172.16.247.135:5001,172.16.247.132:5001,172.16.247.136:5001</span><br><span class="line">dbms.connectors.default_listen_address=0.0.0.0</span><br></pre></td></tr></table></figure><p>slave2节点：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">dbms.mode=HA</span><br><span class="line">ha.server_id=3</span><br><span class="line">ha.initial_hosts=172.16.247.135:5001,172.16.247.132:5001,172.16.247.136:5001</span><br><span class="line">dbms.connectors.default_listen_address=0.0.0.0</span><br></pre></td></tr></table></figure><p>四、启动HA集群,分别进入neo4j 目录下执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">./bin/neo4j start</span><br><span class="line">./bin/neo4j start</span><br><span class="line">./bin/neo4j start</span><br></pre></td></tr></table></figure><p> 五、进入localhost：7474查看集群信息<br><img src="https://img-blog.csdn.net/20180803153649681?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ZGRlNTU0ZGRjY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="Image text"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;** NEO4J高可用集群搭建 **
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;高可用的neo4j集群主要采用了主从的结构，来保证集群的容错能力和应变能力，同时也保证了了集群在读取密集型的数据的场景下可横向的扩展能力。同时，它还支持缓存分区，使得NEO4J高可用性集群
      
    
    </summary>
    
      <category term="图数据库" scheme="http://yoursite.com/categories/%E5%9B%BE%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="neo4j" scheme="http://yoursite.com/tags/neo4j/"/>
    
  </entry>
  
</feed>
