<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>上善若水博客</title>
  
  <subtitle>大数据</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-04-07T11:54:48.115Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>上善若水</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>spark 常用操作</title>
    <link href="http://yoursite.com/2020/04/07/spark-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/"/>
    <id>http://yoursite.com/2020/04/07/spark-常用操作/</id>
    <published>2020-04-07T11:28:53.000Z</published>
    <updated>2020-04-07T11:54:48.115Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、spark-分组计算（转rdd-分组计算完再转回-dateset）"><a href="#一、spark-分组计算（转rdd-分组计算完再转回-dateset）" class="headerlink" title="一、spark 分组计算（转rdd 分组计算完再转回 dateset）"></a>一、spark 分组计算（转rdd 分组计算完再转回 dateset）</h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;Row&gt; rowJavaRdd = orderDistanceCustomer.javaRDD();</span><br><span class="line">JavaRDD&lt;OrderLeaveTime&gt; leaveTimeJavaRDD = rowJavaRdd.groupBy(row -&gt; row.getString(1))</span><br><span class="line">              .map(new Function&lt;Tuple2&lt;String, Iterable&lt;Row&gt;&gt;, OrderLeaveTime&gt;() &#123;</span><br><span class="line">                  @Override</span><br><span class="line">                  public OrderLeaveTime call(Tuple2&lt;String, Iterable&lt;Row&gt;&gt; v1) throws Exception &#123;</span><br><span class="line">                      String order_number = v1._1;</span><br><span class="line">                      Iterator&lt;Row&gt; iterator = v1._2.iterator();</span><br><span class="line">                      String report_time = &quot;&quot;;</span><br><span class="line">                      String flag = &quot;&quot;;</span><br><span class="line">                      while (iterator.hasNext()) &#123;</span><br><span class="line">                          Row next = iterator.next();</span><br><span class="line">                          double order_distance_customer = next.getDouble(14);</span><br><span class="line">                          report_time = next.getString(11);</span><br><span class="line">                          if (order_distance_customer - 2000 &lt; 0) &#123;</span><br><span class="line">                              flag = &quot;已进入&quot;;</span><br><span class="line">                          &#125;</span><br><span class="line">                          if (&quot;已进入&quot;.equals(flag) &amp;&amp; order_distance_customer - 2000 &gt; 0) &#123;</span><br><span class="line">                              break;</span><br><span class="line">                          &#125;</span><br><span class="line">                      &#125;</span><br><span class="line">                      OrderLeaveTime orderArriveTime1 = new OrderLeaveTime();</span><br><span class="line">                      orderArriveTime1.setOrderNumber(order_number);</span><br><span class="line">                      orderArriveTime1.setLeaveTime(report_time);</span><br><span class="line">                      return orderArriveTime1;</span><br><span class="line">                  &#125;</span><br><span class="line">              &#125;);</span><br><span class="line"></span><br><span class="line">      Encoder&lt;OrderLeaveTime&gt; orderLeaveTimeEncode = Encoders.bean(OrderLeaveTime.class);</span><br><span class="line">      Dataset&lt;OrderLeaveTime&gt; leaveTimeDataset = spark.createDataset(leaveTimeJavaRDD.rdd(),orderLeaveTimeEncode);</span><br></pre></td></tr></table></figure><h2 id="二、spark-dataset-分组计算（使用groupbyKey）"><a href="#二、spark-dataset-分组计算（使用groupbyKey）" class="headerlink" title="二、spark dataset 分组计算（使用groupbyKey）"></a>二、spark dataset 分组计算（使用groupbyKey）</h2><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">Dataset&lt;DeviceLocation&gt; deviceLocationDataset = devicePosition.groupByKey(new MapFunction&lt;Row, String&gt;() &#123;</span><br><span class="line">           @Override</span><br><span class="line">           public String call(Row value) throws Exception &#123;</span><br><span class="line">               return value.getString(2);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;, Encoders.STRING()).flatMapGroups(new FlatMapGroupsFunction&lt;String, Row, DeviceLocation&gt;() &#123;</span><br><span class="line">           @Override</span><br><span class="line">           public Iterator&lt;DeviceLocation&gt; call(String key, Iterator&lt;Row&gt; values) throws Exception &#123;</span><br><span class="line">               List&lt;DeviceLocation.Location&gt; locations = new ArrayList&lt;&gt;();</span><br><span class="line">               while (values.hasNext()) &#123;</span><br><span class="line">                   DeviceLocation.Location location = new DeviceLocation.Location();</span><br><span class="line">                   Row next = values.next();</span><br><span class="line">                   location.setId((int)next.getLong(0));</span><br><span class="line">                   location.setLocation_code(next.getString(1));</span><br><span class="line">                   location.setLongitude(next.getString(3));</span><br><span class="line">                   location.setLongmark(next.getString(4));</span><br><span class="line">                   location.setLatitude(next.getString(5));</span><br><span class="line">                   location.setLati_mark(next.getString(6));</span><br><span class="line">                   location.setPosition_time(next.getTimestamp(7));</span><br><span class="line">                   location.setSignal_strength(next.getString(8));</span><br><span class="line">                   location.setPower(next.getString(9));</span><br><span class="line">                   location.setAlarm_status(next.getString(10));</span><br><span class="line">                   location.setExtended_data(next.getString(11));</span><br><span class="line">                   locations.add(location);</span><br><span class="line">               &#125;</span><br><span class="line"></span><br><span class="line">               DeviceLocation deviceLocation = new DeviceLocation();</span><br><span class="line">               deviceLocation.setImei(key);</span><br><span class="line">               deviceLocation.setDateTime(&quot;2020-04-05&quot;);</span><br><span class="line">               deviceLocation.setLocation(JSON.toJSONString(locations));</span><br><span class="line">               ArrayList&lt;DeviceLocation&gt; deviceLocations = new ArrayList&lt;&gt;();</span><br><span class="line">               deviceLocations.add(deviceLocation);</span><br><span class="line">               return deviceLocations.iterator();</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;, Encoders.bean(DeviceLocation.class));</span><br><span class="line"></span><br><span class="line">       deviceLocationDataset.select(col(&quot;imei&quot;),col(&quot;dateTime&quot;),col(&quot;location&quot;).cast(&quot;String&quot;)).write().mode(SaveMode.Append).jdbc(url,&quot;test&quot;,properties);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一、spark-分组计算（转rdd-分组计算完再转回-dateset）&quot;&gt;&lt;a href=&quot;#一、spark-分组计算（转rdd-分组计算完再转回-dateset）&quot; class=&quot;headerlink&quot; title=&quot;一、spark 分组计算（转rdd 分组计算
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>shiro</title>
    <link href="http://yoursite.com/2020/02/26/shiro/"/>
    <id>http://yoursite.com/2020/02/26/shiro/</id>
    <published>2020-02-26T02:31:17.000Z</published>
    <updated>2020-02-26T02:31:17.432Z</updated>
    
    <content type="html"><![CDATA[<h1 id="shiro"><a href="#shiro" class="headerlink" title="shiro"></a>shiro</h1><blockquote><p>Apache Shiro 是一个强大易用的 Java 安全框架，提供了认证、授权、加密和会话管理等功能，对于任何一个应用程序，Shiro 都可以提供全面的安全管理服务。</p></blockquote><p><img src="/images/2020/02/25/3fbc6bf0-5773-11ea-b312-7dd32fa3bd34.png" alt="image.png"></p><blockquote><p>Authentication：身份认证 / 登录，验证用户是不是拥有相应的身份；</p></blockquote><p>Authorization：授权，即权限验证，验证某个已认证的用户是否拥有某个权限；即判断用户是否能做事情，常见的如：验证某个用户是否拥有某个角色。或者细粒度的验证某个用户对某个资源是否具有某个权限；</p><p>Session Manager：会话管理，即用户登录后就是一次会话，在没有退出之前，它的所有信息都在会话中；会话可以是普通 JavaSE 环境的，也可以是如 Web 环境的；</p><p>Cryptography：加密，保护数据的安全性，如密码加密存储到数据库，而不是明文存储；</p><p>Web Support：Web 支持，可以非常容易的集成到 Web 环境；</p><p>Caching：缓存，比如用户登录后，其用户信息、拥有的角色 / 权限不必每次去查，这样可以提高效率；</p><p>Concurrency：shiro 支持多线程应用的并发验证，即如在一个线程中开启另一个线程，能把权限自动传播过去；</p><p>Testing：提供测试支持；</p><p>Run As：允许一个用户假装为另一个用户（如果他们允许）的身份进行访问；</p><p>Remember Me：记住我，这个是非常常见的功能，即一次登录后，下次再来的话不用登录了。</p><p><img src="/images/2020/02/25/6d86ae60-5773-11ea-b312-7dd32fa3bd34.png" alt="image.png"></p><blockquote><p>Subject：主体，代表了当前 “用户”，这个用户不一定是一个具体的人，与当前应用交互的任何东西都是 Subject，如网络爬虫，机器人等；即一个抽象概念；所有 Subject 都绑定到 SecurityManager，与 Subject 的所有交互都会委托给 SecurityManager；可以把 Subject 认为是一个门面；SecurityManager 才是实际的执行者；</p></blockquote><p>SecurityManager：安全管理器；即所有与安全有关的操作都会与 SecurityManager 交互；且它管理着所有 Subject；可以看出它是 Shiro 的核心，它负责与后边介绍的其他组件进行交互，如果学习过 SpringMVC，你可以把它看成 DispatcherServlet 前端控制器；</p><p>Realm：域，Shiro 从从 Realm 获取安全数据（如用户、角色、权限），就是说 SecurityManager 要验证用户身份，那么它需要从 Realm 获取相应的用户进行比较以确定用户身份是否合法；也需要从 Realm 得到用户相应的角色 / 权限进行验证用户是否能进行操作；可以把 Realm 看成 DataSource，即安全数据源。</p><p>参考：<a href="https://www.w3cschool.cn/shiro/" target="_blank" rel="noopener">跟我学shiro</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;shiro&quot;&gt;&lt;a href=&quot;#shiro&quot; class=&quot;headerlink&quot; title=&quot;shiro&quot;&gt;&lt;/a&gt;shiro&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Apache Shiro 是一个强大易用的 Java 安全框架，提供了认证、授权、加密和会
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>权限设计管理</title>
    <link href="http://yoursite.com/2020/02/24/%E6%9D%83%E9%99%90%E8%AE%BE%E8%AE%A1%E7%AE%A1%E7%90%86/"/>
    <id>http://yoursite.com/2020/02/24/权限设计管理/</id>
    <published>2020-02-24T01:10:01.000Z</published>
    <updated>2020-02-26T03:09:42.487Z</updated>
    
    <content type="html"><![CDATA[<h2 id="基于RBAC（Resource-Based-Access-Control）"><a href="#基于RBAC（Resource-Based-Access-Control）" class="headerlink" title="基于RBAC（Resource-Based Access Control）"></a>基于RBAC（Resource-Based Access Control）</h2><h4 id="资源权限控制抽象为uri的访问控制（uri权限控制表）"><a href="#资源权限控制抽象为uri的访问控制（uri权限控制表）" class="headerlink" title="资源权限控制抽象为uri的访问控制（uri权限控制表）"></a>资源权限控制抽象为uri的访问控制（uri权限控制表）</h4><p>自增长id<br>uri(根据业务需要控制颗粒度，例如细可以精确到一条数据的访问，或者，粗可以只是控制一个页面的访问)<br>access_allow</p><h4 id="用户角色（user-role）"><a href="#用户角色（user-role）" class="headerlink" title="用户角色（user role）"></a>用户角色（user role）</h4><p>自增长id<br>用户角色描述</p><h4 id="用户组（user-group）"><a href="#用户组（user-group）" class="headerlink" title="用户组（user group）"></a>用户组（user group）</h4><p>自增长id<br>用户组描述</p><h4 id="用户（user）"><a href="#用户（user）" class="headerlink" title="用户（user）"></a>用户（user）</h4><p>自增长id<br>用户其他相关信息（用户名，password等等）</p><h4 id="用户角色（user-role）-uri访问权限集合（角色-uri权限关系表）"><a href="#用户角色（user-role）-uri访问权限集合（角色-uri权限关系表）" class="headerlink" title="用户角色（user role）-uri访问权限集合（角色-uri权限关系表）"></a>用户角色（user role）-uri访问权限集合（角色-uri权限关系表）</h4><p>用户角色id<br>uri权限id</p><h4 id="用户组（user-group）-uri访问权限集合（用户组-uri权限关系表）"><a href="#用户组（user-group）-uri访问权限集合（用户组-uri权限关系表）" class="headerlink" title="用户组（user group）-uri访问权限集合（用户组-uri权限关系表）"></a>用户组（user group）-uri访问权限集合（用户组-uri权限关系表）</h4><p>用户组id<br>uri权限id</p><h4 id="用户（user-）-uri访问权限集合（用户-uri权限关系表）"><a href="#用户（user-）-uri访问权限集合（用户-uri权限关系表）" class="headerlink" title="用户（user ）-uri访问权限集合（用户-uri权限关系表）"></a>用户（user ）-uri访问权限集合（用户-uri权限关系表）</h4><p>用户id<br>uri权限id</p><h4 id="用户组（user-group）-用户角色（user-role）集合（用户组-用户角色关系表）"><a href="#用户组（user-group）-用户角色（user-role）集合（用户组-用户角色关系表）" class="headerlink" title="用户组（user group）- 用户角色（user role）集合（用户组-用户角色关系表）"></a>用户组（user group）- 用户角色（user role）集合（用户组-用户角色关系表）</h4><p>用户角色id<br>用户组id</p><h4 id="用户（user）-用户组（user-group）集合（用户-用户组关系表）"><a href="#用户（user）-用户组（user-group）集合（用户-用户组关系表）" class="headerlink" title="用户（user）- 用户组（user group）集合（用户-用户组关系表）"></a>用户（user）- 用户组（user group）集合（用户-用户组关系表）</h4><p>用户id<br>用户组id</p><h4 id="用户（user）-用户角色（user-role）集合（用户-用户角色表）"><a href="#用户（user）-用户角色（user-role）集合（用户-用户角色表）" class="headerlink" title="用户（user）- 用户角色（user role）集合（用户-用户角色表）"></a>用户（user）- 用户角色（user role）集合（用户-用户角色表）</h4><p>用户角色id<br>用户id</p><p><img src="/images/2020/02/19/44fa5c10-52e8-11ea-8c8e-7b6faf42a2fd.png" alt="image.png"></p><p><img src="/images/2020/02/22/68cdca20-5516-11ea-a50a-c34d50658225.png" alt="image.png"></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> Navicat Premium Data Transfer</span><br><span class="line"></span><br><span class="line"> Source Server         : 本地</span><br><span class="line"> Source Server Type    : MySQL</span><br><span class="line"> Source Server Version : 80012</span><br><span class="line"> Source Host           : localhost:3306</span><br><span class="line"> Source Schema         : gps_test</span><br><span class="line"></span><br><span class="line"> Target Server Type    : MySQL</span><br><span class="line"> Target Server Version : 80012</span><br><span class="line"> File Encoding         : 65001</span><br><span class="line"></span><br><span class="line"> Date: 21/02/2020 15:14:54</span><br><span class="line">*/</span><br><span class="line"></span><br><span class="line">SET NAMES utf8mb4;</span><br><span class="line">SET FOREIGN_KEY_CHECKS = 0;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for permission</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `permission`;</span><br><span class="line">CREATE TABLE `permission`  (</span><br><span class="line">  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;权限ID&apos;,</span><br><span class="line">  `parent_id` bigint(20) DEFAULT NULL COMMENT &apos;所属父级权限ID&apos;,</span><br><span class="line">  `code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;权限唯一CODE代码&apos;,</span><br><span class="line">  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;权限名称&apos;,</span><br><span class="line">  `dsca` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;权限描述&apos;,</span><br><span class="line">  `category` tinyint(1) DEFAULT NULL COMMENT &apos;权限类别&apos;,</span><br><span class="line">  `uri` bigint(20) DEFAULT NULL COMMENT &apos;URL规则&apos;,</span><br><span class="line">  `create_time` datetime(0) DEFAULT NULL COMMENT &apos;创建时间&apos;,</span><br><span class="line">  `creator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;创建人&apos;,</span><br><span class="line">  `update_time` datetime(0) DEFAULT NULL COMMENT &apos;更新时间&apos;,</span><br><span class="line">  `regenerator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;更新者&apos;,</span><br><span class="line">  `del_flag` tinyint(1) UNSIGNED ZEROFILL DEFAULT 0 COMMENT &apos;逻辑删除:0=未删除,1=已删除&apos;,</span><br><span class="line">  PRIMARY KEY (`id`) USING BTREE,</span><br><span class="line">  INDEX `parent_id`(`parent_id`) USING BTREE COMMENT &apos;父级权限ID&apos;,</span><br><span class="line">  INDEX `code`(`code`) USING BTREE COMMENT &apos;权限CODE代码&apos;</span><br><span class="line">) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = &apos;权限&apos; ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for role</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `role`;</span><br><span class="line">CREATE TABLE `role`  (</span><br><span class="line">  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;角色ID&apos;,</span><br><span class="line">  `code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;角色唯一CODE代码&apos;,</span><br><span class="line">  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;角色名称&apos;,</span><br><span class="line">  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;角色描述&apos;,</span><br><span class="line">  `create_time` datetime(0) DEFAULT NULL COMMENT &apos;创建时间&apos;,</span><br><span class="line">  `creator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;创建人&apos;,</span><br><span class="line">  `update_time` datetime(0) DEFAULT NULL COMMENT &apos;更新时间&apos;,</span><br><span class="line">  `regenerator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;更改者&apos;,</span><br><span class="line">  `del_flag` tinyint(1) UNSIGNED ZEROFILL DEFAULT 0 COMMENT &apos;逻辑删除:0=未删除,1=已删除&apos;,</span><br><span class="line">  `type` tinyint(1) NOT NULL DEFAULT 1 COMMENT &apos;0：超管、1：管理员、2：普通人员&apos;,</span><br><span class="line">  PRIMARY KEY (`id`) USING BTREE,</span><br><span class="line">  INDEX `code`(`code`) USING BTREE COMMENT &apos;权限CODE代码&apos;</span><br><span class="line">) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = &apos;角色&apos; ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for role_permission</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `role_permission`;</span><br><span class="line">CREATE TABLE `role_permission`  (</span><br><span class="line">  `role_id` int(11) NOT NULL COMMENT &apos;角色id&apos;,</span><br><span class="line">  `permission_id` int(11) DEFAULT NULL COMMENT &apos;权限id&apos;</span><br><span class="line">) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user`;</span><br><span class="line">CREATE TABLE `user`  (</span><br><span class="line">  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;用户ID&apos;,</span><br><span class="line">  `state` tinyint(1) DEFAULT NULL COMMENT &apos;用户状态:0=正常,1=禁用&apos;,</span><br><span class="line">  `user_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;姓名&apos;,</span><br><span class="line">  `user_tel_number` varchar(11) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;手机号码&apos;,</span><br><span class="line">  `salt` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;密码加盐&apos;,</span><br><span class="line">  `password` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;登录密码&apos;,</span><br><span class="line">  `create_time` datetime(0) DEFAULT NULL COMMENT &apos;创建时间&apos;,</span><br><span class="line">  `creator` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;创建人&apos;,</span><br><span class="line">  `update_time` datetime(0) DEFAULT NULL COMMENT &apos;更新时间&apos;,</span><br><span class="line">  `regenerator` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;更新者&apos;,</span><br><span class="line">  `del_flag` tinyint(1) UNSIGNED ZEROFILL DEFAULT 0 COMMENT &apos;逻辑删除:0=未删除,1=已删除&apos;,</span><br><span class="line">  PRIMARY KEY (`id`) USING BTREE</span><br><span class="line">) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = &apos;用户&apos; ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user_group</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user_group`;</span><br><span class="line">CREATE TABLE `user_group`  (</span><br><span class="line">  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;ID&apos;,</span><br><span class="line">  `parent_id` bigint(20) DEFAULT NULL COMMENT &apos;所属父级用户组ID&apos;,</span><br><span class="line">  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;用户组名称&apos;,</span><br><span class="line">  `code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;用户组CODE唯一代码&apos;,</span><br><span class="line">  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;用户组描述&apos;,</span><br><span class="line">  `create_time` datetime(0) DEFAULT NULL COMMENT &apos;创建时间&apos;,</span><br><span class="line">  `creator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;创建人&apos;,</span><br><span class="line">  `update_time` datetime(0) DEFAULT NULL COMMENT &apos;更新时间&apos;,</span><br><span class="line">  `regenerator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;更新者&apos;,</span><br><span class="line">  `del_flag` tinyint(1) UNSIGNED ZEROFILL DEFAULT 0 COMMENT &apos;逻辑删除:0=未删除,1=已删除&apos;,</span><br><span class="line">  PRIMARY KEY (`id`) USING BTREE,</span><br><span class="line">  INDEX `parent_id`(`parent_id`) USING BTREE COMMENT &apos;父级用户组ID&apos;,</span><br><span class="line">  INDEX `code`(`code`) USING BTREE COMMENT &apos;用户组CODE代码&apos;</span><br><span class="line">) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = &apos;用户组&apos; ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user_group_role</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user_group_role`;</span><br><span class="line">CREATE TABLE `user_group_role`  (</span><br><span class="line">  `user_group_id` int(11) NOT NULL COMMENT &apos;用户组id&apos;,</span><br><span class="line">  `role_id` int(11) DEFAULT NULL COMMENT &apos;角色id&apos;</span><br><span class="line">) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user_role</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user_role`;</span><br><span class="line">CREATE TABLE `user_role`  (</span><br><span class="line">  `user_id` int(11) NOT NULL COMMENT &apos;用户id&apos;,</span><br><span class="line">  `role_id` int(11) DEFAULT NULL COMMENT &apos;角色id&apos;</span><br><span class="line">) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user_user_group</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user_user_group`;</span><br><span class="line">CREATE TABLE `user_user_group`  (</span><br><span class="line">  `user_id` int(11) NOT NULL COMMENT &apos;用户id&apos;,</span><br><span class="line">  `user_group_id` int(11) DEFAULT NULL COMMENT &apos;用户组id&apos;</span><br><span class="line">) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">SET FOREIGN_KEY_CHECKS = 1;</span><br></pre></td></tr></table></figure><blockquote><p>第二版：权限设计表结构（主要新增了user_permission表 和 user_group_permission表 用于灵活的控制权限修改和授权操作，user_group 用户组表 parent_id属性的删除，主要区别于组织架构的系统，能够更加通用化设计）</p></blockquote><p><img src="/images/2020/02/24/e109f130-56a1-11ea-a50a-c34d50658225.png" alt="image.png"></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br></pre></td><td class="code"><pre><span class="line">/*</span><br><span class="line"> Navicat Premium Data Transfer</span><br><span class="line"></span><br><span class="line"> Source Server         : 本地</span><br><span class="line"> Source Server Type    : MySQL</span><br><span class="line"> Source Server Version : 80012</span><br><span class="line"> Source Host           : localhost:3306</span><br><span class="line"> Source Schema         : gps_test</span><br><span class="line"></span><br><span class="line"> Target Server Type    : MySQL</span><br><span class="line"> Target Server Version : 80012</span><br><span class="line"> File Encoding         : 65001</span><br><span class="line"></span><br><span class="line"> Date: 24/02/2020 08:51:04</span><br><span class="line">*/</span><br><span class="line"></span><br><span class="line">SET NAMES utf8mb4;</span><br><span class="line">SET FOREIGN_KEY_CHECKS = 0;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for permission</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `permission`;</span><br><span class="line">CREATE TABLE `permission`  (</span><br><span class="line">  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;权限ID&apos;,</span><br><span class="line">  `parent_id` bigint(20) DEFAULT NULL COMMENT &apos;所属父级权限ID&apos;,</span><br><span class="line">  `code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;权限唯一CODE代码&apos;,</span><br><span class="line">  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;权限名称&apos;,</span><br><span class="line">  `dsca` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;权限描述&apos;,</span><br><span class="line">  `category` tinyint(1) DEFAULT NULL COMMENT &apos;权限类别&apos;,</span><br><span class="line">  `uri` bigint(20) DEFAULT NULL COMMENT &apos;URL规则&apos;,</span><br><span class="line">  `create_time` datetime(0) DEFAULT NULL COMMENT &apos;创建时间&apos;,</span><br><span class="line">  `creator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;创建人&apos;,</span><br><span class="line">  `update_time` datetime(0) DEFAULT NULL COMMENT &apos;更新时间&apos;,</span><br><span class="line">  `regenerator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;更新者&apos;,</span><br><span class="line">  `del_flag` tinyint(1) UNSIGNED ZEROFILL DEFAULT 0 COMMENT &apos;逻辑删除:0=未删除,1=已删除&apos;,</span><br><span class="line">  PRIMARY KEY (`id`) USING BTREE,</span><br><span class="line">  INDEX `parent_id`(`parent_id`) USING BTREE COMMENT &apos;父级权限ID&apos;,</span><br><span class="line">  INDEX `code`(`code`) USING BTREE COMMENT &apos;权限CODE代码&apos;</span><br><span class="line">) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = &apos;权限&apos; ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for role</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `role`;</span><br><span class="line">CREATE TABLE `role`  (</span><br><span class="line">  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;角色ID&apos;,</span><br><span class="line">  `code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;角色唯一CODE代码&apos;,</span><br><span class="line">  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;角色名称&apos;,</span><br><span class="line">  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;角色描述&apos;,</span><br><span class="line">  `create_time` datetime(0) DEFAULT NULL COMMENT &apos;创建时间&apos;,</span><br><span class="line">  `creator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;创建人&apos;,</span><br><span class="line">  `update_time` datetime(0) DEFAULT NULL COMMENT &apos;更新时间&apos;,</span><br><span class="line">  `regenerator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;更改者&apos;,</span><br><span class="line">  `del_flag` tinyint(1) UNSIGNED ZEROFILL DEFAULT 0 COMMENT &apos;逻辑删除:0=未删除,1=已删除&apos;,</span><br><span class="line">  `type` tinyint(1) NOT NULL DEFAULT 1 COMMENT &apos;0：超管、1：管理员、2：普通人员&apos;,</span><br><span class="line">  PRIMARY KEY (`id`) USING BTREE,</span><br><span class="line">  INDEX `code`(`code`) USING BTREE COMMENT &apos;权限CODE代码&apos;</span><br><span class="line">) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = &apos;角色&apos; ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for role_permission</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `role_permission`;</span><br><span class="line">CREATE TABLE `role_permission`  (</span><br><span class="line">  `role_id` int(11) NOT NULL COMMENT &apos;角色id&apos;,</span><br><span class="line">  `permission_id` int(11) DEFAULT NULL COMMENT &apos;权限id&apos;</span><br><span class="line">) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user`;</span><br><span class="line">CREATE TABLE `user`  (</span><br><span class="line">  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;用户ID&apos;,</span><br><span class="line">  `state` tinyint(1) DEFAULT NULL COMMENT &apos;用户状态:0=正常,1=禁用&apos;,</span><br><span class="line">  `user_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;姓名&apos;,</span><br><span class="line">  `user_tel_number` varchar(11) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;手机号码&apos;,</span><br><span class="line">  `salt` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;密码加盐&apos;,</span><br><span class="line">  `password` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;登录密码&apos;,</span><br><span class="line">  `create_time` datetime(0) DEFAULT NULL COMMENT &apos;创建时间&apos;,</span><br><span class="line">  `creator` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;创建人&apos;,</span><br><span class="line">  `update_time` datetime(0) DEFAULT NULL COMMENT &apos;更新时间&apos;,</span><br><span class="line">  `regenerator` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;更新者&apos;,</span><br><span class="line">  `del_flag` tinyint(1) UNSIGNED ZEROFILL DEFAULT 0 COMMENT &apos;逻辑删除:0=未删除,1=已删除&apos;,</span><br><span class="line">  PRIMARY KEY (`id`) USING BTREE</span><br><span class="line">) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = &apos;用户&apos; ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user_group</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user_group`;</span><br><span class="line">CREATE TABLE `user_group`  (</span><br><span class="line">  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;ID&apos;,</span><br><span class="line">  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;用户组名称&apos;,</span><br><span class="line">  `code` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;用户组CODE唯一代码&apos;,</span><br><span class="line">  `desc` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;用户组描述&apos;,</span><br><span class="line">  `create_time` datetime(0) DEFAULT NULL COMMENT &apos;创建时间&apos;,</span><br><span class="line">  `creator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;创建人&apos;,</span><br><span class="line">  `update_time` datetime(0) DEFAULT NULL COMMENT &apos;更新时间&apos;,</span><br><span class="line">  `regenerator` varchar(36) CHARACTER SET utf8 COLLATE utf8_general_ci DEFAULT NULL COMMENT &apos;更新者&apos;,</span><br><span class="line">  `del_flag` tinyint(1) UNSIGNED ZEROFILL DEFAULT 0 COMMENT &apos;逻辑删除:0=未删除,1=已删除&apos;,</span><br><span class="line">  PRIMARY KEY (`id`) USING BTREE,</span><br><span class="line">  INDEX `code`(`code`) USING BTREE COMMENT &apos;用户组CODE代码&apos;</span><br><span class="line">) ENGINE = InnoDB AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = &apos;用户组&apos; ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user_group_permission</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user_group_permission`;</span><br><span class="line">CREATE TABLE `user_group_permission`  (</span><br><span class="line">  `user_group_id` int(11) NOT NULL COMMENT &apos;用户组id&apos;,</span><br><span class="line">  `permission_id` int(11) DEFAULT NULL COMMENT &apos;权限id&apos;</span><br><span class="line">) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user_group_role</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user_group_role`;</span><br><span class="line">CREATE TABLE `user_group_role`  (</span><br><span class="line">  `user_group_id` int(11) NOT NULL COMMENT &apos;用户组id&apos;,</span><br><span class="line">  `role_id` int(11) DEFAULT NULL COMMENT &apos;角色id&apos;</span><br><span class="line">) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user_permission</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user_permission`;</span><br><span class="line">CREATE TABLE `user_permission`  (</span><br><span class="line">  `user_id` int(11) NOT NULL COMMENT &apos;用户id&apos;,</span><br><span class="line">  `permission_id` int(11) DEFAULT NULL COMMENT &apos;权限id&apos;</span><br><span class="line">) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user_role</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user_role`;</span><br><span class="line">CREATE TABLE `user_role`  (</span><br><span class="line">  `user_id` int(11) NOT NULL COMMENT &apos;用户id&apos;,</span><br><span class="line">  `role_id` int(11) DEFAULT NULL COMMENT &apos;角色id&apos;</span><br><span class="line">) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">-- ----------------------------</span><br><span class="line">-- Table structure for user_user_group</span><br><span class="line">-- ----------------------------</span><br><span class="line">DROP TABLE IF EXISTS `user_user_group`;</span><br><span class="line">CREATE TABLE `user_user_group`  (</span><br><span class="line">  `user_id` int(11) NOT NULL COMMENT &apos;用户id&apos;,</span><br><span class="line">  `user_group_id` int(11) DEFAULT NULL COMMENT &apos;用户组id&apos;</span><br><span class="line">) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;</span><br><span class="line"></span><br><span class="line">SET FOREIGN_KEY_CHECKS = 1;</span><br></pre></td></tr></table></figure><p><a href="https://www.processon.com/view/link/5e4c8ffce4b00aefb7e77730%20" target="_blank" rel="noopener">设计表逻辑图</a></p><p><img src="/images/2020/02/26/46e26010-5845-11ea-9939-157051740e67.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;基于RBAC（Resource-Based-Access-Control）&quot;&gt;&lt;a href=&quot;#基于RBAC（Resource-Based-Access-Control）&quot; class=&quot;headerlink&quot; title=&quot;基于RBAC（Resource-Ba
      
    
    </summary>
    
      <category term="后台" scheme="http://yoursite.com/categories/%E5%90%8E%E5%8F%B0/"/>
    
    
      <category term="权限设计" scheme="http://yoursite.com/tags/%E6%9D%83%E9%99%90%E8%AE%BE%E8%AE%A1/"/>
    
  </entry>
  
  <entry>
    <title>2019年度总结</title>
    <link href="http://yoursite.com/2020/01/18/2019%E5%B9%B4%E5%BA%A6%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2020/01/18/2019年度总结/</id>
    <published>2020-01-18T03:21:20.000Z</published>
    <updated>2020-01-19T07:54:27.413Z</updated>
    
    <content type="html"><![CDATA[<p>1.回顾<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">主要作业</span><br><span class="line">1.机器学习（Python，spark ml）</span><br><span class="line">2.成品码大数据分析（Scala ，spark sql ,hive）</span><br><span class="line">3.微服务架构（spring boot ，spring cloud等）</span><br><span class="line">4.蓝牙定位（netty -》spark streaming ， structured streaming -&gt; redis,mysql --&gt; websocket）</span><br><span class="line">5.电工 （redis ，flink，java）</span><br></pre></td></tr></table></figure></p><p>2.详细分析</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  2019学了很多，但真正精通，学的深的不多。</span><br><span class="line">1.年初学习了机器学习，主要是python的机器学习的包，但之后未用到实际的项目中，现在基本忘的差不多了，也就不多说了。</span><br><span class="line">2.成品码大数据分析项目，主要分为两部分，前一个月主要熟悉项目，这个项目是半路接手，准备第二期，我主要负责的数据处理部分。将需要的数据通过spark sql 处理形成中间结果表，给到后台进一步处理。</span><br><span class="line">后半部分则是彻底整合家用，商用，生活电器形成一张大而完整的表。</span><br><span class="line">主要学习到了spark 中 dataframe中的api,常用的有 spark.table获取hive数据仓库中的表，.where用来筛选符合条件的记录或者用.filter也是同样的作用，.startWith用来获取字段开始符合的条件，还有substr,na.fill,withColumn,lit,join，seq(),union等等，</span><br><span class="line">在项目中使用正则匹配进行数据处理时还是不够灵活，在与洪工对接需求时，需求较明确，反馈问题也能够及时得到回应。</span><br><span class="line">3.微服务架构，最近微服务也很流行，主要了解了spring boot 和 spring cloud 相关的知识，仅限于简单的使用，没有在复杂的场景中运用。</span><br><span class="line">4.蓝牙定位是本年最主要（即时间最久）的项目，从数据的接入到数据处理生成实时的定位信息传入到前端，在这个项目中学到了很多，也接触到了之前未接触到的的东西，比如kafak集群搭建（三个节点没有权限zk自己自带的），spark 集群（三个节点standalone模式）搭建，只是单独的spark集群没有hdfs。</span><br><span class="line">同时也接触到netty，网络之间数据传输（tcp/udp）数据传输。在做项目是由于前期对数据对接时考虑的问题不是很充足，以及对netty和kafak等一些参数不够了解耽误了不少时间，其中关于流处理的接触让我对流处理的一些框架有一定的了解，</span><br><span class="line">同时也了解了flink这个流处理的利器。总的来说还是完成了这个项目，尽管这个项目总是在关键时刻出现问题，但都合理的解决了。</span><br><span class="line">5.电工这个项目是临时接收的，当初只是简单的处理了一个上报的数据，替换相关数据源，将mysql数据源换成redis数据源，</span><br><span class="line">这里简单说明下，由于上个项目了解到redis，加之这个需求改动不大所有=以很快解决了，之后再很长一段时间是在看之前交接人写的代码，插一句由于项目交接多手，而且项目没有正规需求文档和相关的数据字典，难受。</span><br><span class="line">之后接了个上报收线重量的需求，由于之前的种种，以及flink窗口处理的能力出众，所以选择flink，数据源从activemq中读取，处理后上报给webservice服务。</span><br><span class="line">大致这样。下面配上几张数据流程图。</span><br></pre></td></tr></table></figure><p>1.电工数据流图<br><img src="/images/2020/01/18/399a4c70-39c7-11ea-b221-c32b78c1642c.png" alt="image.png"><br><img src="/images/2020/01/18/5d622650-39c7-11ea-b221-c32b78c1642c.png" alt="image.png"></p><p>2.蓝牙定位数据流图<br><img src="/images/2020/01/18/756dd9b0-39c7-11ea-b221-c32b78c1642c.png" alt="image.png"></p><p>3.微服务组件关系图<br><img src="/images/2020/01/18/d1e592a0-39c7-11ea-b221-c32b78c1642c.png" alt="image.png"></p><p>3.展望<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">多读书多看报，少吃零食多睡觉。</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.回顾&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span
      
    
    </summary>
    
      <category term="学习" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="总结" scheme="http://yoursite.com/tags/%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>flink sources</title>
    <link href="http://yoursite.com/2020/01/10/flink-sources/"/>
    <id>http://yoursite.com/2020/01/10/flink-sources/</id>
    <published>2020-01-10T09:19:36.000Z</published>
    <updated>2020-01-10T09:20:13.894Z</updated>
    
    <content type="html"><![CDATA[<ol><li>activemq </li></ol><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot;</span><br><span class="line">         xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line"></span><br><span class="line">    &lt;groupId&gt;com.gree.bdc&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-table-api&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;flink-streaming-java_2.11&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.8.0&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;flink-java&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.8.0&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.bahir&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;flink-connector-activemq_2.11&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.0&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line">package com.gree.bdc.io;</span><br><span class="line"></span><br><span class="line">import org.apache.activemq.ActiveMQConnectionFactory;</span><br><span class="line">import org.apache.flink.streaming.api.functions.source.SourceFunction;</span><br><span class="line"></span><br><span class="line">import javax.jms.*;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 获取activeMQ数据</span><br><span class="line"> */</span><br><span class="line">public class FlinkActiveMQStreamSources implements SourceFunction &#123;</span><br><span class="line"></span><br><span class="line">    private Connection connection = null;</span><br><span class="line">    private Session session = null;</span><br><span class="line">    private MessageConsumer messageConsumer = null;</span><br><span class="line">    private boolean running = Boolean.TRUE;</span><br><span class="line"></span><br><span class="line">    public void run(SourceContext ctx) throws Exception &#123;</span><br><span class="line">        ActiveMQConnectionFactory activeMQConnectionFactory = new ActiveMQConnectionFactory(ActiveMQConnectionFactory.DEFAULT_USER, ActiveMQConnectionFactory.DEFAULT_PASSWORD, ActiveMQConnectionFactory.DEFAULT_BROKER_URL);</span><br><span class="line">        try &#123;</span><br><span class="line">            connection = activeMQConnectionFactory.createConnection();</span><br><span class="line">            connection.start();</span><br><span class="line">            session = connection.createSession(Boolean.FALSE,Session.AUTO_ACKNOWLEDGE);</span><br><span class="line">            String queueName = &quot;test?consumer.exclusive=true&quot;;</span><br><span class="line">            Destination destination  = session.createQueue(queueName);</span><br><span class="line">            messageConsumer = session.createConsumer(destination);</span><br><span class="line"></span><br><span class="line">            while (running)&#123;</span><br><span class="line">                TextMessage message = (TextMessage)messageConsumer.receive(60 * 100);</span><br><span class="line">                if (message instanceof TextMessage)&#123;</span><br><span class="line">                    TextMessage textMessage =(TextMessage) message;</span><br><span class="line">                    String text = textMessage.getText();</span><br><span class="line">                    ctx.collect(text);</span><br><span class="line">                &#125;else &#123;</span><br><span class="line">                    System.out.println(&quot;未收到消息！！！&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;catch (Exception e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;finally &#123;</span><br><span class="line">            try &#123;</span><br><span class="line">                messageConsumer.close();</span><br><span class="line">                session.close();</span><br><span class="line">                connection.close();</span><br><span class="line">            &#125;catch (JMSException e)&#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;finally &#123;</span><br><span class="line">                Thread.sleep(10 * 1000);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void cancel() &#123;</span><br><span class="line">        running = Boolean.FALSE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;activemq &lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span c
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>nifi process 介绍与使用</title>
    <link href="http://yoursite.com/2020/01/09/nifi-process-%E4%BB%8B%E7%BB%8D%E4%B8%8E%E4%BD%BF%E7%94%A8/"/>
    <id>http://yoursite.com/2020/01/09/nifi-process-介绍与使用/</id>
    <published>2020-01-09T02:02:54.000Z</published>
    <updated>2020-01-09T02:19:32.936Z</updated>
    
    <content type="html"><![CDATA[<ol><li><strong>GetJMSQueue</strong></li></ol><p><img src="/images/2020/01/09/ae19c350-3283-11ea-80df-39774ea2e31e.png" alt="image.png"></p><p>作用：读取activeMQ消息队列的数据</p><p><img src="/images/2020/01/09/daf9f3e0-3283-11ea-80df-39774ea2e31e.png" alt="image.png"></p><p>主要 URL ：tcp://localhost:61616 需要将ip地址写入到host文件中<br>Destination Name : 消息队列的名称</p><p>2.<strong>Mysql –&gt; kafka</strong></p><p><img src="/images/2020/01/09/680cc280-3284-11ea-80df-39774ea2e31e.png" alt="image.png"></p><p>主要读取mysql数据 ExecuteSQL<br><img src="/images/2020/01/09/a6f8da60-3284-11ea-80df-39774ea2e31e.png" alt="image.png"><br>主要配置 Database Connection Pooling Service </p><p><img src="/images/2020/01/09/d80ec560-3284-11ea-80df-39774ea2e31e.png" alt="image.png"></p><p>配置 kafaka 生产者<br><img src="/images/2020/01/09/3b494c40-3285-11ea-80df-39774ea2e31e.png" alt="image.png"></p><p>3.<strong>Mysql增量 –》kafka</strong><br><img src="/images/2020/01/09/9ac82ab0-3285-11ea-80df-39774ea2e31e.png" alt="image.png"></p><p>主要将 ExecuteSQL 替换为 QueryDatabaseTable<br><img src="/images/2020/01/09/fbe80ef0-3285-11ea-80df-39774ea2e31e.png" alt="image.png"></p><p>主要配置Maximum-value Columns 增量字段，nifi每次请求数据时都取前一次字段数据后的数据，保证增量读取数据，避免重复读。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;strong&gt;GetJMSQueue&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&quot;/images/2020/01/09/ae19c350-3283-11ea-80df-39774ea2e31e.png&quot; alt=&quot;image.png&quot;&gt;&lt;
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="NIFI" scheme="http://yoursite.com/tags/NIFI/"/>
    
  </entry>
  
  <entry>
    <title>Flink DataStream Api 编程</title>
    <link href="http://yoursite.com/2019/12/30/Flink-DataStream-Api-%E7%BC%96%E7%A8%8B/"/>
    <id>http://yoursite.com/2019/12/30/Flink-DataStream-Api-编程/</id>
    <published>2019-12-30T06:56:27.000Z</published>
    <updated>2019-12-31T01:38:24.414Z</updated>
    
    <content type="html"><![CDATA[<h2 id="流处理基本概念"><a href="#流处理基本概念" class="headerlink" title="流处理基本概念"></a>流处理基本概念</h2><blockquote><p>对于什么是流处理，从不同的角度有不同的定义。其实流处理与批处理这两个概念是对立统一的，它们的关系有点类似于对于 Java 中的 ArrayList 中的元素，是直接看作一个有限数据集并用下标去访问，还是用迭代器去访问。<br>  流处理系统本身有很多自己的特点。一般来说，由于需要支持无限数据集的处理，流处理系统一般采用一种数据驱动的处理方式。它会提前设置一些算子，然后等到数据到达后对数据进行处理。为了表达复杂的计算逻辑，包括 Flink 在内的分布式流处理引擎一般采用 DAG 图来表示整个计算逻辑，其中 DAG 图中的每一个点就代表一个基本的逻辑单元，也就是前面说的算子。由于计算逻辑被组织成有向图，数据会按照边的方向，从一些特殊的 Source 节点流入系统，然后通过网络传输、本地传输等不同的数据传输方式在算子之间进行发送和处理，最后会通过另外一些特殊的 Sink 节点将计算结果发送到某个外部系统或数据库中。</p></blockquote><blockquote><p>总结一下：流数据本身就是源源不断的产生，流数据处理就是提前设置一些算子，然后等待数据流到这些提前设置的算子进行处理的过程。而实际在分布式的情况下，需要考虑不同的实例之间数据传输。</p></blockquote><p><img src="/images/2019/12/30/230086f0-2ad1-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p>对于实际的分布式流处理引擎，它们的实际运行时物理模型要更复杂一些，这是由于每个算子都可能有多个实例。如图 2 所示，作为 Source 的 A 算子有两个实例，中间算子 C 也有两个实例。在逻辑模型中，A 和 B 是 C 的上游节点，而在对应的物理逻辑中，C 的所有实例和 A、B 的所有实例之间可能都存在数据交换。在物理模型中，我们会根据计算逻辑，采用系统自动优化或人为指定的方式将计算工作分布到不同的实例中。只有当算子实例分布到不同进程上时，才需要通过网络进行数据传输，而同一进程中的多个实例之间的数据传输通常是不需要通过网络的。</p></blockquote><h2 id="Flink-DataStram-API-概览"><a href="#Flink-DataStram-API-概览" class="headerlink" title="Flink DataStram API 概览"></a>Flink DataStram API 概览</h2><p> 首先用一个简单例子说明：</p><blockquote><p>//1、设置运行环境<br>StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();<br>//2、配置数据源读取数据<br>DataStream<string> text = env.readTextFile (“input”);<br>//3、进行一系列转换<br>DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; counts = text.flatMap(new Tokenizer()).keyBy(0).sum(1);<br>//4、配置数据汇写出数据<br>counts.writeAsText(“output”);<br>//5、提交执行<br>env.execute(“Streaming WordCount”);</string></p></blockquote><blockquote><p> 为了实现流式 Word Count，我们首先要先获得一个 StreamExecutionEnvironment 对象。它是我们构建图过程中的上下文对象。基于这个对象，我们可以添加一些算子。对于流处理程度，我们一般需要首先创建一个数据源去接入数据。在这个例子中，我们使用了 Environment 对象中内置的读取文件的数据源。这一步之后，我们拿到的是一个 DataStream 对象，它可以看作一个无限的数据集，可以在该集合上进行一序列的操作。例如，在 Word Count 例子中，我们首先将每一条记录（即文件中的一行）分隔为单词，这是通过 FlatMap 操作来实现的。调用 FlatMap 将会在底层的 DAG 图中添加一个 FlatMap 算子。然后，我们得到了一个记录是单词的流。我们将流中的单词进行分组（keyBy），然后累积计算每一个单词的数据（sum(1)）。计算出的单词的数据组成了一个新的流，我们将它写入到输出文件中。<br>最后，我们需要调用 env#execute 方法来开始程序的执行。需要强调的是，前面我们调用的所有方法，都不是在实际处理数据，而是在构通表达计算逻辑的 DAG 图。只有当我们将整个图构建完成并显式的调用 Execute 方法后，框架才会把计算图提供到集群中，接入数据并执行实际的逻辑。<br>基于流式 Word Count 的例子可以看出，基于 Flink 的 DataStream API 来编写流处理程序一般需要三步：通过 Source 接入数据、进行一系统列的处理以及将数据写出。最后，不要忘记显式调用 Execute 方式，否则前面编写的逻辑并不会真正执行。</p></blockquote><p><img src="/images/2019/12/30/e5920700-2ad3-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p>从上面的例子中还可以看出，Flink DataStream API 的核心，就是代表流数据的 DataStream 对象。整个计算逻辑图的构建就是围绕调用 DataStream 对象上的不同操作产生新的 DataStream 对象展开的。整体来说，DataStream 上的操作可以分为四类。第一类是对于单条记录的操作，比如筛除掉不符合要求的记录（Filter 操作），或者将每条记录都做一个转换（Map 操作）。第二类是对多条记录的操作。比如说统计一个小时内的订单总成交量，就需要将一个小时内的所有订单记录的成交量加到一起。为了支持这种类型的操作，就得通过 Window 将需要的记录关联到一起进行处理。第三类是对多个流进行操作并转换为单个流。例如，多个流可以通过 Union、Join 或 Connect 等操作合到一起。这些操作合并的逻辑不同，但是它们最终都会产生了一个新的统一的流，从而可以进行一些跨流的操作。最后， DataStream 还支持与合并对称的操作，即把一个流按一定规则拆分为多个流（Split 操作），每个流是之前流的一个子集，这样我们就可以对不同的流作不同的处理。</p></blockquote><p> <img src="/images/2019/12/30/7d4e2c90-2ad4-11ea-80df-39774ea2e31e.png" alt="image.png"></p><p>参考文献：<a href="https://ververica.cn/developers/apache-flink-basic-zero-iii-datastream-api-programming/" target="_blank" rel="noopener">Apache Flink 零基础入门（四）：DataStream API 编程</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;流处理基本概念&quot;&gt;&lt;a href=&quot;#流处理基本概念&quot; class=&quot;headerlink&quot; title=&quot;流处理基本概念&quot;&gt;&lt;/a&gt;流处理基本概念&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;对于什么是流处理，从不同的角度有不同的定义。其实流处理与批处理这两个概念是
      
    
    </summary>
    
      <category term="学习" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
      <category term="学习" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>scala 引包中遇到问题</title>
    <link href="http://yoursite.com/2019/12/29/scala-%E5%BC%95%E5%8C%85%E4%B8%AD%E9%81%87%E5%88%B0%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2019/12/29/scala-引包中遇到问题/</id>
    <published>2019-12-29T01:53:45.000Z</published>
    <updated>2019-12-29T01:53:45.858Z</updated>
    
    <content type="html"><![CDATA[<p>1.Error:(12, 30) could not find implicit value for evidence parameter of type org.apache.flink.api.common.typeinfo.TypeInformation[(String, String)]     val value = env.addSource(new HBaseReader)</p><blockquote><p>解决方法：import org.apache.flink.api.scala._</p></blockquote><p>2.Scala编程中常见错误：Error:(28, 21) value foreach is not a member of java.util.List[String]</p><blockquote><p>解决方法：因为 Java 集合类型在 Scala 操作时没有 foreach 方法, 所以需要将其转换为Scala的集合类型,<br>因此需要在代码中加入如下内容(Scala支持与Java的隐式转换),<br>import scala.collection.JavaConversions._</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.Error:(12, 30) could not find implicit value for evidence parameter of type org.apache.flink.api.common.typeinfo.TypeInformation[(Strin
      
    
    </summary>
    
      <category term="程序语言" scheme="http://yoursite.com/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="scala" scheme="http://yoursite.com/tags/scala/"/>
    
  </entry>
  
  <entry>
    <title>Flink 基本概念（有状态流式处理引擎）</title>
    <link href="http://yoursite.com/2019/12/27/Flink-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%EF%BC%88%E6%9C%89%E7%8A%B6%E6%80%81%E6%B5%81%E5%BC%8F%E5%A4%84%E7%90%86%E5%BC%95%E6%93%8E%EF%BC%89/"/>
    <id>http://yoursite.com/2019/12/27/Flink-基本概念（有状态流式处理引擎）/</id>
    <published>2019-12-27T01:29:44.000Z</published>
    <updated>2019-12-29T03:14:16.710Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、什么是有状态处理"><a href="#一、什么是有状态处理" class="headerlink" title="一、什么是有状态处理"></a>一、什么是有状态处理</h2><ol><li>传统批次处理方法<br><img src="/images/2019/12/27/8f2108b0-2846-11ea-80df-39774ea2e31e.png" alt="image.png"><blockquote><p>可以看出传统批处理的方法是采用持续收取数据，以时间作为划分多个批次的依据，在周期性执行批次处理。<br><img src="/images/2019/12/27/f1950b40-2846-11ea-80df-39774ea2e31e.png" alt="image.png"><br>但当出现需要就算每个小时出现事件转换次数的需求时，并且事件转换跨越了所定义的时间划分，也即两个事件出现在了，两个不同的批次当中，<strong>传统批处理会将中介运算结果带到下一个批次进行计算</strong> ，还有出现接收的事件顺序颠倒时，传统批处理仍会将中介状态带到下一批次的运算结果中。</p></blockquote></li><li>理想方法<br><img src="/images/2019/12/27/8aa1e1d0-2849-11ea-80df-39774ea2e31e.png" alt="image.png"><blockquote><p>第一点，要有理想方法，这个理想方法是引擎必须要有能力可以累积状态和维护状态，累积状态代表着过去历史中接收过的所有事件，会影响到输出。<br>第二点，时间，时间意味着引擎对于数据完整性有机制可以操控，当所有数据都完全接收到后，输出计算结果。<br>第三点，理想方法模型需要实时产生结果，但更重要的是采用新的持续性数据处理模型来处理实时数据，这样才最符合Continuous data 的特性。<br><img src="/images/2019/12/27/cd4164c0-2849-11ea-80df-39774ea2e31e.png" alt="image.png"></p></blockquote></li><li>流式处理<br><img src="/images/2019/12/27/43597ad0-284a-11ea-80df-39774ea2e31e.png" alt="image.png"><blockquote><p>流式处理简单来讲即有一个无穷无尽的数据源在持续收取数据，以代码作为数据处理的基础逻辑，数据源的数据经过代码处理后产生出结果，然后输出，这就是流式处理的基本原理。</p></blockquote></li><li>分布式流式处理<br><img src="/images/2019/12/27/0a495de0-284b-11ea-80df-39774ea2e31e.png" alt="image.png"><blockquote><p>假设Input Streams 有很多个使用者，每个使用者都有自己的ID，如果计算每个使用者出现的次数，我们需要让同一个使用者的出现事件流到同一运算代码，这跟其他批次需要做Group by 是同样的概念，所以跟Stream 一样需要做分区，设定相应的Key，然后让同样的 Key 流到同一个 Computation instance 做同样的运算。</p></blockquote></li><li>有状态分布式流式处理<br><img src="/images/2019/12/27/673360a0-284b-11ea-80df-39774ea2e31e.png" alt="image.png"><blockquote><p>如图，上述代码中定义了变数X，X 在数据处理过程中会进行读和写，在最后输出结果时，可以依据变数X 决定输出的内容，即状态X 会影响最终的输出结果。这个过程中，第一个重点是先进行了状态Co-partitioned key by，同样的 Key 都会流到Computation instance，与使用者出现次数的原理相同，次数即所谓的状态，这个状态一定会跟同一个Key 的事件累积在同一个 Computation instance。类似于根据输入流的Key 重新分区的状态，当分区进入 Stream 之后，这个 Stream 会累积起来的状态也变成 Copartiton .<br>第二个重点是embeded local state backend。有状态分散式流式处理的引擎，状态可能会累积到非常大，当 Key 非常多时，状态可能就会超出单一节点的 Memory 的负荷量，这时候状态必须有状态后端去维护它；在这个状态后端在正常状况下，用In-memory 维护即可。</p></blockquote></li></ol><h2 id="二、有状态流式处理的挑战"><a href="#二、有状态流式处理的挑战" class="headerlink" title="二、有状态流式处理的挑战"></a>二、有状态流式处理的挑战</h2><ol><li>状态容错<br>需要解决下面三个问题：</li></ol><ul><li>如何确保状态拥有精确一次（exactly-once guarantee）容错保证</li><li>如何在分布式场景下替多个拥有本地状态的运算子产生一个全域一致的快照（global consistent snapshot）</li><li>如何在不中断运算的前提下产生快照<br>1.1 简单场景的精确一次容错方法<blockquote><p>先考虑最简单的使用场景，如无限流的数据进入，后面单一的Process 进行运算，每处理完一笔计算即会累积一次状态，这种情况下如果要确保Process 产生精确一次的状态容错，每处理完一笔数据，更改完状态后进行一次快照，快照包含在队列中并与相应的状态进行对比，完成一致的快照，就能确保精确一次。</p></blockquote></li></ul><p>1.2 分布式状态容错</p><blockquote><p>Flink作为分布式的处理引擎，在分布式的场景下，进行多个本地状态的运算，只产生一个全域一致的快照，如需要在不中断运算值的前提下产生全域一致的快照，就涉及到分散式状态容错。</p></blockquote><p><img src="/images/2019/12/27/9078f390-2872-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p> 关于Global consistent snapshot，当Operator 在分布式的环境中，在各个节点做运算，首先产生Global consistent snapshot 的方式就是处理每一笔数据的快照点是连续的，这笔运算流过所有的运算值，更改完所有的运算值后，能够看到每一个运算值的状态与该笔运算的位置，即可称为Consistent snapshot，当然，Global consistent snapshot 也是简易场景的延伸。</p></blockquote><p>容错恢复</p><p><img src="/images/2019/12/27/09adb2f0-2873-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p>首先了解一下Checkpoint，上面提到连续性快照每个Operator 运算值本地的状态后端都要维护状态，也就是每次将产生检查点时会将它们传入共享的DFS 中。当任何一个Process 挂掉后，可以直接从三个完整的Checkpoint 将所有的运算值的状态恢复，重新设定到相应位置。Checkpoint的存在使整个Process 能够实现分散式环境中的Exactly-once。</p></blockquote><p>1.3 分布式快照的方法（distribution snapshot）<br><img src="/images/2019/12/27/b51633f0-2874-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p>关于Flink 如何在不中断运算的状况下持续产生Global consistent snapshot，其方式是基于用 Simple lamport 演算法机制下延伸的。已知的一个点Checkpoint barrier，Flink 在某个Datastream 中会一直安插Checkpoint barrier，Checkpoint barrier 也会N – 1等等，Checkpoint barrier N 代表着所有在这个范围里面的数据都是Checkpoint barrier N。</p></blockquote><p><img src="/images/2019/12/27/a0fa8a00-2875-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p>举例：假设现在需要产生Checkpoint barrier N，但实际上在Flink 中是由Job manager 触发Checkpoint，Checkpoint 被触发后开始从数据源产生Checkpoint barrier。当Job 开始做Checkpoint barrier N 的时候，可以理解为Checkpoint barrier N 需要逐步填充左下角的表格。</p></blockquote><p><img src="/images/2019/12/27/3cecb820-2876-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p>如图，当部分事件标为红色，Checkpoint barrier N 也是红色时，代表着这些数据或事件都由Checkpoint barrier N 负责。Checkpoint barrier N 后面白色部分的数据或事件则不属于Checkpoint barrier N。</p></blockquote><p>在以上的基础上，当数据源收到Checkpoint barrier N 之后会先将自己的状态保存，以读取Kafka资料为例，数据源的状态就是目前它在Kafka 分区的位置，这个状态也会写入到上面提到的表格中。下游的Operator 1 会开始运算属于Checkpoint barrier N 的数据，当Checkpoint barrier N 跟着这些数据流动到Operator 1 之后,Operator 1 也将属于Checkpoint barrier N 的所有数据都反映在状态中，当收到Checkpoint barrier N 时也会直接对Checkpoint去做快照。</p><p><img src="/images/2019/12/27/6ba1cfc0-2876-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p>当快照完成后继续往下游走，Operator 2 也会接收到所有数据，然后搜索Checkpoint barrier N 的数据并直接反映到状态，当状态收到Checkpoint barrier N 之后也会直接写入到Checkpoint N 中。以上过程到此可以看到Checkpoint barrier N 已经完成了一个完整的表格，这个表格叫做Distributed Snapshots，即分布式快照。分布式快照可以用来做状态容错，任何一个节点挂掉的时候可以在之前的Checkpoint 中将其恢复。继续以上Process，当多个Checkpoint 同时进行，Checkpoint barrier N 已经流到Job manager 2，Flink job manager 可以触发其他的Checkpoint，比如Checkpoint N + 1，Checkpoint N + 2 等等也同步进行，利用这种机制，可以在不阻挡运算的状况下持续地产生Checkpoint。</p></blockquote><p><img src="/images/2019/12/27/adee50b0-2876-11ea-80df-39774ea2e31e.png" alt="image.png"></p><ol start="2"><li>状态维护<blockquote><p>状态维护即用一段代码在本地维护状态值，当状态值非常大时需要本地的状态后端来支持。</p></blockquote></li></ol><p><img src="/images/2019/12/27/a35ab9c0-2878-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p>图中分别为： 状态识别id,状态数据形态资讯，注册状态<br>如图，在Flink 程序中，可以采用getRuntimeContext().getState(desc); 这组API 去注册状态。Flink 有多种状态后端，采用API 注册状态后，读取状态时都是通过状态后端来读取的。Flink 有两种不同的状态值，也有两种不同的状态后端：<br><img src="/images/2019/12/27/102f4a70-2879-11ea-80df-39774ea2e31e.png" alt="image.png"></p></blockquote><p>-JVM Heap状态后端，适合数量较小的状态，当状态量不大时就可以采用JVM Heap 的状态后端。JVM Heap 状态后端会在每一次运算值需要读取状态时，用Java object read / writes 进行读或写，不会产生较大代价，但当Checkpoint 需要将每一个运算值的本地状态放入Distributed Snapshots 的时候，就需要进行序列化了。</p><p><img src="/images/2019/12/27/30faad30-2879-11ea-80df-39774ea2e31e.png" alt="image.png"></p><p>-RocksDB状态后端，它是一种out of core 的状态后端。在Runtime 的本地状态后端让使用者去读取状态的时候会经过磁盘，相当于将状态维护在磁盘里，与之对应的代价可能就是每次读取状态时，都需要经过序列化和反序列化的过程。当需要进行快照时只将应用序列化即可，序列化后的数据直接传输到中央的共享DFS 中。</p><blockquote><p>Flink目前支持以上两种状态后端，一种是纯 Memory 的状态后端，另一种是有资源磁盘的状态后端，在维护状态时可以根据状态的数量选择相应的状态后端。</p></blockquote><ol start="3"><li>event-time process<br>3.1 不同的时间种类<blockquote><p>在Flink 及其他进阶的流式处理引擎出现之前，大数据处理引擎一直只支持Processing-time 的处理。假设定义一个运算 Windows 的窗口，Windows 运算设定每小时进行结算。Processing-time 进行运算时，可以发现数据引擎将3 点至4 点间收到的数据进行结算。实际上在做报表或者分析结果时是想了解真实世界中3 点至4 点之间实际产生数据的输出结果，了解实际数据的输出结果就必须采用Event – Time 了。<br><img src="/images/2019/12/29/1593f130-29e8-11ea-80df-39774ea2e31e.png" alt="image.png"></p></blockquote></li></ol><blockquote><p>如图，Event – Time 相当于事件，它在数据最源头产生时带有时间戳，后面都需要用时间戳来进行运算。用图来表示，最开始的队列收到数据，每小时对数据划分一个批次，这就是Event – Time Process 在做的事情。</p></blockquote><p>3.2 Event-Time处理<br><img src="/images/2019/12/29/4184b8b0-29e8-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p>Event – Time 是用事件真实产生的时间戳去做Re-bucketing，把对应时间3 点到4 点的数据放在3 点到4 点的Bucket，然后Bucket 产生结果。所以Event – Time 跟Processing – time 的概念是这样对比的存在。</p></blockquote><p><img src="/images/2019/12/29/5988a3e0-29e8-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p> Event – Time 的重要性在于记录引擎输出运算结果的时间。简单来说，流式引擎连续24 小时在运行、搜集资料，假设Pipeline 里有一个 Windows Operator 正在做运算，每小时能产生结果，何时输出 Windows的运算值，这个时间点就是Event – Time 处理的精髓，用来表示该收的数据已经收到。</p></blockquote><p>3.3 Watermarks(水位线)<br><img src="/images/2019/12/29/9b44cbb0-29e8-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p> Flink实际上是用 Watermarks 来实现Event – Time 的功能。Watermarks 在Flink 中也属于特殊事件，其精髓在于当某个运算值收到带有时间戳“ T ”的 Watermarks 时就意味着它不会接收到新的数据了。使用Watermarks 的好处在于可以准确预估收到数据的截止时间。举例，假设预期收到数据时间与输出结果时间的时间差延迟5 分钟，那么Flink 中所有的 Windows Operator 搜索3 点至4 点的数据，但因为存在延迟需要再多等5分钟直至收集完4：05 分的数据，此时方能判定4 点钟的资料收集完成了，然后才会产出3 点至4 点的数据结果。这个时间段的结果对应的就是 Watermarks 的部分。</p></blockquote><ol start="4"><li>状态保存与迁移<blockquote><p>流式处理应用无时无刻不在运行，运维上有几个重要考量：</p></blockquote></li></ol><ul><li>如何将前一步执行的的状态迁移到新的执行上</li><li>如何重新定义运行的平行化程度</li><li><blockquote><p> Checkpoint完美符合以上需求，不过Flink 中还有另外一个名词保存点（Savepoint），当手动产生一个Checkpoint 的时候，就叫做一个Savepoint。Savepoint 跟Checkpoint 的差别在于Checkpoint是Flink 对于一个有状态应用在运行中利用分布式快照持续周期性的产生Checkpoint，而Savepoint 则是手动产生的Checkpoint，Savepoint 记录着流式应用中所有运算元的状态。</p></blockquote></li></ul><p><img src="/images/2019/12/29/218dc780-29e9-11ea-80df-39774ea2e31e.png" alt="image.png"></p><blockquote><p> 如图，Savepoint A 和Savepoint B，无论是变更底层代码逻辑、修bug 或是升级Flink 版本，重新定义应用、计算的平行化程度等，最先需要做的事情就是产生Savepoint。</p></blockquote><p>Savepoint产生的原理是在Checkpoint barrier 流动到所有的Pipeline 中手动插入从而产生分布式快照，这些分布式快照点即Savepoint。Savepoint 可以放在任何位置保存，当完成变更时，可以直接从Savepoint 恢复、执行。</p><p>从Savepoint 的恢复执行需要注意，在变更应用的过程中时间在持续，如Kafka 在持续收集资料，当从Savepoint 恢复时，Savepoint 保存着Checkpoint 产生的时间以及Kafka 的相应位置，因此它需要恢复到最新的数据。无论是任何运算，Event – Time 都可以确保产生的结果完全一致。</p><p>假设恢复后的重新运算用Process Event – Time，将 Windows 窗口设为1 小时，重新运算能够在10 分钟内将所有的运算结果都包含到单一的 Windows 中。而如果使用Event – Time，则类似于做Bucketing。在Bucketing 的状况下，无论重新运算的数量多大，最终重新运算的时间以及Windows 产生的结果都一定能保证完全一致。</p><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><blockquote><p> 本文首先从Apache Flink 的定义、架构、基本原理入手，对大数据流计算相关的基本概念进行辨析，在此基础上简单回顾了大数据处理方式的历史演进以及有状态的流式数据处理的原理，最后从目前有状态的流式处理面临的挑战分析Apache Flink 作为业界公认为最好的流计算引擎之一所具备的天然优势。希望有助于大家厘清大数据流式处理引擎涉及的基本概念，能够更加得心应手的使用Flink。</p></blockquote><p>参考文章：<a href="https://ververica.cn/developers/flink-basic-tutorial-1-basic-concept/" target="_blank" rel="noopener">Apache Flink 零基础入门（一&amp;二）：基础概念解析</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、什么是有状态处理&quot;&gt;&lt;a href=&quot;#一、什么是有状态处理&quot; class=&quot;headerlink&quot; title=&quot;一、什么是有状态处理&quot;&gt;&lt;/a&gt;一、什么是有状态处理&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;传统批次处理方法&lt;br&gt;&lt;img src=&quot;/images/20
      
    
    </summary>
    
      <category term="学习" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink 基本概念</title>
    <link href="http://yoursite.com/2019/12/25/flink-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"/>
    <id>http://yoursite.com/2019/12/25/flink-基本概念/</id>
    <published>2019-12-25T02:11:45.000Z</published>
    <updated>2019-12-25T07:35:37.085Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Apache-flink-基本概念，原理和架构"><a href="#一、Apache-flink-基本概念，原理和架构" class="headerlink" title="一、Apache flink 基本概念，原理和架构"></a>一、Apache flink 基本概念，原理和架构</h2><blockquote><p>Apache Flink is a <strong>framework</strong> and <strong>distributed</strong> processing engine for <strong>stateful</strong> computations over unbounded and bounded data <strong>streams</strong>.<br> Apache Flink 是一个分布式大数据处理引擎，可对有限数据流和无限数据流进行有状态或无状态的计算，能够部署在各种集群环境，对各种规模大小的数据进行快速计算。</p></blockquote><h3 id="1-Flink-Application"><a href="#1-Flink-Application" class="headerlink" title="1. Flink Application"></a>1. Flink Application</h3><blockquote><p>首先了解Flink的Streams、State、Time等基本处理语义以及Flink兼顾灵活性和方便性的多层次API。</p><ul><li>Streams：流，分为有限数据流与无限数据流，unbounded stream 是有始无终的数据流，即无限数据流；而bounded stream 是限定大小的有始有终的数据集合，即有限数据流，二者的区别在于无限数据流的数据会随时间的推演而持续增加，计算持续进行且不存在结束的状态，相对的有限数据流数据大小固定，计算最终会完成并处于结束的状态。<br><img src="/images/2019/12/25/3e5f8a80-26e0-11ea-80df-39774ea2e31e.png" alt="image.png"></li></ul></blockquote><ul><li>State，状态是计算过程中的数据信息，在容错恢复和Checkpoint 中有重要的作用，流计算在本质上是Incremental Processing，因此需要不断查询保持状态；另外，为了确保Exactly- once 语义，需要数据能够写入到状态中；而持久化存储，能够保证在整个分布式系统运行失败或者挂掉的情况下做到Exactly- once，这是状态的另外一个价值。flink的状态管理还需加强研究。(Application state is a first-class citizen in flink)</li></ul><p><img src="/images/2019/12/25/c297cec0-26e0-11ea-80df-39774ea2e31e.png" alt="image.png"></p><ul><li>Time，分为Event time、Ingestion time、Processing time，Flink 的无限数据流是一个持续的过程，时间是我们判断业务状态是否滞后，数据处理是否及时的重要依据。（平常主要用Event Time 和 processing time）<br><img src="/images/2019/12/25/9d1afc70-26e1-11ea-80df-39774ea2e31e.png" alt="image.png"></li></ul><blockquote><p><strong>Event Time</strong> is the time when an event was created. It is usually described by a timestamp in the event.<br><strong>Ingestion time</strong> is the time when an event entrty the flink dataflow at the source operator.<br><strong>Processing Time</strong> is the local time at each operator that performs a time-based operation.</p></blockquote><ul><li>API，API 通常分为三层，由上而下可分为SQL / Table API、DataStream API、ProcessFunction 三层，API 的表达能力及业务抽象能力都非常强大，但越接近SQL 层，表达能力会逐步减弱，抽象能力会增强，反之，ProcessFunction 层API 的表达能力非常强，可以进行多种灵活方便的操作，但抽象能力也相对越小。(目前主要使用 DataStream API 和 ProcessFunction)<br><img src="/images/2019/12/25/e2271d20-26e2-11ea-80df-39774ea2e31e.png" alt="image.png"><blockquote><p><strong>ProcessFunctions</strong> ：the most expressive function interfaces that Flink oﬀers. Flink provides ProcessFunctions to process individual events from one or two input streams or events that were grouped in a window.<br><strong>DataStreamAPI</strong> ：provides primitives for many common stream processing operations, such as windowing, record-at-a-time transformations, and enriching events by querying an external data store.<br><strong>SQL/TableAPI</strong> :  relational APIs.</p></blockquote></li></ul><h3 id="2-Flink-Architecture"><a href="#2-Flink-Architecture" class="headerlink" title="2.Flink Architecture"></a>2.Flink Architecture</h3><p>  主要为以下四个部分：<br>     <img src="/images/2019/12/25/4cf5fd50-26e4-11ea-80df-39774ea2e31e.png" alt="image.png"></p><p>第一，Flink 具备统一的框架处理有界和无界两种数据流的能力</p><p>第二， 部署灵活，Flink 底层支持多种资源调度器，包括Yarn、Kubernetes 等。Flink 自身带的Standalone 的调度器，在部署上也十分灵活。</p><p>第三， 极高的可伸缩性，可伸缩性对于分布式系统十分重要，阿里巴巴双11大屏采用Flink 处理海量数据，使用过程中测得Flink 峰值可达17 亿/秒。</p><p>第四， 极致的流式处理性能。Flink 相对于Storm 最大的特点是将状态语义完全抽象到框架中，支持本地状态读取，避免了大量网络IO，可以极大提升状态存取的性能。</p><p><img src="/images/2019/12/25/1f87a110-26e5-11ea-80df-39774ea2e31e.png" alt="image.png"></p><h3 id="3-Flink-Operation"><a href="#3-Flink-Operation" class="headerlink" title="3. Flink Operation"></a>3. Flink Operation</h3><p>后面会有专门课程讲解，此处简单分享Flink 关于运维及业务监控的内容：</p><ul><li><p>Flink具备7 X 24 小时高可用的SOA（面向服务架构），原因是在实现上Flink 提供了一致性的Checkpoint。Checkpoint是Flink 实现容错机制的核心，它周期性的记录计算过程中Operator 的状态，并生成快照持久化存储。当Flink 作业发生故障崩溃时，可以有选择的从Checkpoint 中恢复，保证了计算的一致性。</p></li><li><p>Flink本身提供监控、运维等功能或接口，并有内置的WebUI，对运行的作业提供DAG 图以及各种Metric 等，协助用户管理作业状态。</p></li></ul><h3 id="4-Flink-场景应用"><a href="#4-Flink-场景应用" class="headerlink" title="4.Flink 场景应用"></a>4.Flink 场景应用</h3><h4 id="4-1-Flink-场景应用：Data-Pipeline"><a href="#4-1-Flink-场景应用：Data-Pipeline" class="headerlink" title="4.1 Flink 场景应用：Data Pipeline"></a>4.1 Flink 场景应用：Data Pipeline</h4><p><img src="/images/2019/12/25/e8acbe30-26e6-11ea-80df-39774ea2e31e.png" alt="image.png"><br>Data Pipeline 的核心场景类似于数据搬运并在搬运的过程中进行部分数据清洗或者处理，而整个业务架构图的左边是Periodic ETL，它提供了流式ETL 或者实时ETL，能够订阅消息队列的消息并进行处理，清洗完成后实时写入到下游的Database或File system 中。场景举例：</p><p><strong>实时数仓</strong><br>  当下游要构建实时数仓时，上游则可能需要实时的Stream ETL。这个过程会进行实时清洗或扩展数据，清洗完成后写入到下游的实时数仓的整个链路中，可保证数据查询的时效性，形成实时数据采集、实时数据处理以及下游的实时Query。</p><p><strong>搜索引擎推荐</strong><br>  搜索引擎这块以淘宝为例，当卖家上线新商品时，后台会实时产生消息流，该消息流经过Flink 系统时会进行数据的处理、扩展。然后将处理及扩展后的数据生成实时索引，写入到搜索引擎中。这样当淘宝卖家上线新商品时，能在秒级或者分钟级实现搜索引擎的搜索。</p><h4 id="4-2-Flink-场景应用：Data-Analytics"><a href="#4-2-Flink-场景应用：Data-Analytics" class="headerlink" title="4.2 Flink 场景应用：Data Analytics"></a>4.2 Flink 场景应用：Data Analytics</h4><p><img src="/images/2019/12/25/69d757d0-26e8-11ea-80df-39774ea2e31e.png" alt="image.png"><br>Data Analytics，如图，左边是Batch Analytics，右边是Streaming Analytics。Batch Analytics 就是传统意义上使用类似于Map Reduce、Hive、Spark Batch 等，对作业进行分析、处理、生成离线报表；Streaming Analytics 使用流式分析引擎如Storm、Flink 实时处理分析数据，应用较多的场景如实时大屏、实时报表。</p><h4 id="4-3-Flink-场景应用：Data-Driven"><a href="#4-3-Flink-场景应用：Data-Driven" class="headerlink" title="4.3 Flink 场景应用：Data Driven"></a>4.3 Flink 场景应用：Data Driven</h4><p><img src="/images/2019/12/25/d64efb70-26e8-11ea-80df-39774ea2e31e.png" alt="image.png"><br>从某种程度上来说，所有的实时的数据处理或者是流式数据处理都是属于Data Driven，流计算本质上是Data Driven 计算。应用较多的如风控系统，当风控系统需要处理各种各样复杂的规则时，Data Driven 就会把处理的规则和逻辑写入到Datastream 的API 或者是ProcessFunction 的API 中，然后将逻辑抽象到整个Flink 引擎，当外面的数据流或者是事件进入就会触发相应的规则，这就是Data Driven 的原理。在触发某些规则后，Data Driven 会进行处理或者是进行预警，这些预警会发到下游产生业务通知，这是Data Driven 的应用场景，Data Driven 在应用上更多应用于复杂事件的处理。</p><p>参考资料：<a href="https://ververica.cn/developers/flink-basic-tutorial-1-basic-concept/" target="_blank" rel="noopener">Apache Flink 零基础入门（一&amp;二）：基础概念解析</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、Apache-flink-基本概念，原理和架构&quot;&gt;&lt;a href=&quot;#一、Apache-flink-基本概念，原理和架构&quot; class=&quot;headerlink&quot; title=&quot;一、Apache flink 基本概念，原理和架构&quot;&gt;&lt;/a&gt;一、Apache fl
      
    
    </summary>
    
      <category term="学习" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink 提交任务</title>
    <link href="http://yoursite.com/2019/12/19/flink-%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1/"/>
    <id>http://yoursite.com/2019/12/19/flink-提交任务/</id>
    <published>2019-12-19T01:35:40.000Z</published>
    <updated>2019-12-19T02:09:11.636Z</updated>
    
    <content type="html"><![CDATA[<h1 id="flink-提交任务"><a href="#flink-提交任务" class="headerlink" title="flink 提交任务"></a>flink 提交任务</h1><h2 id="flink本地提交任务"><a href="#flink本地提交任务" class="headerlink" title="flink本地提交任务"></a>flink本地提交任务</h2><blockquote><p>一般在本地测试时，需要在本地自己电脑提交flink任务，本地提交分两种：<br> 1.通过命令行的方式提交flink任务：<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/flink run ./examples/batch/WordCount.jar</span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>2.通过网页ip:8081提交任务<br>点击 add new 上传jar包<br><img src="/images/2019/12/19/3d365750-21ff-11ea-80df-39774ea2e31e.png" alt="image.png"></p></blockquote><blockquote><p>选择想要执行的jar包，点击主类，设置并行度，点击submit提交按钮<br><img src="/images/2019/12/19/1476e7b0-2201-11ea-80df-39774ea2e31e.png" alt="image.png"></p></blockquote><h2 id="flink集群提交任务"><a href="#flink集群提交任务" class="headerlink" title="flink集群提交任务"></a>flink集群提交任务</h2><blockquote><p>说明：flink集群采用oozie编写shell脚本在yarn上提交flink任务，其中flink版本1.8.1，oozie(5.1.0-cdh6.3.0),hue(4.2.0-cdh6.3.0)<br>并且集群采用了kerberos和ldap安全认证，由于oozie并未集成flink任务提交，所以需要配置kerberos认证</p></blockquote><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">1.上传jar包，flink配置文件以及kerberos的keytab到自己的工作目录</span><br><span class="line">2.配置kerberos认证，编辑flink-conf.yaml配置文件，新增配置</span><br><span class="line">security.kerberos.login.use-ticket-cache: false</span><br><span class="line">security.kerberos.login.keytab: ./conf/260164.keytab</span><br><span class="line">security.kerberos.login.principal: 260164@GREE.IO</span><br><span class="line">3.编写shell脚本</span><br><span class="line">#!/bin/bash</span><br><span class="line">env -i FLINK_CONF_DIR=./conf /lvm/data3/flink/flink-1.8.1/bin/flink run -m yarn-cluster -yqu root.dev1 -ynm test-flink./test.jar</span><br><span class="line">重新指定flink配置环境文件目录 -m 指定提交模式，-yqu 指定提交yarn队列，-ynm 指定flink任务名称。最后指定要运行的jar包</span><br><span class="line">需要注意的是shell脚本尽量自己手动写一遍，避免出现一些格式编码等奇怪问题</span><br><span class="line">4.创建oozie shell任务</span><br><span class="line">指定conf配置文件目录，shell脚本，以及上传的jar包</span><br><span class="line">指定shell的队列，默认是default队列</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;flink-提交任务&quot;&gt;&lt;a href=&quot;#flink-提交任务&quot; class=&quot;headerlink&quot; title=&quot;flink 提交任务&quot;&gt;&lt;/a&gt;flink 提交任务&lt;/h1&gt;&lt;h2 id=&quot;flink本地提交任务&quot;&gt;&lt;a href=&quot;#flink本地提交任
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>JSON数据处理（gson 和 fastjson）</title>
    <link href="http://yoursite.com/2019/12/18/JSON%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%EF%BC%88gson-%E5%92%8C-fastjson%EF%BC%89/"/>
    <id>http://yoursite.com/2019/12/18/JSON数据处理（gson-和-fastjson）/</id>
    <published>2019-12-18T06:24:05.000Z</published>
    <updated>2019-12-18T06:24:40.795Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GSON-和-fastjson-总结"><a href="#GSON-和-fastjson-总结" class="headerlink" title="GSON 和 fastjson 总结"></a>GSON 和 fastjson 总结</h1><h2 id="1-JSON两种数据类型"><a href="#1-JSON两种数据类型" class="headerlink" title="1.JSON两种数据类型"></a>1.JSON两种数据类型</h2><ul><li>json对象， object -&gt; {key:value,key:value,…}</li><li>json数组，array -&gt; [value,value,…]</li></ul><h2 id="2-gson-解析-json对象"><a href="#2-gson-解析-json对象" class="headerlink" title="2.gson 解析 json对象"></a>2.gson 解析 json对象</h2><blockquote><p>分为直接解析和通过java类来解析<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--  Gson: Java to Json conversion --&gt;</span><br><span class="line">       &lt;dependency&gt;</span><br><span class="line">           &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;</span><br><span class="line">           &lt;artifactId&gt;gson&lt;/artifactId&gt;</span><br><span class="line">           &lt;version&gt;2.8.5&lt;/version&gt;</span><br><span class="line">           &lt;scope&gt;compile&lt;/scope&gt;</span><br><span class="line">       &lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p></blockquote><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">1.直接解析</span><br><span class="line"></span><br><span class="line"> //json对象形式解析</span><br><span class="line">        String data_json = &quot;&#123;\n&quot; +</span><br><span class="line">                &quot;        \&quot;sex\&quot;: &apos;男&apos;,\n&quot; +</span><br><span class="line">                &quot;        \&quot;hobby\&quot;:[\&quot;baskte\&quot;,\&quot;tennis\&quot;],\n&quot; +</span><br><span class="line">                &quot;        \&quot;introduce\&quot;: &#123;\n&quot; +</span><br><span class="line">                &quot;            \&quot;name\&quot;:\&quot;tom\&quot;,\n&quot; +</span><br><span class="line">                &quot;            \&quot;age\&quot;:23\n&quot; +</span><br><span class="line">                &quot;        &#125;\n&quot; +</span><br><span class="line">                &quot;    &#125;&quot;;</span><br><span class="line"></span><br><span class="line">        //json 解析器，解析json数据</span><br><span class="line">        JsonParser parser = new JsonParser();</span><br><span class="line">        JsonElement element = parser.parse(data_json);</span><br><span class="line">        if (element.isJsonObject()) &#123;</span><br><span class="line">            //转化为对象</span><br><span class="line">            JsonObject object = element.getAsJsonObject();</span><br><span class="line">            //1.当value为String时，取出String值</span><br><span class="line">            String sex = object.get(&quot;sex&quot;).getAsString();</span><br><span class="line"></span><br><span class="line">            //2.当value为数组array,取出array</span><br><span class="line">            JsonArray hobbies = object.getAsJsonArray(&quot;hobby&quot;);</span><br><span class="line">            for (int i = 0; i &lt; hobbies.size(); i++) &#123;</span><br><span class="line">                String hobby = hobbies.get(i).getAsString();</span><br><span class="line">                System.out.println(&quot;hobby: &quot; + hobby);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            //3.当value为object时，取出object</span><br><span class="line">            JsonObject introduce = object.getAsJsonObject(&quot;introduce&quot;);</span><br><span class="line">            String name = introduce.get(&quot;name&quot;).getAsString();</span><br><span class="line">            int age = introduce.get(&quot;age&quot;).getAsInt();</span><br><span class="line">            System.out.println(&quot;name: &quot; + name + &quot;;age: &quot; + age);</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">2.通过java类来解析</span><br><span class="line"></span><br><span class="line">public class People   &#123;</span><br><span class="line">    private String name;</span><br><span class="line">    private int age;</span><br><span class="line">    public String address;</span><br><span class="line">    public int salary;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String toString() &#123;</span><br><span class="line">        return &quot;&quot; +</span><br><span class="line">                &quot;name=&apos;&quot; + name + &apos;\&apos;&apos; +</span><br><span class="line">                &quot;, age=&quot; + age +</span><br><span class="line">                &quot;, address=&apos;&quot; + address + &apos;\&apos;&apos; +</span><br><span class="line">                &quot;, salary=&quot; + salary ;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">//======================================================</span><br><span class="line"></span><br><span class="line">   //3.借助java类来生成对应的java对象来解析数据</span><br><span class="line">        String object_json = &quot;&#123;\&quot;name\&quot;:\&quot;tom\&quot;,\&quot;salary\&quot;:12999&#125;&quot;;</span><br><span class="line">        Gson gson = new Gson();</span><br><span class="line">        People people = gson.fromJson(object_json, People.class);</span><br><span class="line">        System.out.println(people.toString());</span><br></pre></td></tr></table></figure><h2 id="3-gson-解析-json数组"><a href="#3-gson-解析-json数组" class="headerlink" title="3.gson 解析 json数组"></a>3.gson 解析 json数组</h2><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">// json数组对象解析</span><br><span class="line">       String array_data_json = &quot;[\n&quot; +</span><br><span class="line">               &quot;    \&quot;cake\&quot;,\n&quot; +</span><br><span class="line">               &quot;    2,\n&quot; +</span><br><span class="line">               &quot;    &#123;\&quot;brother\&quot;:\&quot;tom\&quot;,\&quot;sister\&quot;:\&quot;lucy\&quot;&#125;,\n&quot; +</span><br><span class="line">               &quot;    [\&quot;red\&quot;,\&quot;orange\&quot;]\n&quot; +</span><br><span class="line">               &quot;]&quot;;</span><br><span class="line"></span><br><span class="line">       // json解析器，解析json数据</span><br><span class="line">       JsonParser parser_array = new JsonParser();</span><br><span class="line">       JsonElement element_array = parser_array.parse(array_data_json);</span><br><span class="line">       // json属于数组类型</span><br><span class="line">       if (element_array.isJsonArray()) &#123;</span><br><span class="line">           JsonArray array = element_array.getAsJsonArray();</span><br><span class="line"></span><br><span class="line">           // 1. value为string时，取出string</span><br><span class="line">           String array_1 = array.get(0).getAsString();</span><br><span class="line">           System.out.println(&quot;array_1:&quot; + array_1);</span><br><span class="line"></span><br><span class="line">           // 2. value为int时，取出int</span><br><span class="line">           int array_2 = array.get(1).getAsInt();</span><br><span class="line">           System.out.println(&quot;array_2:&quot; + array_2);</span><br><span class="line"></span><br><span class="line">           // 3. value为object时，取出object</span><br><span class="line">           JsonObject array_3 = array.get(2).getAsJsonObject();</span><br><span class="line">           String brother = array_3.get(&quot;brother&quot;).getAsString();</span><br><span class="line">           String sister = array_3.get(&quot;sister&quot;).getAsString();</span><br><span class="line">           System.out.println(&quot;brother:&quot; + brother + &quot;;sister:&quot; + sister);</span><br><span class="line"></span><br><span class="line">           // 4. value为array时，取出array</span><br><span class="line">           JsonArray array_4 = array.get(3).getAsJsonArray();</span><br><span class="line">           for (int i = 0; i &lt; array_4.size(); i++) &#123;</span><br><span class="line">               System.out.println(array_4.get(i).getAsString());</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">2.java 数组解析</span><br><span class="line">当数据为数组时，对应java中是数组类型</span><br><span class="line">[&quot;apple&quot;, &quot;banana&quot;, &quot;pear&quot;]</span><br><span class="line"></span><br><span class="line">String json2 = &quot;[\&quot;apple\&quot;, \&quot;pear\&quot;, \&quot;banana\&quot;]&quot;;</span><br><span class="line">Gson gson2 = new Gson();</span><br><span class="line">// 传入的java类型是String[].class</span><br><span class="line">String[] fruits = gson2.fromJson(json2, String[].class);  </span><br><span class="line"></span><br><span class="line">对于简单数组可以反序列化List类型</span><br><span class="line">String json2 = &quot;[\&quot;apple\&quot;, \&quot;pear\&quot;, \&quot;banana\&quot;]&quot;;</span><br><span class="line">Gson gson2 = new Gson();</span><br><span class="line">List&lt;String&gt; fruitList = gson2.fromJson(json2, new TypeToken&lt;List&lt;String&gt;&gt;()&#123;&#125;.getType());</span><br></pre></td></tr></table></figure><h3 id="注意："><a href="#注意：" class="headerlink" title="注意："></a>注意：</h3><blockquote><p>1.json数据与java类字段名不一样，可以添加注解@SerializedName()</p></blockquote><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">@SerializedName(&quot;money&quot;)</span><br><span class="line">private String salary;</span><br><span class="line"></span><br><span class="line">@SerializedName(&#123;&quot;money&quot;, &quot;salary&quot;&#125;)  // 可以有多个备选值</span><br><span class="line">private String salary;</span><br></pre></td></tr></table></figure><blockquote><p>2.限定字段是否需要序列化<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">@Expose(serialize=false,deserialize=false)</span><br><span class="line">private String name;</span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>3.复合对象处理<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;name&quot;: &quot;tom&quot;,</span><br><span class="line">  &quot;age&quot;: 0,</span><br><span class="line">  &quot;money&quot;: 2999,</span><br><span class="line">  &quot;hobbies&quot;: [</span><br><span class="line">    &quot;basket&quot;,</span><br><span class="line">    &quot;tennis&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;collections&quot;: &#123;</span><br><span class="line">    &quot;2&quot;: &quot;paint&quot;,</span><br><span class="line">    &quot;3&quot;: &quot;mouse&quot;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">//一般而言，当value是数组时，对应java类中也是数组；当value 是对象时，对应java类中的map(k-v对)</span><br><span class="line"></span><br><span class="line">private List&lt;String&gt; hobbies;</span><br><span class="line">private Map&lt;Integer, String&gt; collections;</span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>4.通过泛型来处理<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">如json数据格式相近</span><br><span class="line">&#123;&quot;code&quot;:&quot;0&quot;,&quot;message&quot;:&quot;success&quot;,&quot;data&quot;:&#123;&#125;&#125;</span><br><span class="line">&#123;&quot;code&quot;:&quot;0&quot;,&quot;message&quot;:&quot;success&quot;,&quot;data&quot;:[]&#125;</span><br><span class="line">则动态生成java对象</span><br><span class="line"></span><br><span class="line">public class Result&lt;T&gt;&#123;</span><br><span class="line">    public int code;</span><br><span class="line">    public String message;</span><br><span class="line">    public T data;</span><br><span class="line">    // getter、setter</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="4-gson将java对象转为json字符串"><a href="#4-gson将java对象转为json字符串" class="headerlink" title="4. gson将java对象转为json字符串"></a>4. gson将java对象转为json字符串</h2><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Gson gson2 = new Gson();</span><br><span class="line">String json2 = gson2.toJson(entry2);</span><br><span class="line">System.out.println(json2);</span><br><span class="line"></span><br><span class="line">对于非值属性，即引用属性，如hobbies、collections，如果没有设置值的话，在序列化后的json数据中，是不会出现的。而如果是值属性的话，没有设置值的情况下，在json数据中会是使用java中的默认值。</span><br></pre></td></tr></table></figure><h2 id="5-fastjson解析java对象"><a href="#5-fastjson解析java对象" class="headerlink" title="5.fastjson解析java对象"></a>5.fastjson解析java对象</h2><blockquote><p>Json是一种轻量级的数据交换格式，采用一种“键：值”对的文本格式来存储和表示数据，在系统交换数据过程中常常被使用，是一种理想的数据交换语言。<br>fastjson.jar是阿里爸爸开发的一款专门用于Java开发的包，可以方便的实现json对象与JavaBean对象的转换，实现JavaBean对象与json字符串的转换，实现json对象与json字符串的转换。</p></blockquote><p>例子<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">package com.gree.bdc.jsonchange;</span><br><span class="line"></span><br><span class="line">import com.alibaba.fastjson.JSON;</span><br><span class="line">import com.gree.bdc.entity.EnamellingPullingMachineStatus;</span><br><span class="line">import com.gree.bdc.entity.PullingRecord;</span><br><span class="line">import com.gree.bdc.util.DateUtils;</span><br><span class="line"></span><br><span class="line">import java.util.UUID;</span><br><span class="line"></span><br><span class="line">public class JsonChange &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        String jsonString = &quot;&#123;\&quot;CUR_DV\&quot;:\&quot;110.60\&quot;,\&quot;CUR_LSP\&quot;:\&quot;155.71\&quot;,\&quot;DQSX_WE\&quot;:\&quot;128.72\&quot;,\&quot;HP_PO\&quot;:\&quot;0\&quot;,\&quot;JLHP_TM\&quot;:\&quot;261.07\&quot;,\&quot;MachineCode\&quot;:\&quot;123\&quot;,\&quot;MachineType\&quot;:1,\&quot;PX_IT\&quot;:\&quot;1.00\&quot;,\&quot;PX_SP\&quot;:\&quot;198.26\&quot;,\&quot;QBX_LR\&quot;:\&quot;0.70\&quot;,\&quot;SDCX_LSP\&quot;:\&quot;158.00\&quot;,\&quot;SDGZ_LSP\&quot;:\&quot;158.00\&quot;,\&quot;SFHP_WE\&quot;:\&quot;270.00\&quot;,\&quot;SXZL_CUR\&quot;:\&quot;50.52\&quot;,\&quot;SXZL_SE\&quot;:\&quot;50.00\&quot;,\&quot;SXZL_SW\&quot;:\&quot;50.00\&quot;,\&quot;Sub_Oven_Index\&quot;:1,\&quot;Type_Data\&quot;:3,\&quot;YPX_CUD\&quot;:\&quot;8\&quot;,\&quot;YP_TY\&quot;:\&quot;8\&quot;,\&quot;YSX_RSP\&quot;:\&quot;0.00\&quot;,\&quot;ZL_EN\&quot;:\&quot;1\&quot;,\&quot;ZPX_CUD\&quot;:\&quot;8\&quot;,\&quot;ZP_TY\&quot;:\&quot;8\&quot;,\&quot;ZSX_RSP\&quot;:\&quot;140.21\&quot;&#125;&quot;;</span><br><span class="line"></span><br><span class="line">        EnamellingPullingMachineStatus enamellingPullingMachineStatus = JSON.parseObject( jsonString, EnamellingPullingMachineStatus.class );</span><br><span class="line">        PullingRecord pullingRecord = new PullingRecord();</span><br><span class="line">        String id = UUID.randomUUID().toString().replace(&quot;-&quot;, &quot;&quot;);</span><br><span class="line">        String machine_index = enamellingPullingMachineStatus.getMachineCode() + (enamellingPullingMachineStatus.getSubOvenIndex() + 1);;</span><br><span class="line">        Float weight = enamellingPullingMachineStatus.getCurrentTakeUpWeight();;</span><br><span class="line">        String record_time = DateUtils.getFormatTimeNow();</span><br><span class="line">        pullingRecord.setId( id );</span><br><span class="line">        pullingRecord.setMachine_index( machine_index );</span><br><span class="line">        pullingRecord.setWeight( weight );</span><br><span class="line">        pullingRecord.setRecord_time( record_time );</span><br><span class="line"></span><br><span class="line">        String pullingRecordJson = JSON.toJSONString( pullingRecord );</span><br><span class="line">        System.out.println( pullingRecordJson );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>参考文献：<a href="https://www.jianshu.com/p/75a50aa0cad1" target="_blank" rel="noopener">GSON</a><br>          <a href="https://blog.csdn.net/srj1095530512/article/details/82529759" target="_blank" rel="noopener">Json详解以及fastjson使用教程</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;GSON-和-fastjson-总结&quot;&gt;&lt;a href=&quot;#GSON-和-fastjson-总结&quot; class=&quot;headerlink&quot; title=&quot;GSON 和 fastjson 总结&quot;&gt;&lt;/a&gt;GSON 和 fastjson 总结&lt;/h1&gt;&lt;h2 id=&quot;1
      
    
    </summary>
    
      <category term="程序语言" scheme="http://yoursite.com/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>flink 基础知识</title>
    <link href="http://yoursite.com/2019/12/06/flink-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <id>http://yoursite.com/2019/12/06/flink-基础知识/</id>
    <published>2019-12-06T03:26:35.000Z</published>
    <updated>2019-12-06T06:04:38.566Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、Flink核心概念和基础"><a href="#一、Flink核心概念和基础" class="headerlink" title="一、Flink核心概念和基础"></a>一、Flink核心概念和基础</h2><blockquote><p>Flink 是一个框架和分布式处理引擎。用于对有界和无界数据流进行有状态计算。并且Flink提供了数据分布和<br>容错机制以及资源管理等核心功能。</p></blockquote><p>flink 提供了诸多高抽象层API以便用户进行分布式任务编写：</p><ul><li>DateSet API ,对静态数据进行批处理，将静态数据抽象成分布式的数据集，用户可以方便对分布式数据集进行处理。</li><li>DateStream API ,对数据流进行流处理操作，将流数据抽象成分布式数据流。</li><li>Table API ,对结果化数据进行查询操作，将流式数据抽象成关系表，并通过类SQL的DSL对关系表进行操作</li></ul><p>flink的特性：</p><blockquote><p>支持高吞吐、低延迟、高性能的流处理<br>支持带有事件时间的窗口（Window）操作<br>支持有状态计算的Exactly-once语义<br>支持高度灵活的窗口（Window） 操作<br>支持具有Backpressure功能的持续流模型<br>支持基于轻量级分布式快照实现容错（snapshot）<br>一个运行时同时支持Batch on Streaming处理和Streaming 处理<br>Flink在JVM实现了自己的内存管理<br>支持迭代计算<br>支持程序自动优化：避免特定情况下：Shuffle、排序等昂贵操作，中间结果有必要进行缓存</p></blockquote><h2 id="二、Flink-与-spark-streaming-区别"><a href="#二、Flink-与-spark-streaming-区别" class="headerlink" title="二、Flink 与 spark streaming 区别"></a>二、Flink 与 spark streaming 区别</h2><p><strong>Flink 是标准的实时处理引擎，基于事件驱动，而spark streaming 是微批处理（Micro-Batch）</strong></p><p>参考：<a href="https://mp.weixin.qq.com/s/U6ctAawGl29ULIz7FLsY2A" target="_blank" rel="noopener">Flink面试通关手册</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、Flink核心概念和基础&quot;&gt;&lt;a href=&quot;#一、Flink核心概念和基础&quot; class=&quot;headerlink&quot; title=&quot;一、Flink核心概念和基础&quot;&gt;&lt;/a&gt;一、Flink核心概念和基础&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;Flink 是一个
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>flink sink mysql 和 hbase</title>
    <link href="http://yoursite.com/2019/12/05/flink-sink-mysql-%E5%92%8C-hbase/"/>
    <id>http://yoursite.com/2019/12/05/flink-sink-mysql-和-hbase/</id>
    <published>2019-12-05T01:58:52.000Z</published>
    <updated>2019-12-05T01:58:52.807Z</updated>
    
    <content type="html"><![CDATA[<p>直接上例子，本人亲测有效<br>1.搭建kafka(单机)，hbase（单机）<br>2.引入依赖<br>主要包括 flink-connector-kafka-0.11_2.11、hbase-client、mysql-connector-java、gson<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line"></span><br><span class="line">    &lt;groupId&gt;com.gree.bdc&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;flink-source&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;</span><br><span class="line">    &lt;name&gt;flink-source&lt;/name&gt;</span><br><span class="line">    &lt;description&gt;Demo project for flink-source&lt;/description&gt;</span><br><span class="line"></span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</span><br><span class="line">        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;</span><br><span class="line">        &lt;java.version&gt;1.8&lt;/java.version&gt;</span><br><span class="line">        &lt;flink.version&gt;1.8.0&lt;/flink.version&gt;</span><br><span class="line">    &lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;!-- flink 快速开始--&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;flink-java&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;flink-streaming-java_2.11&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;flink-connector-kafka-0.11_2.11&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;flink-streaming-scala_2.11&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;$&#123;flink.version&#125;&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;!-- flink 结束--&gt;</span><br><span class="line"></span><br><span class="line">        &lt;!-- log4j 开始 --&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.slf4j&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.7.25&lt;/version&gt;</span><br><span class="line">            &lt;scope&gt;compile&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;log4j&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;log4j&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.2.17&lt;/version&gt;</span><br><span class="line">            &lt;scope&gt;compile&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;!-- log4j 结束--&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;5.1.47&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;hbase-client&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;2.1.0&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;!--插件 --&gt;</span><br><span class="line">        &lt;!--  Gson: Java to Json conversion --&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;com.google.code.gson&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;gson&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;2.8.5&lt;/version&gt;</span><br><span class="line">            &lt;scope&gt;compile&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt;</span><br><span class="line">                &lt;version&gt;2.3.1&lt;/version&gt;</span><br><span class="line">                &lt;configuration&gt;</span><br><span class="line">                    &lt;source&gt;1.8&lt;/source&gt;</span><br><span class="line">                    &lt;target&gt;1.8&lt;/target&gt;</span><br><span class="line">                &lt;/configuration&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">        &lt;/plugins&gt;</span><br><span class="line">    &lt;/build&gt;</span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure></p><p>3.项目结构<br><img src="/images/2019/12/05/7b5b2b40-1701-11ea-8aaf-4df9698be8a5.png" alt="image.png"><br>4.创建MysqlSink<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">package com.gree.bdc</span><br><span class="line"></span><br><span class="line">import java.sql.&#123;Connection, Driver, DriverManager&#125;</span><br><span class="line"></span><br><span class="line">import com.google.gson.Gson</span><br><span class="line">import com.gree.bdc.KafkaToSinkStreaming.Student</span><br><span class="line">import org.apache.flink.configuration.Configuration</span><br><span class="line">import org.apache.flink.streaming.api.functions.sink.&#123;RichSinkFunction, SinkFunction&#125;</span><br><span class="line"></span><br><span class="line">class MysqlSink (url:String, user:String, pwd:String ) extends RichSinkFunction[String]&#123;</span><br><span class="line"></span><br><span class="line">  var conn:Connection = _</span><br><span class="line"></span><br><span class="line">  override def open(parameters: Configuration): Unit =&#123;</span><br><span class="line">    super.open(parameters)</span><br><span class="line">    Class.forName(&quot;com.mysql.jdbc.Driver&quot;)</span><br><span class="line">    conn = DriverManager.getConnection(url,user,pwd)</span><br><span class="line">    conn.setAutoCommit(false)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  override def invoke(value: String,context:SinkFunction.Context[_]): Unit =&#123;</span><br><span class="line">//    super.invoke(value)</span><br><span class="line">    val gson = new Gson()</span><br><span class="line">    val student = gson.fromJson(value,classOf[Student])</span><br><span class="line">    println(value)</span><br><span class="line"></span><br><span class="line">    val person = conn.prepareStatement(&quot;replace into student(name,age,sex,sid) values(?,?,?,?)&quot;)</span><br><span class="line">    person.setString(1,student.name)</span><br><span class="line">    person.setString(2,student.age.toString)</span><br><span class="line">    person.setString(3,student.sex)</span><br><span class="line">    person.setString(4,student.sid)</span><br><span class="line">    person.execute()</span><br><span class="line">    conn.commit()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  override def close(): Unit = &#123;</span><br><span class="line">    super.close()</span><br><span class="line">    conn.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>5.创建HbaseSink<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">package com.gree.bdc</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import com.google.gson.Gson</span><br><span class="line">import com.gree.bdc.KafkaToSinkStreaming.Student</span><br><span class="line">import org.apache.flink.configuration.Configuration</span><br><span class="line">import org.apache.flink.streaming.api.functions.sink.&#123;RichSinkFunction, SinkFunction&#125;</span><br><span class="line">import org.apache.hadoop.hbase.&#123;HBaseConfiguration, TableName&#125;</span><br><span class="line">import org.apache.hadoop.hbase.client.&#123;Connection, ConnectionFactory, Put&#125;</span><br><span class="line">import org.apache.hadoop.hbase.util.Bytes</span><br><span class="line"></span><br><span class="line">class HBaseSink(tableName:String, family:String) extends RichSinkFunction[String] &#123;</span><br><span class="line">  var conn:Connection = _</span><br><span class="line"></span><br><span class="line">  override def open(parameters: Configuration): Unit = &#123;</span><br><span class="line">    super.open(parameters)</span><br><span class="line">    val conf = HBaseConfiguration.create()</span><br><span class="line">    conf.set(&quot;hbase.zookeeper.quorum&quot;,&quot;172.16.247.131&quot;)</span><br><span class="line">    conn = ConnectionFactory.createConnection(conf)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  override def invoke(value: String, context: SinkFunction.Context[_]): Unit =&#123;</span><br><span class="line">    val gson = new Gson()</span><br><span class="line">    val student = gson.fromJson(value,classOf[Student])</span><br><span class="line">    println(value)</span><br><span class="line">    println(student)</span><br><span class="line"></span><br><span class="line">    val table = conn.getTable(TableName.valueOf(tableName))</span><br><span class="line">    val put = new Put(Bytes.toBytes(student.sid))</span><br><span class="line">    put.addColumn(Bytes.toBytes(family),Bytes.toBytes(&quot;name&quot;),Bytes.toBytes(student.name))</span><br><span class="line">    put.addColumn(Bytes.toBytes(family),Bytes.toBytes(&quot;age&quot;),Bytes.toBytes(student.age))</span><br><span class="line">    put.addColumn(Bytes.toBytes(family),Bytes.toBytes(&quot;sex&quot;),Bytes.toBytes(student.sex))</span><br><span class="line">    table.put(put)</span><br><span class="line">    table.close()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  override def close(): Unit =&#123;</span><br><span class="line">    super.close()</span><br><span class="line">    conn.close()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>6.创建KafkaToSinkStreaming<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">package com.gree.bdc</span><br><span class="line"></span><br><span class="line">import java.util.Properties</span><br><span class="line"></span><br><span class="line">import org.apache.flink.api.common.serialization.SimpleStringSchema</span><br><span class="line">import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment</span><br><span class="line">import org.apache.flink.streaming.connectors.kafka.&#123;FlinkKafkaConsumer010, FlinkKafkaConsumer011&#125;</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line">flink 读取 kafka数据</span><br><span class="line">sink mysql 和 hbase</span><br><span class="line"> */</span><br><span class="line">object KafkaToSinkStreaming &#123;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val env = StreamExecutionEnvironment.getExecutionEnvironment</span><br><span class="line"></span><br><span class="line">    val prop = new Properties()</span><br><span class="line">    prop.setProperty(&quot;bootstrap.servers&quot;,&quot;localhost:9092&quot;)</span><br><span class="line">    prop.setProperty(&quot;group.id&quot;,&quot;test&quot;)</span><br><span class="line"></span><br><span class="line">    val input = env.addSource(new FlinkKafkaConsumer010[String](&quot;test&quot;, new SimpleStringSchema(),prop))</span><br><span class="line"></span><br><span class="line">    //自定义MysqlSink类。将数据写入到mysql</span><br><span class="line">    val mysqlSink = new MysqlSink(&quot;jdbc:mysql://localhost:3306/test?serverTimezone=GMT&amp;autoReconnect=true&amp;useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&quot;, &quot;root&quot;, &quot;123456&quot;)</span><br><span class="line">    input.addSink(mysqlSink)</span><br><span class="line"></span><br><span class="line">    //自定义HBaseSink类，将数据Sink到HBase</span><br><span class="line"></span><br><span class="line">    val hBaseSink = new HBaseSink(&quot;student&quot;,&quot;sfz&quot;)</span><br><span class="line">    input.addSink(hBaseSink)</span><br><span class="line"></span><br><span class="line">    env.execute(&quot;KafkaToSinkStreaming&quot;)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  case class Student(name: String,age: Int,sex:String,sid:String)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>7.遇到问题总结</p><blockquote><p>1.NoSuchColumnFamilyException<br>主要是创建hbase table 是 familycloumn 和表对应的列族相同</p></blockquote><blockquote><p>2.java.net.UnknownHostException<br>hosts文件中未配置主机名和ip对应表<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/hosts</span><br><span class="line"></span><br><span class="line">172.16.247.131 kubernetes-master</span><br></pre></td></tr></table></figure></p></blockquote><p>参考文章：<a href="https://blog.csdn.net/qq_33689414/article/details/86629720" target="_blank" rel="noopener">Flink读取Kafka数据Sink到MySQL和HBase数据库</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;直接上例子，本人亲测有效&lt;br&gt;1.搭建kafka(单机)，hbase（单机）&lt;br&gt;2.引入依赖&lt;br&gt;主要包括 flink-connector-kafka-0.11_2.11、hbase-client、mysql-connector-java、gson&lt;br&gt;&lt;figu
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>linux （ubuntu） hbase 单机安装</title>
    <link href="http://yoursite.com/2019/12/04/linux-%EF%BC%88ubuntu%EF%BC%89-hbase-%E5%8D%95%E6%9C%BA%E5%AE%89%E8%A3%85/"/>
    <id>http://yoursite.com/2019/12/04/linux-（ubuntu）-hbase-单机安装/</id>
    <published>2019-12-04T03:39:18.000Z</published>
    <updated>2019-12-05T01:59:11.319Z</updated>
    
    <content type="html"><![CDATA[<p>1.jdk 安装</p><p>下载jdk-8u212-linux-x64.tar.gz安装包，执行命令<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local</span><br><span class="line">mkdir java</span><br><span class="line">tar -zxvf jdk-8u212-linux-x64.tar.gz</span><br></pre></td></tr></table></figure></p><p>配置JAVA_HOME等参数<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br></pre></td></tr></table></figure></p><blockquote><p>export JAVA_HOME=/usr/local/java/jdk1.8.0_212<br>export HBASE_HOME=/usr/local/hbase/hbase-2.1.0<br>export JRE_HOME=/usr/local/java/jdk1.8.0_212/jre<br>export PATH=${JAVA_HOME}/bin:$PATH:${HBASE_HOME}/bin:$PATH</p></blockquote><p>保存，使生效<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><p>2.hbase 安装<br>下载 hbase-2.1.0-bin.tar.gz 安装包，执行命令<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local</span><br><span class="line">mkdir hbase</span><br><span class="line">tar -zxvf hbase-2.1.0-bin.tar.gz</span><br></pre></td></tr></table></figure></p><p>配置HBASE_HOME等参数。如上参数。</p><p>修改配置文件<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hbase/hbase-2.1.0/conf</span><br><span class="line">vim hbase-env.sh</span><br></pre></td></tr></table></figure></p><p>新增配置参数</p><blockquote><p>export JAVA_HOME=/usr/local/java/jdk1.8.0_212<br>export HBASE_MANAGES_ZK=true</p></blockquote><p>配置hbase数据目录<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hbase/hbase-2.1.0/conf</span><br><span class="line">vim hbase-site.xml</span><br></pre></td></tr></table></figure></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:///usr/local/hbase/hbase-tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>启动habse<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/local/hbase/hbase-2.1.0/bin</span><br><span class="line">./start-hbase.sh</span><br><span class="line"></span><br><span class="line">hbase shell</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.jdk 安装&lt;/p&gt;
&lt;p&gt;下载jdk-8u212-linux-x64.tar.gz安装包，执行命令&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span cla
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hbase" scheme="http://yoursite.com/tags/hbase/"/>
    
  </entry>
  
  <entry>
    <title>lambda 表达式</title>
    <link href="http://yoursite.com/2019/12/03/lambda-%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>http://yoursite.com/2019/12/03/lambda-表达式/</id>
    <published>2019-12-03T06:23:59.000Z</published>
    <updated>2019-12-05T01:59:38.176Z</updated>
    
    <content type="html"><![CDATA[<p>1.什么是lambda表达式</p><blockquote><p>简单讲就是实现将一个代码块赋值给一个变量。如将右边代码块赋给左边变量：<br><img src="/images/2019/12/03/b18cf6d0-1594-11ea-be28-a13eed6a6a63.png" alt="image.png"></p></blockquote><p><img src="/images/2019/12/03/ba23a4f0-1595-11ea-be28-a13eed6a6a63.png" alt="image.png"></p><p>2.lambda表达式的作用</p><blockquote><p>可以使代码变得简洁<br>如我们在不使用lambda表达式实现接口，并调用它时与使用lambda表达式对比<br><img src="/images/2019/12/03/f0f43cb0-1595-11ea-be28-a13eed6a6a63.png" alt="image.png"></p></blockquote><p>参考：zhihu.com/question/20125256/answer/324121308</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.什么是lambda表达式&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;简单讲就是实现将一个代码块赋值给一个变量。如将右边代码块赋给左边变量：&lt;br&gt;&lt;img src=&quot;/images/2019/12/03/b18cf6d0-1594-11ea-be28-a13eed6a6a
      
    
    </summary>
    
      <category term="程序语言" scheme="http://yoursite.com/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="java" scheme="http://yoursite.com/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>spring boot jpa</title>
    <link href="http://yoursite.com/2019/11/30/spring-boot-jpa/"/>
    <id>http://yoursite.com/2019/11/30/spring-boot-jpa/</id>
    <published>2019-11-30T01:04:38.000Z</published>
    <updated>2019-12-05T02:00:07.059Z</updated>
    
    <content type="html"><![CDATA[<p>spring boot jpa<br> jpa 常用于数据库访问</p><p>1.依赖<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span><br><span class="line">         xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt;</span><br><span class="line">    &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line">    &lt;parent&gt;</span><br><span class="line">        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt;</span><br><span class="line">        &lt;version&gt;2.1.5.RELEASE&lt;/version&gt;</span><br><span class="line">        &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;</span><br><span class="line">    &lt;/parent&gt;</span><br><span class="line">    &lt;groupId&gt;com.gree.bdc&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spring-boot-jpa&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt;</span><br><span class="line">    &lt;name&gt;jpa-test&lt;/name&gt;</span><br><span class="line">    &lt;description&gt;jpa-test&lt;/description&gt;</span><br><span class="line"></span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">        &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt;</span><br><span class="line">        &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt;</span><br><span class="line">        &lt;java.version&gt;1.8&lt;/java.version&gt;</span><br><span class="line">    &lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">    &lt;dependencies&gt;</span><br><span class="line">        &lt;!-- spring boot begin--&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">            &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;!--mysql 依赖--&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;8.0.11&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;!-- log4j--&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-log4j&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.3.8.RELEASE&lt;/version&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">        &lt;!-- spring boot jpa --&gt;</span><br><span class="line">        &lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;</span><br><span class="line">        &lt;/dependency&gt;</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    &lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">    &lt;build&gt;</span><br><span class="line">        &lt;plugins&gt;</span><br><span class="line">            &lt;plugin&gt;</span><br><span class="line">                &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">                &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;</span><br><span class="line">            &lt;/plugin&gt;</span><br><span class="line">        &lt;/plugins&gt;</span><br><span class="line">    &lt;/build&gt;</span><br><span class="line"></span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure></p><p>2.application.properties 配置，创建入口类。<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#通用数据源配置</span><br><span class="line"></span><br><span class="line">spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver</span><br><span class="line">spring.datasource.url=jdbc:mysql://localhost:3306/springboot_jpa?charset=utf8mb4&amp;useSSL=false&amp;serverTimezone=GMT</span><br><span class="line">spring.datasource.username=root</span><br><span class="line">spring.datasource.password=123456</span><br><span class="line"># Hikari 数据源专用配置</span><br><span class="line">spring.datasource.hikari.maximum-pool-size=20</span><br><span class="line">spring.datasource.hikari.minimum-idle=5</span><br><span class="line"># JPA 相关配置</span><br><span class="line">spring.jpa.database-platform=org.hibernate.dialect.MySQL5InnoDBDialect</span><br><span class="line">spring.jpa.show-sql=true</span><br><span class="line">spring.jpa.hibernate.ddl-auto=create</span><br></pre></td></tr></table></figure></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">package com.gree.bdc.jpa;</span><br><span class="line"></span><br><span class="line">import org.springframework.boot.SpringApplication;</span><br><span class="line">import org.springframework.boot.autoconfigure.SpringBootApplication;</span><br><span class="line"></span><br><span class="line">@SpringBootApplication</span><br><span class="line">public class JpaApplication &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SpringApplication.run(JpaApplication.class,args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>3.创建实体<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">package com.gree.bdc.jpa.entity;</span><br><span class="line"></span><br><span class="line">import javax.persistence.Column;</span><br><span class="line">import javax.persistence.Entity;</span><br><span class="line">import javax.persistence.Id;</span><br><span class="line">import javax.persistence.Table;</span><br><span class="line"></span><br><span class="line">@Entity</span><br><span class="line">@Table(name = &quot;AUTH_USER&quot;)</span><br><span class="line">public class UserDO &#123;</span><br><span class="line">        @Id</span><br><span class="line">        private Long id;</span><br><span class="line">        @Column(length = 32)</span><br><span class="line">        private String name;</span><br><span class="line">        @Column(length = 32)</span><br><span class="line">        private String account;</span><br><span class="line">        @Column(length = 64)</span><br><span class="line">        private String pwd;</span><br><span class="line"></span><br><span class="line">        public Long getId() &#123;</span><br><span class="line">            return id;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void setId(Long id) &#123;</span><br><span class="line">            this.id = id;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public String getName() &#123;</span><br><span class="line">            return name;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void setName(String name) &#123;</span><br><span class="line">            this.name = name;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public String getAccount() &#123;</span><br><span class="line">            return account;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void setAccount(String account) &#123;</span><br><span class="line">            this.account = account;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public String getPwd() &#123;</span><br><span class="line">            return pwd;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        public void setPwd(String pwd) &#123;</span><br><span class="line">            this.pwd = pwd;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>4.写一个DAO继承Repository或他的子类，执行入口类创建数据库表。后注释掉配置文件</p><p>spring.jpa.hibernate.ddl-auto=create</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">package com.gree.bdc.jpa.repository;</span><br><span class="line"></span><br><span class="line">import com.gree.bdc.jpa.entity.UserDO;</span><br><span class="line">import org.springframework.data.jpa.repository.JpaRepository;</span><br><span class="line">import org.springframework.stereotype.Repository;</span><br><span class="line"></span><br><span class="line">@Repository</span><br><span class="line">public interface UserDAO extends JpaRepository&lt;UserDO,Long&gt; &#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>5.使用DAO调用其操作数据库方法<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">package com.gree.bdc.jpa;</span><br><span class="line"></span><br><span class="line">import com.gree.bdc.jpa.entity.UserDO;</span><br><span class="line">import com.gree.bdc.jpa.repository.UserDAO;</span><br><span class="line">import org.junit.After;</span><br><span class="line">import org.junit.Before;</span><br><span class="line">import org.junit.Test;</span><br><span class="line">import org.junit.runner.RunWith;</span><br><span class="line">import org.springframework.beans.factory.annotation.Autowired;</span><br><span class="line">import org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line">import org.springframework.test.context.junit4.SpringRunner;</span><br><span class="line"></span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">@RunWith(SpringRunner.class)</span><br><span class="line">@SpringBootTest</span><br><span class="line">public class UserDOTest &#123;</span><br><span class="line"></span><br><span class="line">    @Autowired</span><br><span class="line">    private UserDAO userDAO;</span><br><span class="line"></span><br><span class="line">    @Before</span><br><span class="line">    public void before()&#123;</span><br><span class="line">        UserDO userDO = new UserDO();</span><br><span class="line">        userDO.setId(1L);</span><br><span class="line">        userDO.setName(&quot;风清扬&quot;);</span><br><span class="line">        userDO.setAccount(&quot;fengqy&quot;);</span><br><span class="line">        userDO.setPwd(&quot;123456&quot;);</span><br><span class="line">        userDAO.save(userDO);</span><br><span class="line">        userDO = new UserDO();</span><br><span class="line">        userDO.setId(3L);</span><br><span class="line">        userDO.setName(&quot;东方不败&quot;);</span><br><span class="line">        userDO.setAccount(&quot;bubai&quot;);</span><br><span class="line">        userDO.setPwd(&quot;123456&quot;);</span><br><span class="line">        userDAO.save(userDO);</span><br><span class="line">        userDO.setId(5L);</span><br><span class="line">        userDO.setName(&quot;向问天&quot;);</span><br><span class="line">        userDO.setAccount(&quot;wentian&quot;);</span><br><span class="line">        userDO.setPwd(&quot;123456&quot;);</span><br><span class="line">        userDAO.save(userDO);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Test</span><br><span class="line">    public void testAdd()&#123;</span><br><span class="line">        UserDO userDO = new UserDO();</span><br><span class="line">        userDO.setId(2L);</span><br><span class="line">        userDO.setName(&quot;任我行&quot;);</span><br><span class="line">        userDO.setAccount(&quot;renwox&quot;);</span><br><span class="line">        userDO.setPwd(&quot;123456&quot;);</span><br><span class="line">        userDAO.save(userDO);</span><br><span class="line">        userDO = new UserDO();</span><br><span class="line">        userDO.setId(4L);</span><br><span class="line">        userDO.setName(&quot;令狐冲&quot;);</span><br><span class="line">        userDO.setAccount(&quot;linghuc&quot;);</span><br><span class="line">        userDO.setPwd(&quot;123456&quot;);</span><br><span class="line">        userDAO.save(userDO);</span><br><span class="line">    &#125;</span><br><span class="line">    @After</span><br><span class="line">    public void after()&#123;</span><br><span class="line">        userDAO.deleteById(1L);</span><br><span class="line">        List&lt;UserDO&gt; users = userDAO.findAll();</span><br><span class="line">        for(UserDO user: users)&#123;</span><br><span class="line">            System.out.println(user.getName());</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>参考文档：<a href="https://www.jianshu.com/p/c14640b63653" target="_blank" rel="noopener">spring boot jpa</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;spring boot jpa&lt;br&gt; jpa 常用于数据库访问&lt;/p&gt;
&lt;p&gt;1.依赖&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line
      
    
    </summary>
    
      <category term="后台" scheme="http://yoursite.com/categories/%E5%90%8E%E5%8F%B0/"/>
    
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>java 基本知识</title>
    <link href="http://yoursite.com/2019/11/29/java-%E5%9F%BA%E6%9C%AC%E7%9F%A5%E8%AF%86/"/>
    <id>http://yoursite.com/2019/11/29/java-基本知识/</id>
    <published>2019-11-29T02:00:58.000Z</published>
    <updated>2020-01-13T00:59:50.666Z</updated>
    
    <content type="html"><![CDATA[<p>1.泛型<br>  通过泛型可以定义类型安全的数据结构（类型安全），而无须使用实际的数据类型（可扩展）。这能够显著提高性能并得到更高质量的代码（高性能），因为您可以重用数据处理算法，而无须复制类型特定的代码（可重用）。</p><p>2.java.sql.SQLException: Unknown system variable ‘query_cache_size’<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">           &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">           &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">       &lt;/dependency&gt;</span><br></pre></td></tr></table></figure></p><p>3.java.sql.SQLException: The server time zone value ‘ÖÐ¹ú±ê×¼Ê±¼ä’ is unrecognized or represents more than one time zone. You must configure either the server or JDBC driver (via the serverTimezone configuration property) to use a more specifc time zone value if you want to utilize time zone support.</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jdbc:mysql://localhost:3306/springboot_jpa?charset=utf8mb4&amp;useSSL=false&amp;serverTimezone=GMT</span><br></pre></td></tr></table></figure><p>4.java.lang.Exception: No runnable methods</p><blockquote><p>测试时 未在test方法上加上 @test 注解，同时保证注解依赖org.junit.test</p></blockquote><p>5.STRING…</p><blockquote><p>类型后面三个点(String…)，是从Java 5开始，Java语言对方法参数支持一种新写法，叫可变长度参数列表，其语法就是类型后跟…，表示此处接受的参数为0到多个Object类型的对象，或者是一个Object[]。</p></blockquote><p>java 面向对象编程三条主线</p><blockquote><p>1.java类以及类的成员（属性，方法，构造器，代码块）<br>2.java三大特性：封装（封装与隐藏，主要通过权限修饰符来控制），继承和多态<br>3.java关键字：this</p></blockquote><blockquote><p>构造器：每一个类都有构造器，构造器的主要作用就是创建对象，和初始化一些属性值，构造器没有返回值<br>继承：子类继承父类，子类拥有父类的所有结构，主要为：属性和方法，子类还可以拥有自己的属性和方法。<br>关键字：package，import</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.泛型&lt;br&gt;  通过泛型可以定义类型安全的数据结构（类型安全），而无须使用实际的数据类型（可扩展）。这能够显著提高性能并得到更高质量的代码（高性能），因为您可以重用数据处理算法，而无须复制类型特定的代码（可重用）。&lt;/p&gt;
&lt;p&gt;2.java.sql.SQLExcept
      
    
    </summary>
    
      <category term="程序语言" scheme="http://yoursite.com/categories/%E7%A8%8B%E5%BA%8F%E8%AF%AD%E8%A8%80/"/>
    
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>spark 常用 api</title>
    <link href="http://yoursite.com/2019/11/26/spark-%E5%B8%B8%E7%94%A8-api/"/>
    <id>http://yoursite.com/2019/11/26/spark-常用-api/</id>
    <published>2019-11-26T03:20:57.000Z</published>
    <updated>2019-12-05T02:00:57.104Z</updated>
    
    <content type="html"><![CDATA[<p>1.spark 中采用部分关联字段</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">//可以看出Temp_khcp 字段包含 first_chart 字段 ，通过部分关联来实现表连接</span><br><span class="line">  val alphabet_Beign = number_Beign.join(custom_file_regular, col(&quot;Temp_khcp&quot;).startsWith(col(&quot;first_chart&quot;)), &quot;left&quot;).drop(&quot;first_chart&quot;).na.fill(&quot;&quot;, Seq(&quot;before_file&quot;))</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.spark 中采用部分关联字段&lt;/p&gt;
&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>Docker 三剑客之 Docker Compose</title>
    <link href="http://yoursite.com/2019/10/25/Docker-%E4%B8%89%E5%89%91%E5%AE%A2%E4%B9%8B-Docker-Compose/"/>
    <id>http://yoursite.com/2019/10/25/Docker-三剑客之-Docker-Compose/</id>
    <published>2019-10-25T00:55:10.000Z</published>
    <updated>2019-12-05T02:01:32.914Z</updated>
    
    <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Docker Compose 定位是 定义和运行多个docker容器应用（Defining and running multi-container Docker applications）</span><br><span class="line"></span><br><span class="line">它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）</span><br><span class="line"></span><br><span class="line">Compose 中有两个重要的概念：</span><br><span class="line"></span><br><span class="line">服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。</span><br><span class="line">项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。</span><br></pre></td></tr></table></figure><h1 id="安装与卸载"><a href="#安装与卸载" class="headerlink" title="安装与卸载"></a>安装与卸载</h1><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1.安装</span><br><span class="line">$ sudo curl -L https://github.com/docker/compose/releases/download/1.17.1/docker-compose-`uname -s`-`uname -m` &gt; /usr/local/bin/docker-compose</span><br><span class="line">$ sudo chmod +x /usr/local/bin/docker-compose</span><br><span class="line"></span><br><span class="line">2.卸载</span><br><span class="line">sudo rm /usr/local/bin/docker-compose</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h1&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;
      
    
    </summary>
    
      <category term="后台" scheme="http://yoursite.com/categories/%E5%90%8E%E5%8F%B0/"/>
    
    
      <category term="docker" scheme="http://yoursite.com/tags/docker/"/>
    
  </entry>
  
</feed>
