<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>上善若水博客</title>
  
  <subtitle>大数据</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-07-24T07:11:11.184Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>上善若水</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>markdowm语法笔记</title>
    <link href="http://yoursite.com/2020/07/24/markdowm%E8%AF%AD%E6%B3%95%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/07/24/markdowm语法笔记/</id>
    <published>2020-07-24T02:12:24.000Z</published>
    <updated>2020-07-24T07:11:11.184Z</updated>
    
    <content type="html"><![CDATA[<h1 id="markdown语法"><a href="#markdown语法" class="headerlink" title="markdown语法"></a>markdown语法</h1><h2 id="1-斜体和粗体"><a href="#1-斜体和粗体" class="headerlink" title="1. 斜体和粗体"></a>1. 斜体和粗体</h2><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">*斜体*或_斜体_</span><br><span class="line">**粗体**</span><br><span class="line">***加粗斜体***</span><br><span class="line">~~删除线~~</span><br></pre></td></tr></table></figure><p>显示效果：<br><img src="/images/2020/07/24/80b46735-9655-4f19-ae5a-ef21d5491ea4.png" alt="image.png"></p><h2 id="2-分级标题"><a href="#2-分级标题" class="headerlink" title="2.分级标题"></a>2.分级标题</h2><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">这是一个一级标题</span><br><span class="line">============================</span><br><span class="line"></span><br><span class="line">这是一个二级标题</span><br><span class="line">--------------------------------------------------</span><br></pre></td></tr></table></figure><p><img src="/images/2020/07/24/0df888f7-8a5e-4675-ac35-ea4e914fdec7.png" alt="image.png"></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 一级标题</span><br><span class="line">## 二级标题</span><br><span class="line">### 三级标题</span><br><span class="line">#### 四级标题</span><br><span class="line">##### 五级标题</span><br><span class="line">###### 六级标题</span><br></pre></td></tr></table></figure><p><img src="/images/2020/07/24/4aef7631-4fa7-4570-9210-8bdb314f09c9.png" alt="image.png"></p><h2 id="3-链接"><a href="#3-链接" class="headerlink" title="3.链接"></a>3.链接</h2><ul><li>行内链接<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">欢迎来到[百度的主页](http://www.baidu.com)</span><br><span class="line"></span><br><span class="line">欢迎来到[百度的主页](http://www.baidu.com &quot;百度的主页&quot;)</span><br></pre></td></tr></table></figure></li></ul><p><img src="/images/2020/07/24/7a8cb724-e2a1-4d8b-87ca-8c7ac65bcabc.png" alt="image.png"></p><ul><li>参考式链接</li></ul><figure class="highlight java hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">我经常去的几个网站[GitHub][<span class="hljs-number">1</span>]、[知乎][<span class="hljs-number">2</span>]以及[简书][<span class="hljs-number">3</span>]</span><br><span class="line">[简书][<span class="hljs-number">3</span>]是一个不错的[写作社区][]。</span><br><span class="line"></span><br><span class="line">[<span class="hljs-number">1</span>]:https:<span class="hljs-comment">//github.com "GitHub"</span></span><br><span class="line">[<span class="hljs-number">2</span>]:https:<span class="hljs-comment">//www.zhihu.com "知乎"</span></span><br><span class="line">[<span class="hljs-number">3</span>]:http:<span class="hljs-comment">//www.jianshu.com "简书"</span></span><br><span class="line">[写作社区]:http:<span class="hljs-comment">//www.jianshu.com</span></span><br></pre></td></tr></table></figure><p><img src="/images/2020/07/24/d924005f-b773-4094-9704-ac39a482a048.png" alt="image.png"></p><ul><li>自动链接<figure class="highlight html hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">http:</span>//<span class="hljs-attr">example.com</span>/&gt;</span></span><br><span class="line"><span class="hljs-tag">&lt;<span class="hljs-name">address@example.com</span>&gt;</span></span><br></pre></td></tr></table></figure></li></ul><p><img src="/images/2020/07/24/1bf3a49f-e4c1-4985-80c5-06a3a3e607a9.png" alt="image.png"></p><h2 id="4-锚点"><a href="#4-锚点" class="headerlink" title="4.锚点"></a>4.锚点</h2><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">## 0. 目录&#123;#index&#125;</span><br><span class="line">跳转到[目录](#index)</span><br></pre></td></tr></table></figure><p><img src="/images/2020/07/24/2cc0d0c8-e198-43d3-a00d-f0576591ccf7.png" alt="image.png"></p><h2 id="5-列表"><a href="#5-列表" class="headerlink" title="5.列表"></a>5.列表</h2><ul><li><p>无序列表</p><blockquote><p> *，+，- 表示无序列表</p></blockquote></li><li><p>有序列表</p><blockquote><p> 有序列表则使用数字接着一个英文句点。</p></blockquote></li><li><p>定义型列表</p><blockquote><p>定义型列表由名词和解释组成。一行写上定义，紧跟一行写上解释。解释的写法:紧跟一个缩进(Tab)</p></blockquote></li></ul><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Markdown</span><br><span class="line">:    轻量级文本标记语言，可以转换成html，pdf等格式（左侧有一个可见的冒号和四个不可见的空格）</span><br><span class="line"></span><br><span class="line">代码块 2</span><br><span class="line">:   这是代码块的定义（左侧有一个可见的冒号和四个不可见的空格）</span><br><span class="line"></span><br><span class="line">        代码块（左侧有八个不可见的空格）</span><br></pre></td></tr></table></figure><ul><li>列表缩进</li></ul><h2 id="6-引用"><a href="#6-引用" class="headerlink" title="6. 引用"></a>6. 引用</h2><blockquote><p>区块引用可以嵌套（例如：引用内的引用），只要根据层次加上不同数量的 &gt;：<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; 请问 Markdwon 怎么用？ - 小白</span><br><span class="line"></span><br><span class="line">&gt;&gt;自己看教程！ - 愤青</span><br><span class="line"></span><br><span class="line">&gt;教程在哪？ - 小白</span><br></pre></td></tr></table></figure></p></blockquote><h2 id="7-图片插入"><a href="#7-图片插入" class="headerlink" title="7.图片插入"></a>7.图片插入</h2><blockquote><p> <img src="图片地址" alt="图片Alt" title="图片Title"></p></blockquote><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">快乐学习： </span><br><span class="line">![快乐学习](http://upload-images.jianshu.io/upload_images/1001659-7535c9e3fe16240d?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240 &quot;快乐学习&quot;)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;markdown语法&quot;&gt;&lt;a href=&quot;#markdown语法&quot; class=&quot;headerlink&quot; title=&quot;markdown语法&quot;&gt;&lt;/a&gt;markdown语法&lt;/h1&gt;&lt;h2 id=&quot;1-斜体和粗体&quot;&gt;&lt;a href=&quot;#1-斜体和粗体&quot; class
      
    
    </summary>
    
      <category term="开发工具" scheme="http://yoursite.com/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="工具" scheme="http://yoursite.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
      <category term="markdowm" scheme="http://yoursite.com/tags/markdowm/"/>
    
  </entry>
  
  <entry>
    <title>持续集成与持续部署（CICD）笔记</title>
    <link href="http://yoursite.com/2020/07/23/%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E4%B8%8E%E6%8C%81%E7%BB%AD%E9%83%A8%E7%BD%B2%EF%BC%88CICD%EF%BC%89%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2020/07/23/持续集成与持续部署（CICD）笔记/</id>
    <published>2020-07-23T01:40:06.000Z</published>
    <updated>2020-07-23T09:08:06.949Z</updated>
    
    <content type="html"><![CDATA[<h1 id="持续集成与持续部署"><a href="#持续集成与持续部署" class="headerlink" title="持续集成与持续部署"></a>持续集成与持续部署</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><blockquote><p>互联网软件的开发和发布，已经形成了一套标准流程，最重要的组成部分就是持续集成（Continuous integration，简称CI）。</p></blockquote><h3 id="1-持续集成"><a href="#1-持续集成" class="headerlink" title="1. 持续集成"></a>1. 持续集成</h3><p><strong>持续集成</strong>指的是，频繁地（一天多次）将代码集成到主干。它的好处主要有两个：</p><ul><li>快速发现错误。每完成一点更新，就集成到主干，可以快速发现错误，定位错误也比较容易。</li><li><p>防止分支大幅偏离主干。如果不是经常集成，主干又在不断更新，会导致以后集成的难度变大，甚至难以集成。</p><p>持续集成强调开发人员提交了新代码之后，立刻进行<strong>构建</strong>、（单元）<strong>测试</strong>。根据测试结果，我们可以确定新代码和原有代码能否正确地集成在一起。</p></li></ul><h3 id="2-持续交付"><a href="#2-持续交付" class="headerlink" title="2.持续交付"></a>2.持续交付</h3><blockquote><p><strong>持续交付</strong>（Continuous delivery）指的是，频繁地将软件的新版本，交付给质量团队或者用户，以供评审。如果评审通过，代码就进入生产阶段。</p></blockquote><blockquote><p>持续交付可以看作持续集成的下一步。它强调的是，不管怎么更新，软件是<strong>随时随地</strong>可以交付的。</p></blockquote><blockquote><p>持续交付在持续集成的基础上，将集成后的代码部署到更贴近真实运行环境的「类生产环境」（production-like environments）中。比如，我们完成单元测试后，可以把代码部署到连接数据库的 Staging 环境中更多的测试。如果代码没有问题，可以继续手动部署到生产环境中。</p></blockquote><p><img src="/images/2020/07/23/87bb2c99-d9be-430c-ba99-d38a045ba9ac.png" alt="image.png"></p><h3 id="3-持续部署"><a href="#3-持续部署" class="headerlink" title="3.持续部署"></a>3.持续部署</h3><blockquote><p><strong>持续部署</strong>（continuous deployment）是持续交付的下一步，指的是代码通过<strong>评审</strong>以后，自动部署到生产环境。</p></blockquote><blockquote><p>持续部署的目标是，代码在任何时刻都是可部署的，可以进入生产阶段。</p></blockquote><blockquote><p>持续部署的前提是能自动化完成测试、构建、部署等步骤。</p></blockquote><p><img src="/images/2020/07/23/9ebcee37-01e9-40eb-bac4-bbc97b255d2d.png" alt="image.png"></p><p>参考文档：<a href="https://www.funtl.com/zh/spring-cloud-itoken-ci/#%E6%8C%81%E7%BB%AD%E4%BA%A4%E4%BB%98" target="_blank" rel="noopener">千峰教育微服务</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;持续集成与持续部署&quot;&gt;&lt;a href=&quot;#持续集成与持续部署&quot; class=&quot;headerlink&quot; title=&quot;持续集成与持续部署&quot;&gt;&lt;/a&gt;持续集成与持续部署&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
      <category term="后台" scheme="http://yoursite.com/categories/%E5%90%8E%E5%8F%B0/"/>
    
    
      <category term="笔记" scheme="http://yoursite.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
      <category term="CICD" scheme="http://yoursite.com/tags/CICD/"/>
    
  </entry>
  
  <entry>
    <title>hadoop</title>
    <link href="http://yoursite.com/2020/07/22/hadoop/"/>
    <id>http://yoursite.com/2020/07/22/hadoop/</id>
    <published>2020-07-22T02:52:34.000Z</published>
    <updated>2020-07-23T01:13:51.270Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-hadoop"><a href="#1-hadoop" class="headerlink" title="1. hadoop"></a>1. hadoop</h1><blockquote><p>Apache Hadoop 软件库是一个框架，它允许使用简单的编程模型跨计算机群集对大型数据集进行分布式处理。它旨在从单个服务器扩展到数千台计算机，每台计算机都提供本地计算和存储。库本身不是依靠硬件来提供高可用性，而是用于检测和处理应用程序层的故障，因此在计算机群集上提供高可用性服务，每个计算机群集都容易发生故障。</p></blockquote><p><strong>Hadoop架构</strong><br><img src="/images/2020/07/22/ca504f8d-eea8-45bf-a06a-c2675b07161f.png" alt="image.png"></p><h2 id="1-1-hdfs"><a href="#1-1-hdfs" class="headerlink" title="1.1 hdfs"></a>1.1 hdfs</h2><blockquote><p>分布式文件存储系统（hadoop distribute file system）</p></blockquote><p><strong>架构</strong><br><img src="/images/2020/07/22/f3f33cf0-a978-441b-a357-a964fd398c89.png" alt="image.png"></p><ul><li><strong>Block数据块</strong><br>① 基本存储单位，一般大小为64M（配置大的块主要是因为：1）减少搜寻时间，一般硬盘传输速率比寻道时间要快，大的块可以减少寻道时间；2）减少管理块的数据开销，每个块都需要在NameNode上有对应的记录；3）对数据块进行读写，减少建立网络的连接成本）<br>② 一个大文件会被拆分成一个个的块，然后存储于不同的机器。如果一个文件少于Block大小，那么实际占用的空间为其文件的大小<br>③ 基本的读写单位，类似于磁盘的页，每次都是读写一个块<br>④ 每个块都会被复制到多台机器，默认复制3份</li><li><strong>NameNode</strong><br>① 存储文件的metadata，运行时所有数据都保存到内存，整个HDFS可存储的文件数受限于NameNode的内存大小<br>② 一个Block在NameNode中对应一条记录（一般一个block占用150字节），如果是大量的小文件，会消耗大量内存。同时map task的数量是由splits来决定的，所以用MapReduce处理大量的小文件时，就会产生过多的map task，线程管理开销将会增加作业时间。处理大量小文件的速度远远小于处理同等大小的大文件的速度。因此<strong>Hadoop建议存储大文件</strong><br>③ 数据会定时保存到本地磁盘，但不保存block的位置信息，而是由DataNode注册时上报和运行时维护（NameNode中与DataNode相关的信息并不保存到NameNode的文件系统中，而是NameNode每次重启后，动态重建）<br>④ NameNode失效则整个HDFS都失效了，所以要保证NameNode的可用性</li><li><strong>Secondary NameNode</strong><br>① 定时与NameNode进行同步（定期合并文件系统镜像和编辑日志，然后把合并后的传给NameNode，替换其镜像，并清空编辑日志，类似于CheckPoint机制），但NameNode失效后仍需要手工将其设置成主机</li><li><strong>DataNode</strong><br>① 保存具体的block数据<br>② 负责数据的读写操作和复制操作<br>③ DataNode启动时会向NameNode报告当前存储的数据块信息，后续也会定时报告修改信息<br>④ DataNode之间会进行通信，复制数据块，保证数据的冗余性</li></ul><h3 id="1-1-1-hdfs写文件"><a href="#1-1-1-hdfs写文件" class="headerlink" title="1.1.1 hdfs写文件"></a>1.1.1 hdfs写文件</h3><p><img src="/images/2020/07/22/47e11694-a856-4a14-9e83-8597a9eefb46.png" alt="image.png"></p><ul><li>客户端将文件写入本地磁盘的HDFS Client文件中</li><li>当临时文件大小达到一个block大小时，HDFS client通知NameNode，申请写入文件</li><li>NameNode在HDFS的文件系统中创建一个文件，并把该block id和要写入的DataNode的列表返回给客户端</li><li>客户端收到这些信息后，将临时文件写入DataNodes<br>① 客户端将文件内容写入第一个DataNode（一般以4kb为单位进行传输）<br>② 第一个DataNode接收后，将数据写入本地磁盘，同时也传输给第二个DataNode<br>③ 依此类推到最后一个DataNode，数据在DataNode之间是通过pipeline的方式进行复制的<br>④ 后面的DataNode接收完数据后，都会发送一个确认给前一个DataNode，最终第一个DataNode返回确认给客户端<br>⑤ 当客户端接收到整个block的确认后，会向NameNode发送一个最终的确认信息<br>⑥ 如果写入某个DataNode失败，数据会继续写入其他的DataNode。然后NameNode会找另外一个好的DataNode继续复制，以保证冗余性<br>⑦ 每个block都会有一个校验码，并存放到独立的文件中，以便读的时候来验证其完整性</li><li>文件写完后（客户端关闭），NameNode提交文件（这时文件才可见，如果提交前，NameNode垮掉，那文件也就丢失了。fsync：只保证数据的信息写到NameNode上，但并不保证数据已经被写到DataNode中）</li></ul><h3 id="1-1-2-hdfs读文件"><a href="#1-1-2-hdfs读文件" class="headerlink" title="1.1.2 hdfs读文件"></a>1.1.2 hdfs读文件</h3><p><img src="/images/2020/07/22/c788be00-24fc-48de-b091-55df8e5f2484.png" alt="image.png"><br>① 客户端向NameNode发送读取请求<br>② NameNode返回文件的所有block和这些block所在的DataNodes（包括复制节点）<br>③ 客户端直接从DataNode中读取数据，如果该DataNode读取失败（DataNode失效或校验码不对），则从复制节点中读取（如果读取的数据就在本机，则直接读取，否则通过网络读取）</p><h3 id="1-1-3-hadoop-可靠性"><a href="#1-1-3-hadoop-可靠性" class="headerlink" title="1.1.3 hadoop 可靠性"></a>1.1.3 hadoop 可靠性</h3><p>① DataNode可以失效<br>② DataNode会定时发送心跳到NameNode。如果一段时间内NameNode没有收到DataNode的心跳消息，则认为其失效。此时NameNode就会将该节点的数据（从该节点的复制节点中获取）复制到另外的DataNode中<br>③ 数据可以毁坏<br>④无论是写入时还是硬盘本身的问题，只要数据有问题（读取时通过校验码来检测），都可以通过其他的复制节点读取，同时还会再复制一份到健康的节点中<br>⑤NameNode不可靠</p><h2 id="1-2-mapreduce"><a href="#1-2-mapreduce" class="headerlink" title="1.2 mapreduce"></a>1.2 mapreduce</h2><blockquote><p>分布式计算系统（map，reduce）</p></blockquote><blockquote><p>一种分布式的计算方式指定一个Map（映#x5C04;）函数，用来把一组键值对映射成一组新的键值对，指定并发的Reduce（归约）函数，用来保证所有映射的键值对中的每一个共享相同的键组</p></blockquote><p><strong>模式</strong><br><img src="/images/2020/07/23/e82b08e7-b657-43d6-b296-debcc3b54c0c.png" alt="image.png"></p><p>主要过程：<br><img src="/images/2020/07/23/47755cfe-d26e-405b-96b7-efa7dbf92ff5.png" alt="image.png"></p><p><strong>Map Side</strong></p><p><strong>Record reader</strong></p><blockquote><p>记录阅读器会翻译由输入格式生成的记录，记录阅读器用于将数据解析给记录，并不分析记录自身。记录读取器的目的是将数据解析成记录，但不分析记录本身。它将数据以键值对的形式传输给mapper。通常键是位置信息，值是构成记录的数据存储块.自定义记录不在本文讨论范围之内.</p></blockquote><p><strong>Map</strong></p><blockquote><p>在映射器中用户提供的代码称为中间对。对于键值的具体定义是慎重的，因为定义对于分布式任务的完成具有重要意义.键决定了数据分类的依据，而值决定了处理器中的分析信息.本书的设计模式将会展示大量细节来解释特定键值如何选择.</p></blockquote><p><strong>Shuffle and Sort</strong></p><blockquote><p>ruduce任务以随机和排序步骤开始。此步骤写入输出文件并下载到本地计算机。这些数据采用键进行排序以把等价密钥组合到一起。</p></blockquote><p><strong>Reduce</strong></p><blockquote><p>reducer采用分组数据作为输入。该功能传递键和此键相关值的迭代器。可以采用多种方式来汇总、过滤或者合并数据。当ruduce功能完成，就会发送0个或多个键值对。</p></blockquote><p><strong>输出格式</strong></p><blockquote><p>输出格式会转换最终的键值对并写入文件。默认情况下键和值以tab分割，各记录以换行符分割。因此可以自定义更多输出格式，最终数据会写入HDFS。类似记录读取，自定义输出格式不在本书范围。</p></blockquote><h2 id="1-3-yarn"><a href="#1-3-yarn" class="headerlink" title="1.3 yarn"></a>1.3 yarn</h2><blockquote><p>分布式资源管理系统</p></blockquote><p><strong>旧的MapReduce架构</strong><br><img src="/images/2020/07/22/c019477d-70a9-42d8-886f-9d50831ed908.png" alt="image.png"></p><ul><li><strong>JobTracker</strong> ： 负责资源管理，跟踪资源消耗和可用性，作业生命周期管理（调度作业任务，跟踪进度，为任务提供容错）</li><li><strong>TaskTracker</strong> ： 加载或关闭任务，定时报告任务状态</li></ul><p>此架构会有以下问题：<br>    ① JobTracker是MapReduce的集中处理点，存在单点故障<br>    ② JobTracker完成了太多的任务，造成了过多的资源消耗，当MapReduce job 非常多的时候，会造成很大的内存开销。这也是业界普遍总结出老Hadoop的MapReduce只能支持4000 节点主机的上限<br>    ③在TaskTracker端，以map/reduce task的数目作为资源的表示过于简单，没有考虑到cpu/ 内存的占用情况，如果两个大内存消耗的task被调度到了一块，很容易出现OOM<br>    ④ 在TaskTracker端，把资源强制划分为map task slot和reduce task slot, 如果当系统中只有map task或者只有reduce task的时候，会造成资源的浪费，也就集群资源利用的问题</p><p>总的来说就是<strong>单点问题</strong>和<strong>资源利用率问题</strong></p><p><strong>YARN架构</strong><br><img src="/images/2020/07/22/25507eb1-ef6a-4b33-986f-34b7c522a77d.png" alt="image.png"><br><img src="/images/2020/07/22/8aa945ab-3aa2-4aa8-a862-9c93fad8a6fd.png" alt="image.png"></p><p>YARN就是将JobTracker的职责进行拆分，将资源管理和任务调度监控拆分成独立#x7ACB;的进程：一个全局的资源管理和一个每个作业的管理（ApplicationMaster） ResourceManager和NodeManager提供了计算资源的分配和管理，而ApplicationMaster则完成应用程序的运行</p><ul><li>ResourceManager: 全局资源管理和任务调度</li><li>NodeManager: 单个节点的资源管理和监控</li><li>ApplicationMaster: 单个作业的资源管理和任务监控</li><li>Container: 资源申请的单位和任务运行的容器</li></ul><p><strong>YARN基本流程</strong><br><img src="/images/2020/07/22/6f798eb8-2151-4548-b2f0-16f79669467e.png" alt="image.png"><br><img src="/images/2020/07/22/2707808d-7af2-41d2-b649-ade6b4b0e74c.png" alt="image.png"></p><p>① Job submission</p><blockquote><p>从ResourceManager中获取一个Application ID 检查作业输出配置，计算输入分片 拷贝作业资源（job jar、配置文件、分片信息）到HDFS，以便后面任务的执行</p></blockquote><p>② Job initialization</p><blockquote><p>ResourceManager将作业递交给Scheduler（有很多调度算法，一般是根据优先级）Scheduler为作业分配一个Container，ResourceManager就加载一个application master process并交给NodeManager管理ApplicationMaster主要是创建一系列的监控进程来跟踪作业的进度，同时获取输入分片，为每一个分片创建一个Map task和相应的reduce task Application Master还决定如何运行作业，如果作业很小（可配置），则直接在同一个JVM下运行</p></blockquote><p>③ Task assignment</p><blockquote><p>ApplicationMaster向Resource Manager申请资源（一个个的Container，指定任务分配的资源要求）一般是根据data locality来分配资源</p></blockquote><p>④ Task execution</p><blockquote><p>ApplicationMaster根据ResourceManager的分配情况，在对应的NodeManager中启动Container 从HDFSN#x4E2D;读取任务所需资源（job jar，配置文件等），然后执行该任务</p></blockquote><p>⑤ Progress and status update</p><blockquote><p>定时将任务的进度和状态报告给ApplicationMaster Client定时向ApplicationMaster获取整个任务的进度和状态</p></blockquote><p>⑥ Job completion</p><blockquote><p>Client定时检查整个作业是否完成 作业完成后，会清空临时文件、目录等</p></blockquote><h2 id="1-4-Others"><a href="#1-4-Others" class="headerlink" title="1.4 Others"></a>1.4 Others</h2><blockquote><p>利用YARN的资源管理功能实现其他的数据处理方式</p></blockquote><p>参考文档：<a href="https://www.w3cschool.cn/hadoop/xvmi1hd6.html" target="_blank" rel="noopener">w3cschool Hadoop</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;1-hadoop&quot;&gt;&lt;a href=&quot;#1-hadoop&quot; class=&quot;headerlink&quot; title=&quot;1. hadoop&quot;&gt;&lt;/a&gt;1. hadoop&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Apache Hadoop 软件库是一个框架，它允许使用简单的
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
      <category term="笔记" scheme="http://yoursite.com/tags/%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>hue 提交程序报错总结</title>
    <link href="http://yoursite.com/2020/07/17/hue-%E6%8F%90%E4%BA%A4%E7%A8%8B%E5%BA%8F%E6%8A%A5%E9%94%99%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2020/07/17/hue-提交程序报错总结/</id>
    <published>2020-07-17T01:25:21.000Z</published>
    <updated>2020-07-17T01:25:21.444Z</updated>
    
    <content type="html"><![CDATA[<p>1.hue提交程序时依赖jar包小技巧<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">默认是先在工作区和默认路径找到所有的jar包，若有jar包冲突，则需要手动去除掉工作区的jar包，若jar包缺失则需要手动加上jar包</span><br><span class="line">若两个工作目录都有jar包，但版本不一致，默认使用工作区间的jar包，此时需要选择正确的版本号。</span><br><span class="line"></span><br><span class="line">① jar包冲突 Caused by: org.apache.hadoop.mapred.InvalidJobConfException: cache file (mapreduce.job.cache.files) scheme: &quot;hdfs&quot; host: &quot;nameservice1&quot; port: -1 file: &quot;/user/hue/oozie/workspaces/hue-oozie-1585550821.94/lib/slf4j-log4j12-1.7.25.jar&quot; conflicts with cache file (mapreduce.job.cache.files) hdfs://nameservice1/user/oozie/share/lib/lib_20190819164924/spark/slf4j-log4j12-1.7.25.jar</span><br><span class="line">（解决办法 ：去掉工作区jar包 ）</span><br><span class="line">② jar包缺失 [main] ERROR org.apache.spark.deploy.yarn.Client - Application diagnostics message: User class threw exception: org.apache.spark.sql.AnalysisException: Failed to find data source: kafka. Please deploy the application as per the deployment section of &quot;Structured Streaming + Kafka Integration Guide&quot;.;</span><br><span class="line">（解决办法：在工作区新增jar包）</span><br><span class="line">③jar包版本不对 </span><br><span class="line">Application diagnostics message: User class threw exception: java.lang.NoSuchMethodError: org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Iface.get_all_functions()Lorg/apache/hadoop/hive/metastore/api/GetAllFunctionsResponse;</span><br><span class="line">（解决办法：更换正确版本jar包，或者去掉工作区jar包）</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.hue提交程序时依赖jar包小技巧&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hue" scheme="http://yoursite.com/tags/hue/"/>
    
  </entry>
  
  <entry>
    <title>SecureCRT 安装和下载</title>
    <link href="http://yoursite.com/2020/07/16/SecureCRT-%E5%AE%89%E8%A3%85%E5%92%8C%E4%B8%8B%E8%BD%BD/"/>
    <id>http://yoursite.com/2020/07/16/SecureCRT-安装和下载/</id>
    <published>2020-07-16T05:58:06.000Z</published>
    <updated>2020-07-16T06:33:43.553Z</updated>
    
    <content type="html"><![CDATA[<p>1.下载</p><blockquote><p>链接：<a href="https://pan.baidu.com/s/1CrMxHO5eaj15CV7GzzgheQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1CrMxHO5eaj15CV7GzzgheQ</a><br>提取码：o1sa</p></blockquote><p>2.解压安装<br><img src="/images/2020/07/16/03858510-c729-11ea-85dc-6bd40b871a61.png" alt="image.png"></p><p>3.输入以下注册信息，其中任意一个都行，第一个清册有效<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Name:meisi</span><br><span class="line">Company:TEAM ZWT</span><br><span class="line">Serial Number:03-14-367662</span><br><span class="line">License Key:ACCFAX R9FHJ7 QZVS2P JPBCVA ABCMBF HNEJ2T R9EVZN 2EEK2Q</span><br><span class="line">Issue Date:01-30-2018</span><br><span class="line">Features:</span><br><span class="line"> </span><br><span class="line">=========================</span><br><span class="line"></span><br><span class="line">Name:Ronaldo</span><br><span class="line">Company:TEAM ZWT</span><br><span class="line">Serial Number:03-49-375243</span><br><span class="line">License Key:ACGRNV 7BS22M RHCXRZ Q1ZTU6 AAUAUZ NGR1BA BQYM94 2JVHP4</span><br><span class="line">Issue Date:01-30-2018</span><br><span class="line">Features:</span><br></pre></td></tr></table></figure></p><p>4.外观设置</p><p><img src="/images/2020/07/16/dc170a00-c72b-11ea-85dc-6bd40b871a61.png" alt="image.png"></p><p>①设置主题背景<br><img src="/images/2020/07/16/2a1534b0-c72d-11ea-85dc-6bd40b871a61.png" alt="image.png"></p><p><img src="/images/2020/07/16/48747970-c72d-11ea-85dc-6bd40b871a61.png" alt="image.png"></p><p><img src="/images/2020/07/16/c9e0cc70-c72d-11ea-85dc-6bd40b871a61.png" alt="image.png"></p><p><img src="/images/2020/07/16/ff339dd0-c72d-11ea-85dc-6bd40b871a61.png" alt="image.png"></p><p><img src="/images/2020/07/16/49cf0af0-c72e-11ea-85dc-6bd40b871a61.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.下载&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;链接：&lt;a href=&quot;https://pan.baidu.com/s/1CrMxHO5eaj15CV7GzzgheQ&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://pan.baidu.co
      
    
    </summary>
    
      <category term="开发工具" scheme="http://yoursite.com/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="开发工具" scheme="http://yoursite.com/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>hive 数据库</title>
    <link href="http://yoursite.com/2020/07/06/hive-%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    <id>http://yoursite.com/2020/07/06/hive-数据库/</id>
    <published>2020-07-06T01:12:08.000Z</published>
    <updated>2020-07-06T04:21:07.388Z</updated>
    
    <content type="html"><![CDATA[<p>1.hive临时表<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：hive临时表只对当前的会话有效，可以在程序执行是选择创建，但其也有缺陷就是不支持分区字段和创建索引</span><br></pre></td></tr></table></figure></p><p>2.hive临时表一般用处不大，再出现中不容易使用<br>建议采用创建内部表，并在程序执行前后执行删除内部表的操作</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.hive临时表&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>spark 读取hive jdbc方式</title>
    <link href="http://yoursite.com/2020/07/03/spark-%E8%AF%BB%E5%8F%96hive-jdbc%E6%96%B9%E5%BC%8F/"/>
    <id>http://yoursite.com/2020/07/03/spark-读取hive-jdbc方式/</id>
    <published>2020-07-03T10:46:08.000Z</published>
    <updated>2020-07-03T10:46:08.257Z</updated>
    
    <content type="html"><![CDATA[<p>1.先通过hive-jdbc读取出来的到resultset，然后再将resultset转成list，在将list 转成dataset<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></p><p>2.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.先通过hive-jdbc读取出来的到resultset，然后再将resultset转成list，在将list 转成dataset&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>flink 提交命令</title>
    <link href="http://yoursite.com/2020/06/30/flink-%E6%8F%90%E4%BA%A4%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2020/06/30/flink-提交命令/</id>
    <published>2020-06-30T07:36:41.000Z</published>
    <updated>2020-06-30T07:36:41.961Z</updated>
    
    <content type="html"><![CDATA[<p>一、flink 提交运行程序一般有两种方式<br>1.通过flink监控界面来提交flink程序<br>2.通过命令行的方式提交命令</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">nohup flink run -p 1 -c com.gree.bdc.track.DeviceTrackInfo /home/bdcopt/spark/logistics/test/car-track-show-test.jar --paramProperties /home/bdcopt/spark/logistics/test/druid-test.properties  &gt; /home/bdcopt/spark/logistics/test/car-track-show-test.log 2&gt;&amp;1  &amp;</span><br><span class="line"></span><br><span class="line">解释 ：flink run 运行</span><br><span class="line"></span><br><span class="line">-p 配置job的并行度</span><br><span class="line">-c 指定主类</span><br><span class="line">/home/bdcopt/spark/logistics/test/car-track-show-test.jar 可运行jar</span><br><span class="line"></span><br><span class="line">--paramProperties 自定义指定额外配置文件</span><br><span class="line">如：</span><br><span class="line"> try &#123;</span><br><span class="line">            ParameterTool parameterTool = ParameterTool.fromArgs(args);</span><br><span class="line">            String druidProperties = parameterTool.get(&quot;paramProperties&quot;);</span><br><span class="line">            ///加载类路径</span><br><span class="line">            properties.load(new FileInputStream(druidProperties));</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;一、flink 提交运行程序一般有两种方式&lt;br&gt;1.通过flink监控界面来提交flink程序&lt;br&gt;2.通过命令行的方式提交命令&lt;/p&gt;
&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>spark 集群常见错误</title>
    <link href="http://yoursite.com/2020/06/26/spark-%E9%9B%86%E7%BE%A4%E5%B8%B8%E8%A7%81%E9%94%99%E8%AF%AF/"/>
    <id>http://yoursite.com/2020/06/26/spark-集群常见错误/</id>
    <published>2020-06-26T01:02:41.000Z</published>
    <updated>2020-07-06T04:25:00.653Z</updated>
    
    <content type="html"><![CDATA[<p>1.本地依赖jar与集群jar包冲突<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">org.apache.oozie.action.ActionExecutorException: JA009: cache file (mapreduce.job.cache.files) scheme: &quot;hdfs&quot; host: &quot;nameservice1&quot; port: -1 file: &quot;/user/hue/oozie/workspaces/hue-oozie-1585558811.97/lib/spark-sql-kafka-0-10_2.11-2.4.0-cdh6.3.0.jar&quot; conflicts with cache file (mapreduce.job.cache.files) hdfs://nameservice1/user/oozie/share/lib/lib_20190819164924/spark/spark-sql-kafka-0-10_2.11-2.4.0-cdh6.3.0.jar</span><br><span class="line"></span><br><span class="line">解决办法：在本地工作区内去除所依赖的jar</span><br></pre></td></tr></table></figure></p><p>2.scala版本不一致导致出错<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.lang.NoSuchMethodError: scala.Predef$.ArrowAssoc(Ljava/lang/Object;)Ljava/lang/Object;</span><br><span class="line"></span><br><span class="line">解决办法：重新设置scala版本号</span><br></pre></td></tr></table></figure></p><p>3.hue提交spark注意点<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">java.lang.reflect.InvocationTargetException</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">at org.apache.oozie.action.hadoop.LauncherAM.runActionMain(LauncherAM.java:410)</span><br><span class="line">at org.apache.oozie.action.hadoop.LauncherAM.access$300(LauncherAM.java:55)</span><br><span class="line">at org.apache.oozie.action.hadoop.LauncherAM$2.run(LauncherAM.java:223)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)</span><br><span class="line">at org.apache.oozie.action.hadoop.LauncherAM.run(LauncherAM.java:217)</span><br><span class="line">at org.apache.oozie.action.hadoop.LauncherAM$1.run(LauncherAM.java:153)</span><br><span class="line">at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">at javax.security.auth.Subject.doAs(Subject.java:422)</span><br><span class="line">at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1875)</span><br><span class="line">at org.apache.oozie.action.hadoop.LauncherAM.main(LauncherAM.java:141)</span><br><span class="line">Caused by: org.apache.spark.SparkException: Application application_1588215511098_574080 finished with failed status</span><br><span class="line"></span><br><span class="line">可能是spark提交时未去掉master设置，在代码里注释就可以了。</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.本地依赖jar与集群jar包冲突&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>flink 运行时长记录</title>
    <link href="http://yoursite.com/2020/06/18/flink-%E8%BF%90%E8%A1%8C%E6%97%B6%E9%95%BF%E8%AE%B0%E5%BD%95/"/>
    <id>http://yoursite.com/2020/06/18/flink-运行时长记录/</id>
    <published>2020-06-18T06:14:01.000Z</published>
    <updated>2020-06-18T06:14:01.959Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/2020/06/18/da8d2f50-b12a-11ea-a950-4d00710d9c4a.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/2020/06/18/da8d2f50-b12a-11ea-a950-4d00710d9c4a.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;

      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>spark 读取外部配置文件</title>
    <link href="http://yoursite.com/2020/06/13/spark-%E8%AF%BB%E5%8F%96%E5%A4%96%E9%83%A8%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/"/>
    <id>http://yoursite.com/2020/06/13/spark-读取外部配置文件/</id>
    <published>2020-06-13T01:16:43.000Z</published>
    <updated>2020-06-13T01:20:42.165Z</updated>
    
    <content type="html"><![CDATA[<p>1.spark如何读取外部配置文件，能够更好的动态迁移程序以及当数据库等迁移是，只需要重新修改配置文件即可，而不需要指定重新编译程序，提交配置。<br>以下方法本人亲测有效<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">package load;</span><br><span class="line"></span><br><span class="line">import org.apache.spark.SparkFiles;</span><br><span class="line">import org.apache.spark.sql.SparkSession;</span><br><span class="line"></span><br><span class="line">import java.io.FileInputStream;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.util.Properties;</span><br><span class="line"></span><br><span class="line">public class ReadConfig &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        SparkSession spark = SparkSession.builder()</span><br><span class="line">                .appName(&quot;test&quot;)</span><br><span class="line">                .config(&quot;spark.debug.maxToStringFields&quot;,&quot;100&quot;)</span><br><span class="line">                .config(&quot;spark.sql.shuffle.partitions&quot;, &quot;50&quot;)</span><br><span class="line">                .config(&quot;spark.default.parallelism&quot;, &quot;12&quot;)</span><br><span class="line">                .getOrCreate();</span><br><span class="line"></span><br><span class="line">        String s = SparkFiles.get(&quot;property.yml&quot;);</span><br><span class="line">        try &#123;</span><br><span class="line">            Properties props = new Properties();</span><br><span class="line">            props.load(new FileInputStream(s));</span><br><span class="line">            String nodes = props.getProperty(&quot;es.nodes&quot;);</span><br><span class="line">            String port = props.getProperty(&quot;es.port&quot;);</span><br><span class="line">            System.out.println(nodes);</span><br><span class="line">        &#125; catch (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        spark.stop();</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><img src="/images/2020/06/13/80058250-ad13-11ea-9fb5-4b8d3e35b365.png" alt="image.png"><br>参考地址：<a href="https://blog.csdn.net/high2011/article/details/96288072?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase&amp;depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-3.nonecase" target="_blank" rel="noopener">spark读取配置文件</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.spark如何读取外部配置文件，能够更好的动态迁移程序以及当数据库等迁移是，只需要重新修改配置文件即可，而不需要指定重新编译程序，提交配置。&lt;br&gt;以下方法本人亲测有效&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
  </entry>
  
  <entry>
    <title>git ssh 免密配置</title>
    <link href="http://yoursite.com/2020/06/12/git-ssh-%E5%85%8D%E5%AF%86%E9%85%8D%E7%BD%AE/"/>
    <id>http://yoursite.com/2020/06/12/git-ssh-免密配置/</id>
    <published>2020-06-12T03:28:53.000Z</published>
    <updated>2020-06-12T03:32:16.722Z</updated>
    
    <content type="html"><![CDATA[<h3 id="一、配置全局用户名和邮箱"><a href="#一、配置全局用户名和邮箱" class="headerlink" title="一、配置全局用户名和邮箱"></a>一、配置全局用户名和邮箱</h3><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git config --global user.name &quot;xxx&quot;</span><br><span class="line">git config --global user.email &quot;xxx@xxx.com.cn&quot;</span><br><span class="line">ssh-keygen -t rsa -C &quot;xxx@xxx.com.cn&quot;</span><br></pre></td></tr></table></figure><p><img src="/images/2020/06/12/fd79a2b0-ac5b-11ea-9fb5-4b8d3e35b365.png" alt="image.png"></p><h3 id="二-、复制id-rsa-pub内容到git上"><a href="#二-、复制id-rsa-pub内容到git上" class="headerlink" title="二 、复制id_rsa.pub内容到git上"></a>二 、复制id_rsa.pub内容到git上</h3><p><img src="/images/2020/06/12/b96abbd0-ac5c-11ea-9fb5-4b8d3e35b365.png" alt="image.png"><br><img src="/images/2020/06/12/aee7b190-ac5c-11ea-9fb5-4b8d3e35b365.png" alt="image.png"></p><h3 id="三-、克隆git代码"><a href="#三-、克隆git代码" class="headerlink" title="三 、克隆git代码"></a>三 、克隆git代码</h3><blockquote><p>git clone git@xxx</p></blockquote><h3 id="四-maven安装配置"><a href="#四-maven安装配置" class="headerlink" title="四 maven安装配置"></a>四 maven安装配置</h3><p>参考博客：<a href="https://blog.csdn.net/l05199179/article/details/78982212" target="_blank" rel="noopener">maven安装</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;一、配置全局用户名和邮箱&quot;&gt;&lt;a href=&quot;#一、配置全局用户名和邮箱&quot; class=&quot;headerlink&quot; title=&quot;一、配置全局用户名和邮箱&quot;&gt;&lt;/a&gt;一、配置全局用户名和邮箱&lt;/h3&gt;&lt;figure class=&quot;highlight plain hl
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>常用地址记录</title>
    <link href="http://yoursite.com/2020/06/11/%E5%B8%B8%E7%94%A8%E5%9C%B0%E5%9D%80%E8%AE%B0%E5%BD%95/"/>
    <id>http://yoursite.com/2020/06/11/常用地址记录/</id>
    <published>2020-06-11T08:17:56.000Z</published>
    <updated>2020-06-11T08:17:56.595Z</updated>
    
    <content type="html"><![CDATA[<h1 id="目录地址"><a href="#目录地址" class="headerlink" title="目录地址"></a>目录地址</h1><blockquote><p>C:\Users\hadoop\Documents\Tencent Files\2590667609\FileRecv</p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;目录地址&quot;&gt;&lt;a href=&quot;#目录地址&quot; class=&quot;headerlink&quot; title=&quot;目录地址&quot;&gt;&lt;/a&gt;目录地址&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;C:\Users\hadoop\Documents\Tencent Files\259066760
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>jrebel 安装部署</title>
    <link href="http://yoursite.com/2020/06/11/jrebel-%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/"/>
    <id>http://yoursite.com/2020/06/11/jrebel-安装部署/</id>
    <published>2020-06-11T02:53:05.000Z</published>
    <updated>2020-06-11T02:56:19.261Z</updated>
    
    <content type="html"><![CDATA[<p>1.下载安装jrebel插件，并restart idea<br><img src="/images/2020/06/11/f2ec91f0-ab8d-11ea-9fb5-4b8d3e35b365.png" alt="image.png"></p><p>2.注册认证，打开注册机<br><img src="/images/2020/06/11/2d9fe220-ab8e-11ea-9fb5-4b8d3e35b365.png" alt="image.png"></p><p>3.激活jrebel<br><img src="/images/2020/06/11/644dfdc0-ab8e-11ea-9fb5-4b8d3e35b365.png" alt="image.png"><br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">http://127.0.0.1:8888/ae6a7dd7-fc4a-4044-8266-7d8220ae6567</span><br><span class="line">topsale@vip.qq.com</span><br></pre></td></tr></table></figure></p><p>4.<br><img src="/images/2020/06/11/9ec1d3f0-ab8e-11ea-9fb5-4b8d3e35b365.png" alt="image.png"></p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">链接：https://pan.baidu.com/s/1ctag4-yj9YYo5Xe3DxPVMA</span><br><span class="line">提取码：18rj</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.下载安装jrebel插件，并restart idea&lt;br&gt;&lt;img src=&quot;/images/2020/06/11/f2ec91f0-ab8d-11ea-9fb5-4b8d3e35b365.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;2.注册认证，打开注
      
    
    </summary>
    
      <category term="IDEA" scheme="http://yoursite.com/categories/IDEA/"/>
    
    
      <category term="插件" scheme="http://yoursite.com/tags/%E6%8F%92%E4%BB%B6/"/>
    
  </entry>
  
  <entry>
    <title>idea 快捷键</title>
    <link href="http://yoursite.com/2020/06/11/idea-%E5%BF%AB%E6%8D%B7%E9%94%AE/"/>
    <id>http://yoursite.com/2020/06/11/idea-快捷键/</id>
    <published>2020-06-11T00:48:00.000Z</published>
    <updated>2020-06-11T00:48:00.784Z</updated>
    
    <content type="html"><![CDATA[<p>1.try-catch快捷键<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ctrl+alt+t</span><br></pre></td></tr></table></figure></p><p><img src="/images/2020/06/11/2030c430-ab7d-11ea-9fb5-4b8d3e35b365.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.try-catch快捷键&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;lin
      
    
    </summary>
    
      <category term="学习" scheme="http://yoursite.com/categories/%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="工具" scheme="http://yoursite.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>spring boot test</title>
    <link href="http://yoursite.com/2020/06/10/spring-boot-test/"/>
    <id>http://yoursite.com/2020/06/10/spring-boot-test/</id>
    <published>2020-06-10T07:21:58.000Z</published>
    <updated>2020-06-10T07:21:58.936Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">package com.gree.bdc;</span><br><span class="line"></span><br><span class="line">import com.gree.bdc.entity.TGpsWarehouse;</span><br><span class="line">import com.gree.bdc.mapper.TGpsWarehouseMapper;</span><br><span class="line">import org.junit.Test;</span><br><span class="line">import org.junit.runner.RunWith;</span><br><span class="line">import org.springframework.boot.test.context.SpringBootTest;</span><br><span class="line">import org.springframework.test.context.junit4.SpringRunner;</span><br><span class="line"></span><br><span class="line">import javax.annotation.Resource;</span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">@RunWith(SpringRunner.class)</span><br><span class="line">@SpringBootTest(classes = DataAccessApplication.class,webEnvironment = SpringBootTest.WebEnvironment.DEFINED_PORT)</span><br><span class="line">public class MysqlTest &#123;</span><br><span class="line"></span><br><span class="line">    @Resource</span><br><span class="line">    private TGpsWarehouseMapper tGpsWarehouseMapper;</span><br><span class="line"></span><br><span class="line">    @Test</span><br><span class="line">    public void addBatchWareHouse()&#123;</span><br><span class="line">        List&lt;TGpsWarehouse&gt; warehouseList = new ArrayList&lt;&gt;();</span><br><span class="line">        TGpsWarehouse warehouse = new TGpsWarehouse(null,&quot;Aa&quot;,&quot;006&quot;,&quot;格力电器&quot;,</span><br><span class="line">                &quot;003&quot;,&quot;经济&quot;,2000,&quot;销售订单&quot;,null);</span><br><span class="line">        warehouseList.add(warehouse);</span><br><span class="line">        tGpsWarehouseMapper.addBatchWareHouse(warehouseList);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">           &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;</span><br><span class="line">           &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt;</span><br><span class="line">           &lt;version&gt;2.1.7.RELEASE&lt;/version&gt;</span><br><span class="line">           &lt;scope&gt;test&lt;/scope&gt;</span><br><span class="line">       &lt;/dependency&gt;</span><br><span class="line"></span><br><span class="line">       &lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt;</span><br><span class="line">       &lt;dependency&gt;</span><br><span class="line">           &lt;groupId&gt;junit&lt;/groupId&gt;</span><br><span class="line">           &lt;artifactId&gt;junit&lt;/artifactId&gt;</span><br><span class="line">           &lt;version&gt;4.12&lt;/version&gt;</span><br><span class="line">           &lt;!--&lt;scope&gt;test&lt;/scope&gt;--&gt;</span><br><span class="line">       &lt;/dependency&gt;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span 
      
    
    </summary>
    
      <category term="后台" scheme="http://yoursite.com/categories/%E5%90%8E%E5%8F%B0/"/>
    
    
      <category term="springboot" scheme="http://yoursite.com/tags/springboot/"/>
    
  </entry>
  
  <entry>
    <title>mysql mybatis</title>
    <link href="http://yoursite.com/2020/06/06/mysql-mybatis/"/>
    <id>http://yoursite.com/2020/06/06/mysql-mybatis/</id>
    <published>2020-06-06T09:12:06.000Z</published>
    <updated>2020-06-11T09:11:57.618Z</updated>
    
    <content type="html"><![CDATA[<p>1.mybatis 动态查询<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;select id=&quot;isExistWarehouse&quot; resultType=&quot;integer&quot; resultMap=&quot;BaseResultMap&quot;&gt;</span><br><span class="line">   select count(*) from t_gps_warehouse</span><br><span class="line">   &lt;where&gt;</span><br><span class="line">     &lt;if test=&quot;warehouseAddress != null &quot;&gt;</span><br><span class="line">       warehouse_address = #&#123;warehouseAddress&#125;</span><br><span class="line">     &lt;/if&gt;</span><br><span class="line"></span><br><span class="line">     &lt;if test=&quot;warehouseCode != null &quot;&gt;</span><br><span class="line">       AND warehouse_code = #&#123;warehouseCode&#125;</span><br><span class="line">     &lt;/if&gt;</span><br><span class="line">     &lt;if test=&quot;areaCode != null &quot;&gt;</span><br><span class="line">       AND area_code = #&#123;areaCode&#125;</span><br><span class="line">     &lt;/if&gt;</span><br><span class="line">   &lt;/where&gt;</span><br><span class="line"> &lt;/select&gt;</span><br></pre></td></tr></table></figure></p><p>2.mybatis插入数据报错<br><img src="/images/2020/06/08/0d2815a0-a975-11ea-9fb5-4b8d3e35b365.png" alt="image.png"></p><p>原因：数据库中表的自增id没有设置成自增模式<br>解决办法：将自增id设置自动增加<br><img src="/images/2020/06/08/61474570-a975-11ea-9fb5-4b8d3e35b365.png" alt="image.png"></p><p>3.mysql重新设置主键生成策略为auto_increment时报错：resulting in duplicate entry ‘1’ for key ‘PRIMARY’</p><blockquote><p>原因：自增字段有值为0或其他小于0值<br>解决方法：改为其他值大于0<br>参考解决方案：<a href="https://blog.csdn.net/huanghanqian/article/details/80866802" target="_blank" rel="noopener">自增id设置出错</a></p></blockquote><p>4.mybatis插入操作<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;insert id=&quot;insertWaybillNo&quot; useGeneratedKeys=&quot;true&quot; keyProperty=&quot;id&quot; parameterType=&quot;com.gree.bdc.entity.TGpsWaybill&quot;&gt;</span><br><span class="line"></span><br><span class="line">   insert into t_gps_waybill (waybill_no,licence_plate, company_name, device_id,imei,</span><br><span class="line">                              leave_warehouse_id,latitude,longitude,geo_hash,factory_time,bind_status)</span><br><span class="line">    values (#&#123;waybillNo&#125;,#&#123;licencePlate&#125;,#&#123;companyName&#125;,#&#123;deviceId&#125;,#&#123;imei&#125;,#&#123;leaveWarehouseId&#125;,</span><br><span class="line">   #&#123;latitude&#125;,#&#123;longitude&#125;,#&#123;geoHash&#125;,#&#123;factoryTime&#125;,#&#123;bindStatus&#125;)</span><br><span class="line"></span><br><span class="line"> &lt;/insert&gt;</span><br></pre></td></tr></table></figure></p><ol start="5"><li>mybatis 查询数据一直为 null<figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">package com.gree.bdc.entity;</span><br><span class="line"></span><br><span class="line">import lombok.AllArgsConstructor;</span><br><span class="line">import lombok.Data;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 司机信息</span><br><span class="line"> * @author hadoop</span><br><span class="line"> */</span><br><span class="line">@Data</span><br><span class="line">@AllArgsConstructor</span><br><span class="line">public class Driver &#123;</span><br><span class="line">    //司机名</span><br><span class="line">    private String driverName;</span><br><span class="line">    //司机电话</span><br><span class="line">    private String driverPhone;</span><br><span class="line">    //身份证号</span><br><span class="line">    private String idCard;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ol><p><img src="/images/2020/06/11/98146fb0-abc3-11ea-9fb5-4b8d3e35b365.png" alt="image.png"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.mybatis 动态查询&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;lin
      
    
    </summary>
    
      <category term="数据库 " scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="数据库" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>flink 算子记录</title>
    <link href="http://yoursite.com/2020/05/29/flink-%E7%AE%97%E5%AD%90%E8%AE%B0%E5%BD%95/"/>
    <id>http://yoursite.com/2020/05/29/flink-算子记录/</id>
    <published>2020-05-29T05:37:12.000Z</published>
    <updated>2020-06-04T01:43:57.509Z</updated>
    
    <content type="html"><![CDATA[<p>1、join静态数据库<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 关联运单表,以及订单完成情况</span><br><span class="line"> * 输入 Tuple5&lt;&gt;(positionTime, imei, latitude, longitude, geoHashValue)</span><br><span class="line"> * 输出 WayBill</span><br><span class="line"> * @author hadoop</span><br><span class="line"> */</span><br><span class="line">public class JoinWaybill extends RichFlatMapFunction&lt;Tuple5&lt;Timestamp, String, Double, Double, String&gt;, WayBill&gt; &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void flatMap(Tuple5&lt;Timestamp, String, Double, Double, String&gt; value, Collector&lt;WayBill&gt; out) throws Exception &#123;</span><br><span class="line">        Connection conn;</span><br><span class="line">        Statement statement;</span><br><span class="line">        conn = DruidPoolUtils.getConnection();</span><br><span class="line">        statement = conn.createStatement();</span><br><span class="line">        ResultSet resultSet =  statement.executeQuery(&quot;SELECT waybill_no,device_id,longitude,latitude,&quot; +</span><br><span class="line">                    &quot; geo_hash,factory_time,bind_status,leave_time,distance_departure,waybill_status,finish_time FROM  t_gps_waybill where device_id = &quot; + value.f1);</span><br><span class="line"></span><br><span class="line">        while (resultSet.next())&#123;</span><br><span class="line">                WayBill wayBill = new WayBill();</span><br><span class="line">                wayBill.setWayBill(resultSet.getString(&quot;waybill_no&quot;));</span><br><span class="line">                out.collect(wayBill);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        DruidPoolUtils.close(conn,statement);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p><p>2.sink mysql<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">.flatMap(new JoinWaybill())</span><br><span class="line">      .addSink(new RichSinkFunction&lt;WayBill&gt;() &#123;</span><br><span class="line">          @Override</span><br><span class="line">          public void invoke(WayBill value, Context context) throws Exception &#123;</span><br><span class="line">              Connection conn;</span><br><span class="line">              PreparedStatement statement;</span><br><span class="line">              conn = DruidPoolUtils.getConnection();</span><br><span class="line"></span><br><span class="line">              statement = conn.prepareStatement(</span><br><span class="line">                      &quot; INSERT INTO t_gps_test (waybill_no)&quot; +</span><br><span class="line">                              &quot; values(?)&quot; );</span><br><span class="line"></span><br><span class="line">              statement.setString( 1,  value.getWayBill() );</span><br><span class="line">              statement.execute();</span><br><span class="line">              DruidPoolUtils.close(conn,statement);</span><br><span class="line">          &#125;</span><br><span class="line">      &#125;)</span><br></pre></td></tr></table></figure></p><p>3.window<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.window(SlidingEventTimeWindows.of(Time.minutes(1),Time.minutes(1)))</span><br><span class="line">                .process(new JoinWaybill()).print()</span><br></pre></td></tr></table></figure></p><p>4.flink全局变量</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">//③配置参数</span><br><span class="line">        Configuration conf = new Configuration();</span><br><span class="line">        conf.setDouble(&quot;fixDistance&quot;,2000);</span><br><span class="line">        conf.setLong(&quot;fixTime&quot;,120L);</span><br><span class="line">        env.getConfig().setGlobalJobParameters(conf);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> ExecutionConfig.GlobalJobParameters globalParams = getRuntimeContext().getExecutionConfig().getGlobalJobParameters();</span><br><span class="line">        Configuration globConf = (Configuration) globalParams;</span><br><span class="line">        fixDistance = globConf.getDouble(&quot;fixDistance&quot;, 2000);</span><br><span class="line">        fixTime = globConf.getLong(&quot;fixTime&quot;, 120L);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1、join静态数据库&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>mysql 常见问题</title>
    <link href="http://yoursite.com/2020/05/29/mysql-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2020/05/29/mysql-常见问题/</id>
    <published>2020-05-29T05:33:17.000Z</published>
    <updated>2020-07-20T07:09:32.679Z</updated>
    
    <content type="html"><![CDATA[<p>1.druidpool连接池空指针异常<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Connection conn;</span><br><span class="line">       Statement statement;</span><br><span class="line">       conn = DruidPoolUtils.getConnection();</span><br><span class="line">       statement = conn.createStatement();</span><br></pre></td></tr></table></figure></p><p>2.Exception in thread “main” java.sql.SQLException: Can not call getNString() when field’s charset isn’t UTF-8<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wayBill.setWayBill(resultSet.getNString(&quot;waybill_no&quot;));</span><br><span class="line">          System.out.println(resultSet.getString(&quot;waybill_no&quot;));</span><br></pre></td></tr></table></figure></p><p>3.当数据为null时，插入数据库是，程序异常</p><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">   statement.setInt( 1,  wayBillInfo.getBindStatus() );</span><br><span class="line">        statement.setTimestamp( 2, wayBillInfo.getLeaveTime());</span><br><span class="line">        statement.setDouble( 3, wayBillInfo.getDistanceDeparture());</span><br><span class="line">        statement.setLong( 4, wayBillInfo.getTimeDeparture());</span><br><span class="line">        statement.setInt( 5, wayBillInfo.getWayBillStatus());</span><br><span class="line">        statement.setTimestamp( 6,  wayBillInfo.getFinishTime() );</span><br><span class="line">        statement.setString( 7, wayBillInfo.getWayBillNo() );</span><br><span class="line"></span><br><span class="line">解决办法：setObject()</span><br></pre></td></tr></table></figure><p>4.sql防注入以及参数传递<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Connection conn = DruidPoolUtils.getConnection();</span><br><span class="line">        PreparedStatement statement = conn.prepareStatement(&quot;&quot;);</span><br><span class="line"></span><br><span class="line">        ResultSet resultSet = statement.executeQuery(&quot;SELECT order_no,purpose_latitude,purpose_longitude ,finish_time FROM t_gps_order_list WHERE waybill_no = &apos;&quot; +wayBill.getWayBillNo() +&quot;&apos;&quot; );</span><br></pre></td></tr></table></figure></p><p>5.mysql差集<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">SELECT a.oname, a.odesc </span><br><span class="line">FROM</span><br><span class="line">  object_a a </span><br><span class="line">  LEFT JOIN object_b b </span><br><span class="line">    ON a.oname = b.oname </span><br><span class="line">    AND a.odesc = b.odesc </span><br><span class="line">WHERE b.id IS NULL</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">SELECT a.oname, a.odesc FROM object_a a </span><br><span class="line">MINUS </span><br><span class="line">SELECT b.oname, b.odesc FROM object_b b</span><br></pre></td></tr></table></figure></p><p>6.mysql数据字段长度注意点<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">varchar(M)可以保存可变长度的字符串. 其中M代表该数据类型所允许保存的字符串的最大长度，</span><br><span class="line">只要长度小于该最大值的字符串都可以被保存在该数据类型中, 而当插入的数据长度超出长度时, 有以下两种情况:</span><br><span class="line">在MySQL处于严格模式下, 超过了长度就会报错.</span><br><span class="line">非严格模式下, 插入值会被截断为合适的长度后入库</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.druidpool连接池空指针异常&lt;br&gt;&lt;figure class=&quot;highlight plain hljs&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class
      
    
    </summary>
    
      <category term="数据库 " scheme="http://yoursite.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
      <category term="数据库" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>flink 常见问题</title>
    <link href="http://yoursite.com/2020/05/27/flink-%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2020/05/27/flink-常见问题/</id>
    <published>2020-05-27T08:15:57.000Z</published>
    <updated>2020-06-01T08:14:53.011Z</updated>
    
    <content type="html"><![CDATA[<p>1.Exception in thread “main” org.apache.flink.api.common.functions.InvalidTypesException: The generic type parameters of ‘Collector’ are missing. In many cases lambda methods don’t provide enough information for automatic type extraction when Java generics are involved. An easy workaround is to use an (anonymous) class instead that implements the ‘org.apache.flink.streaming.api.functions.windowing.AllWindowFunction’ interface. Otherwise the type has to be specified explicitly using type information</p><p><img src="/images/2020/05/27/05f0a360-9ff2-11ea-ba39-730617437852.png" alt="image.png"></p><p>解决办法：加上返回数据类型，如：<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.returns(TypeInformation.of(new TypeHint&lt;List&lt;Tuple8&lt;Timestamp, String, Double, Double, String, Integer, Long, String&gt;&gt;&gt;()&#123;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure></p><p>2.flink 一直重复计算第一条数据<br><img src="/images/2020/05/29/c3e8f080-a19a-11ea-ba39-730617437852.png" alt="image.png"></p><p>原因：<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">与flink的状态值有关</span><br></pre></td></tr></table></figure></p><p>解决办法<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">每次用到value是都调用 .value方法,如：</span><br><span class="line"></span><br><span class="line"> wayBillState.value().equals(0)</span><br></pre></td></tr></table></figure></p><p>可能原因2：<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">该算子自身报错，flinkcheckpoint 后重新计算导致程序一直在处理第一条数据</span><br></pre></td></tr></table></figure></p><p>3.flink的状态变量如何只更新元组中的某个字段，其他字段不更新<br><figure class="highlight plain hljs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">目前没有什么好办法：现提供两个不是办法的办法</span><br><span class="line">1.将两个字段分别用两个不同的状态变量保存，这样就可以分别更新了，但是造成状态变量过多，内存浪费</span><br><span class="line">2.还是用一个变量，在更新其中的某个字段时，取出不更新的字段与更新的字段和并，更新这个状态值</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1.Exception in thread “main” org.apache.flink.api.common.functions.InvalidTypesException: The generic type parameters of ‘Collector’ are 
      
    
    </summary>
    
      <category term="大数据" scheme="http://yoursite.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://yoursite.com/tags/flink/"/>
    
  </entry>
  
</feed>
